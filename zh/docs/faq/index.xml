<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>FAQ on</title><link>https://n9e.github.io/zh/docs/faq/</link><description>Recent content in FAQ on</description><generator>Hugo -- gohugo.io</generator><language>en-US</language><lastBuildDate>Mon, 07 Jul 2025 10:30:30 +0800</lastBuildDate><atom:link href="https://n9e.github.io/zh/docs/faq/index.xml" rel="self" type="application/rss+xml"/><item><title>全局回调下线，那全局场景怎么处理？</title><link>https://n9e.github.io/zh/docs/faq/global-callback/</link><pubDate>Mon, 07 Jul 2025 10:31:38 +0800</pubDate><guid>https://n9e.github.io/zh/docs/faq/global-callback/</guid><description>后面计划在 V9 版本，下掉全局回调，如果你当前还在使用全局回调功能，需要尽快迁移到新的使用方式。那么，使用什么方式来替代全局回调呢？
答案是：订阅规则（ 👈 点击查看使用说明）。
订阅规则的菜单入口是：告警-规则管理-订阅规则TAB。下面是创建订阅规则的界面：
我们可以创建一个订阅规则，然后订阅所有的告警事件，即不要加过滤条件，直接选中所有级别，这样任何告警事件都会匹配这个订阅规则，注意：
上图是老版本，数据源类型还是必须要选的，所以准确来讲，上例的订阅规则其实不是针对所有告警事件，而是针对 Prometheus 类型的数据源的所有告警事件。 后面的版本会做优化，数据源类型会做成非必填项，即可以订阅所有数据源类型的告警事件。 然后，选择一个通知规则，这样一来，所有的告警事件都可以走这个通知规则了。和之前的全局回调相比，有两个典型好处：
订阅规则这里，可以做一些过滤，比如只订阅某个数据源类型的告警事件，或者只订阅某个级别的告警事件。 所有告警事件走一个统一的通知规则，通知规则里可以有事件处理器 Pipeline，可以使用不同的通知媒介，不同的通知媒介还可以有细粒度的过滤配置，整体上比全局回调更灵活。</description></item><item><title>CPU 负载高，到底应不应该告警？</title><link>https://n9e.github.io/zh/docs/faq/cpu-alerting/</link><pubDate>Wed, 23 Jul 2025 11:50:21 +0800</pubDate><guid>https://n9e.github.io/zh/docs/faq/cpu-alerting/</guid><description>CPU 负载高，到底应不应该告警？
不告警吧，出了问题怕被怼，嫌你告警缺失 告警吧，好像全是噪音，工程师都自动忽略了 尴尬&amp;hellip;
成年人的世界没有非黑即白，如果要严肃的论述，就要加很多限定词，为了避免歧义拉齐认知，我先补充一点前置知识（原则）。
前置知识（原则） # 告警应该有不同的紧迫级别，有些公司甚至会规定 6 个级别（估计自己的工程师都捋不清楚&amp;hellip;），通常建议 3 个级别足够了：
Critical：已经影响业务，立马需要处理。通常使用打扰性很强的多个告警通知媒介一起发告警消息，比如电话+短信+IM+邮件。比如电商业务订单量下跌严重，就是紧急告警。 Warning：不用立马处理，可以自动建立工单，慢慢处理。但也必须要处理，如果不处理，可能会酿成大故障。通常也要发告警，只不过选用的通知媒介没有那么强的打扰性。比如重要机器的磁盘使用率已经 95%，可能再有 24 小时就要写满了；或域名证书再有 3 天就要过期了之类的。 Info：仅生成告警事件，不用发告警通知，相当于是从海量指标里提取了一些稍微重要的信息。如果有故障发生，这些信息是作为故障排查的线索依据。比如某个 Pod 被驱逐漂移了；或者某个用户尝试登录系统的失败次数太多。 整体来看，可以分成两个大类：
要处理的：Critical、Warning 不用处理的：Info 其中，Info 不关键，可配可不配，完全可以等到后面你的监控、故障定位体系做得很精细化的时候再说。我们重点关注前面两个级别：Critical 和 Warning，这俩级别有个相同点，就是都！要！处！理！英文世界里通常称之为 actionable（感觉很精确）。
所以，CPU 负载高，到底要不要配置告警？
CPU 告警的制定逻辑 # 如果 CPU 告警产生之后，你们有后续处理动作，那就应该配置，即便这个动作是登录机器瞅一眼，出两句跟进结论，也算动作 如果没有后续动作就无需配置，比如看到了这个告警，习惯了，直接忽略了，这就不算动作，这个告警就不应该配置；或者，也可以配置，但是作为 Info 级别，仅生成告警事件，不做告警通知 其实，不仅仅是 CPU 告警，所有的告警规则配置，都是这个逻辑，所有的告警规则，都应该是 actionable 的。所以，理论上，每个告警规则都应该对应一个 SOP（处理预案），Prometheus 和夜莺的告警规则里都有个 Annotations 字段，典型的应该放到 Annotations 中的字段就是 SOP URL 和 Dashboard URL。
很多人看到这里，觉得，那这个工作量大了，每个告警规则都要整理 SOP（不同的公司 SOP 通常不同，一些中间件、数据库的部分 SOP 可能相同），之前就仅仅是从网上找了一些告警规则导入即可，以为就完事了，没成想还有这些活要干！</description></item><item><title>底层的告警，上层业务应该收吗？</title><link>https://n9e.github.io/zh/docs/faq/biz-team-subscribe-infra-alarms/</link><pubDate>Wed, 23 Jul 2025 11:53:21 +0800</pubDate><guid>https://n9e.github.io/zh/docs/faq/biz-team-subscribe-infra-alarms/</guid><description>有朋友问：我是业务应用的 DEV 或 SRE，我的应用依赖了底层服务和基础设施，比如依赖基础网络、Kubernetes、MySQL、收银台服务，那这些基础服务如果出问题，我应该收告警吗？夜莺里有个订阅规则，是不是就是为此设计的？
本文讲讲笔者的个人理解，仅供参考。
首先，请大家看一下上一篇文章《CPU负载高，到底应不应该告警？》，其中提到一个点：只有 actionable 的告警规则才有意义！
所以，要看你们的情况：
1，如果你的服务是单机房部署，这些基础设施和服务出问题你无能为力，只能被动等待恢复，即你没有 SOP，那收这些告警意义不大。
此时推荐的做法是：做一个可视化页面，把你依赖的基础设施和服务的关键 SLI 放上去，你能通过查看 UI 趋势图，了解到各个基础设施和服务的健康状况即可。Facebook 有个内部产品叫 SLICK，就是类似的逻辑，我们创业做的 Flashcat 里有个功能叫“灭火图”，也有类似的效果。这算是一个惯常做法。
2，如果你有 SOP，比如可以切流，那么去订阅这类告警是有意义的。
但是，很多底层服务的关键指标你也未必看得懂，此时最好有个规范。比如，每个底层服务的负责人，在配置告警规则时，如果觉得那个告警规则很重要，对应的告警会影响上层服务，那就给那个规则打上一个特殊标签，比如 advertise=mysql 表示所有 MySQL 相关的需要周知的告警，比如 advertise=k8s 表示所有 Kubernetes 相关的需要周知的告警，之后上层应用的 DEV、SRE 就可以订阅这类标签，知悉相关的告警。
另外
MySQL、收银台这类服务，相比去订阅它们的 SLI 告警，更好的方式是在上层应用里自行埋点，主要是采集一下请求数、失败数、延迟就可以了。
因为从 MySQL 的视角来看，其 SLI 指标是面向整个实例的，而如果在上层应用埋点，其指标就可以细化到与这个服务相关，甚至与这个服务的特定业务场景相关，做得更精细化。</description></item></channel></rss>