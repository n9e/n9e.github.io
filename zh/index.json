[{"RelPermalink":"/zh/docs/prologue/introduction/","contents":"夜莺监控（Nightingale）是一款侧重告警的监控类开源项目。类似 Grafana 的数据源集成方式，夜莺也是对接多种既有的数据源，不过 Grafana 侧重在可视化，夜莺是侧重在告警引擎、告警事件的处理和分发。\n夜莺监控项目，最初由滴滴开发和开源，并于 2022 年 5 月 11 日，捐赠予中国计算机学会开源发展委员会（CCF ODC），为 CCF ODC 成立后接受捐赠的第一个开源项目。\n代码仓库 #  后端(主仓库)：https://github.com/ccfos/nightingale 前端：https://github.com/n9e/fe  夜莺的工作逻辑 # 很多用户已经自行采集了指标、日志数据，此时就把存储库（VictoriaMetrics、ElasticSearch等）作为数据源接入夜莺，即可在夜莺里配置告警规则、通知规则，完成告警事件的生成和派发。\n夜莺项目本身不提供监控数据采集能力。推荐您使用 Categraf 作为采集器，可以和夜莺丝滑对接。\nCategraf 可以采集操作系统、网络设备、各类中间件、数据库的监控数据，通过 Remote Write 协议推送给夜莺，夜莺把监控数据转存到时序库（如 Prometheus、VictoriaMetrics 等），并提供告警和可视化能力。\n对于个别边缘机房，如果和中心夜莺服务端网络链路不好，希望提升告警可用性，夜莺也提供边缘机房告警引擎下沉部署模式，这个模式下，即便边缘和中心端网络割裂，告警功能也不受影响。\n 上图中，机房A和中心机房的网络链路很好，所以直接由中心端的夜莺进程做告警引擎，机房B和中心机房的网络链路不好，所以在机房B部署了 n9e-edge 做告警引擎，对机房B的数据源做告警判定。\n 告警降噪、升级、协同 # 夜莺的侧重点是做告警引擎，即负责产生告警事件，并根据规则做灵活派发，内置支持 20 种通知媒介（电话、短信、邮件、钉钉、飞书、企微、Slack 等）。\n如果您有更高级的需求，比如：\n 想要把公司的多套监控系统产生的事件聚拢到一个平台，统一做收敛降噪、响应处理、数据分析 想要支持人员的排班，践行 On-call 文化，想要支持告警认领、升级（避免遗漏）、协同处理  那夜莺是不合适的，推荐您使用 FlashDuty 这样的 On-call 产品，把云上、云下各类监控系统的告警收拢到一起，统一做降噪、分发、响应。\n相关资料 \u0026amp; 交流渠道 #  📚 夜莺介绍 PPT 对您了解夜莺各项关键特性会有帮助（PPT链接在文末） ❤️ 提问 \u0026amp; 报告 Bug 写清楚版本、问题描述、复现步骤、截图等信息，否则社区无法帮助您 🌟 加我微信：picobyte（备注：夜莺互助群）拉入微信群，如果已经把夜莺上到生产环境了，可联系我拉入资深监控用户群  关键特性简介 #  夜莺支持告警规则、屏蔽规则、订阅规则、通知规则，内置支持 20 种通知媒介，支持消息模板自定义 支持事件管道，对告警事件做 Pipeline 处理，方便和自有系统做自动化整合，比如给告警事件附加一些元信息，对事件做 relabel 支持业务组概念，引入权限体系，分门别类管理各类规则 很多数据库、中间件内置了告警规则，可以直接导入使用，也可以直接导入 Prometheus 的告警规则 支持告警自愈，即告警之后自动触发一个脚本执行一些预定义的逻辑，比如清理一下磁盘、抓一下现场等   夜莺存档了历史告警事件，支持多维度的查询和统计 支持灵活的聚合分组，一目了然看到公司的告警事件分布情况   夜莺内置常用操作系统、中间件、数据库的的指标说明、仪表盘、告警规则，不过都是社区贡献的，整体也是参差不齐 夜莺直接接收 Remote Write、OpenTSDB、Datadog、Falcon 等多种协议的数据，故而可以和各类 Agent 对接 夜莺支持 Prometheus、ElasticSearch、Loki、TDEngine 等多种数据源，可以对其中的数据做告警 夜莺可以很方便内嵌企业内部系统，比如 Grafana、CMDB 等，甚至可以配置这些内嵌系统的菜单可见性   夜莺支持仪表盘功能，支持常见的图表类型，也内置了一些仪表盘，上图是其中一个仪表盘的截图。 如果你已经习惯了 Grafana，建议仍然使用 Grafana 看图。Grafana 在看图方面道行更深。 机器相关的监控数据，如果是 Categraf 采集的，建议使用夜莺自带的仪表盘查看，因为 Categraf 的指标命名 Follow 的是 Telegraf 的命名方式，和 Node Exporter 不同 因为夜莺有个业务组的概念，机器可以归属不同的业务组，有时在仪表盘里只想查看当前所属业务组的机器，所以夜莺的仪表盘可以和业务组联动  感谢众多企业信赖 # 夜莺有众多企业用户，如下只是选取了一部分，以下企业排名不分先后。\n开源协议 # 夜莺监控项目采用 Apache License 2.0 协议开源。\n","description":"夜莺监控（Nightingale）是一款侧重告警的监控类开源项目。类似 Grafana 的数据源集成方式，夜莺也是对接多种既有的数据源，不过 Grafana 侧重在可视化，夜莺是侧重在告警引擎、告警事件的处理和分发。","title":"夜莺项目介绍"},{"RelPermalink":"/zh/docs/prologue/prometheus/","contents":"夜莺监控（Nightingale）类似 Grafana，可以对接多种数据源，最常用的数据源就是 Prometheus（其他兼容 Prometheus 接口的数据源，比如 VictoriaMetrics、Thanos、M3DB，都可以看做是 Prometheus 类型），所以二者关系密切。\n如果您有如下诉求，可以考虑夜莺：\n 有多套时序库，比如 Prometheus、VictoriaMetrics 等，想要使用一套统一的平台来管理各类告警规则，并有权限管控 Prometheus 的告警引擎是单点的，担心单机挂掉导致告警引擎无法工作 除了 Prometheus 的告警，还需要 ElasticSearch、Loki、ClickHouse 等其他数据源的告警 需要更灵活的告警规则配置，比如控制生效时间、事件 Relabel、事件联动 CMDB、支持告警联动自愈脚本  夜莺监控也具备类似 Grafana 的可视化能力，不过没有 Grafana 道行深，以笔者观察来看，很多公司是一套组合方案（成年人的世界，没有非黑即白，都要）：\n 数据采集：组合使用了各种 agent 和 exporter，比如主要使用 Categraf（尤其是机器监控，和夜莺丝滑对接），辅以各类 Exporter 存储：时序库主要使用 VictoriaMetrics，因为 VictoriaMetrics 兼容 Prometheus，而且性能更好且有集群版本，对大部分公司，单机版就足够用了 告警引擎：使用夜莺，方便不同的团队管理协作，内置了一些规则开箱即用，告警规则的配置非常灵活，事件 Pipeline 机制方便和自己的 CMDB 等打通 看图可视化：使用 Grafana，图表更为炫酷，社区非常庞大，从 Grafana 站点可以找到很多别人做好的仪表盘，较为省心 告警事件 On-call 分发：使用 FlashDuty，支持对接 Zabbix、Prometheus、夜莺、各云监控、Elastalert 等各类监控系统，收拢告警事件到一个平台，统一收敛降噪、排班、认领升级、响应、派发等。  ","description":"夜莺监控（Nightingale）和 Prometheus 的关系，是一个经常被讨论的话题，实际这二者是一个协同互补的关系，本文会详细介绍二者的区别和联系。","title":"夜莺对比 Prometheus"},{"RelPermalink":"/zh/docs/prologue/pre-knowledge/","contents":"夜莺监控（Nightingale）算是 Prometheus 大生态的一部分，所以很多 Prometheus 的概念和知识就是使用夜莺的前置知识，本文把关键知识做一个罗列，并给出相关学习资料，希望对你有所帮助。\n基础知识 #  Linux 知识，比如进程相关、网络相关、systemd 相关的等，可参考书籍《鸟哥的Linux私房菜》、视频教程《面向研发工程师的Linux进阶知识》 提问的技巧，可以参考著名黑客 Raymond 的《提问的智慧》，在全球范围内传播甚广。Raymond 的文章很长，也可以参考这篇短文《学会这招，技术问题再也难不倒你》  监控知识 #  基础的一些监控概念，可以参考这个专栏《运维监控系统实战笔记》，尤其是前面几篇基础内容 Prometheus 的基础概念，可以参考 Prometheus 的官网文档，也可以参考这里的中文知识。 Promql，非常非常非常重要，这是使用 Prometheus 和 Nightingale 的前提，可以参考《Promql系列教程》  ","description":"夜莺监控（Nightingale）是一个开源的监控系统，本文介绍了学习夜莺前需要了解的一些基础知识和概念。监控方向的知识非常驳杂，希望各位读者能够耐心。","title":"学习夜莺的前置知识"},{"RelPermalink":"/zh/docs/prologue/architecture/","contents":"夜莺的架构比较简单，如果只是测试功能，一个二进制就可以启动，如果要上到生产环境，则要依赖 MySQL 和 Redis。有些公司会有多个机房，有些边缘机房和中心机房的网络质量较差，夜莺也针对这种情况做了专门的设计。\n架构图 # 不考虑边缘模式的话，夜莺只有一个主进程，即 n9e 进程，依赖 MySQL 和 Redis 存储一些管理数据，可以接入多种数据源，技术架构图示意如下：\n初期支持的数据源：Prometheus、VictoriaMetrics、ElasticSearch，既支持看图也支持告警，后面夜莺侧重在做告警引擎，所以后面新支持的数据源就只支持告警。\n根据监控数据是否流经夜莺，可以分成两个模式：\n 模式1：监控数据不流经夜莺，用户自己搞定数据采集的问题，仅把时序库配置到夜莺里，使用夜莺看图和配置告警。上面的架构图就是典型的这种模式。 模式2：数据流经夜莺，Categraf 通过 remote write 协议把数据推给夜莺，夜莺不直接存储数据，而是把数据转存到时序库，转存到哪些时序库？由夜莺配置文件 config.toml 中的 Pushgw.Writers 来决定，模式2下的架构图如下：  上图中，夜莺接到监控数据之后转发给了 VictoriaMetrics，当然，也可以转发给 Prometheus，如果要转发给 Prometheus，记得 Prometheus 启动的时候要打开 remote receiver 的功能（./prometheus --help | grep receiver 可以看到具体是要加哪个控制参数），即开启 Prometheus 的 /api/v1/write 接口。\n 🟢 如果是新用户，建议直接使用 VictoriaMetrics，VictoriaMetrics 性能更好，且支持集群模式，而且，和 Prometheus 接口兼容。不过 VictoriaMetrics 的中文资料比 Prometheus 更少一些。\n 单节点测试模式 # 从夜莺的 github releases 下载发布包，解压之后里边有个 n9e 二进制文件，直接 ./n9e 就可以运行起来，默认端口是 17000，默认用户名是 root，密码是 root.2020。\nn9e 进程只依赖二进制同级目录的 etc 和 integrations 目录，不依赖其他任何服务。\n在这种单机模式下，方便做快速测试，不过不建议用于生产环境。此种模式下，夜莺会把配置类数据（比如用户信息、告警规则、仪表盘等）存储在本地的 SQLite 数据库文件中，所以 n9e 进程启动之后，同级目录下会生成一个 n9e.db 的 SQLite 数据库文件。\n单节点生产模式 # 如果要上到生产环境，则需要依赖 MySQL 和 Redis。所以，需要在配置文件 etc/config.toml 中配置 MySQL 和 Redis 的连接信息。\nMySQL 的关键配置样例：\n[DB] DBType = \u0026quot;mysql\u0026quot; DSN = \u0026quot;root:YourPa55word@tcp(localhost:3306)/n9e_v6?charset=utf8mb4\u0026amp;parseTime=True\u0026amp;loc=Local\u0026quot;  上面 DSN（连接字符串）的格式是 用户名:密码@tcp(地址:端口)/数据库名?参数，其中 n9e_v6 是夜莺的数据库名，从 V6 版本开始，就一直习惯使用这个名字了（即便现在是 V8+ 版本了），建表语句里也一直延用了这个名字。\nRedis 的关键配置样例：\n[Redis] Address = \u0026quot;127.0.0.1:6379\u0026quot; RedisType = \u0026quot;standalone\u0026quot;  上面只是给了最基础的配置样例，配置文件中还有很多其他配置项，具体可以参考配置文件中的注释，也可以参考这里的配置文件说明。\n夜莺集群 # 集群模式很简单，只需要搞多台机器，每台机器都部署 n9e 进程（进程要想正常工作依赖 etc 和 integrations 目录），多个 n9e 的配置文件确保完全一致，共享同一套 MySQL 和 Redis，即可。\n多个 n9e 进程会自动分派告警规则，比如有 2 个 n9e 进程，用户共配置了 100 条告警规则，夜莺会自动把这 100 条告警规则分配到 2 个 n9e 进程上，每个进程大概 50 条告警规则（一个规则只会在某一个 n9e 实例上运行，不会重复告警）。如果某个机器挂了，另一个机器上的 n9e 会接管它的告警规则，继续工作。\n边缘模式 # 上面讲到的几种模式，都是中心化模式，但实际生产环境里，可能会有多个机房，中心机房和边缘机房的网络质量可能不太好，如果让中心机房的 n9e 负责边缘机房的某个时序库的告警，会不稳定，有时甚至 n9e 直接连不通边缘机房的时序库，这时就需要夜莺的边缘机房下沉部署模式。\n我们这里假设贵司有 3 个机房：中心主力机房、边缘机房 A 和边缘机房 B，其中边缘机房 A 和中心机房之间有专线，网络链路很好，边缘机房 B 和中心机房之间没有专线，走公网，网络链路不够可靠。\nn9e 进程部署在中心主力机房，n9e 依赖 mysql 和 redis，所以 mysql 和 redis 也部署在中心主力机房。如果你想做高可用，中心机房的 n9e 可以部署多个实例，配置文件保持一致，连同一个 mysql 和 redis 即可。\n上图中，我们有 5 个数据源：\n 中心机房有一套 Loki，一套 ElasticSearch 边缘机房 A 有一套 ElasticSearch，一套 Prometheus 边缘机房 B 有一套 VictoriaMetrics  我们希望在中心 n9e 统一查看这 5 个数据源的数据，所以要把这 5 个数据源的访问地址配置到夜莺中，菜单位置：集成中心-数据源。\n中心 n9e 可以通过内网地址直接连通中心机房和边缘机房 A 的数据源，但是无法直接连通边缘机房 B 的数据源（因为没有专线），那只能把边缘机房 B 的 VictoriaMetrics 暴露一个公网地址出来，中心 n9e 通过公网地址访问边缘机房 B 的 VictoriaMetrics，即：\n 机房 B 的 VictoriaMetrics 暴露公网访问地址，比如为：https://ex.a.com 在夜莺的 WEBUI 上配置数据源时，把机房 B 的 VictoriaMetrics 的 URL 配置为：https://ex.a.com  架构图中的 1、2、3、4、5 这 5 条线，表示中心 n9e 和 5 个数据源的连接关系。用户在查询数据的时候，是在 n9e 的 web 上查的，发请求给 n9e 进程，n9e 进程此时相当于一个 proxy，把请求代理给后端的各个数据源，然后把数据源的数据返回给用户。\nn9e-edge 部署在边缘机房 B，用于处理 B 机房 VictoriaMetrics 的告警判定，n9e-edge 会从中心 n9e 同步告警规则（即图中的 A 那条线），然后把告警规则缓存在内存里，对本机房的 VictoriaMetrics 做告警判定工作。这样的架构下，n9e-edge 和 VictoriaMetrics 是内网连通的，所以告警比较可靠，另外即便 n9e-edge 连不通中心机房的 n9e 了，也不影响 B 机房的告警判定工作，因为 n9e-edge 内存中已经缓存了告警规则。\nn9e-edge 产生的告警事件会调用 n9e 的接口写回中心 mysql，调用钉钉、飞书、FlashDuty 等的接口发送通知。如果 n9e-edge 和 n9e 之间网络断了，告警事件就写不到 mysql 了，但是只要 n9e-edge 所在机房的外网出口是好的，告警通知还是可以发出去的。\n架构图中：\n 中心机房的 n9e 负责中心机房的 Loki、ElasticSearch 的告警判定，也负责机房 A 的 ElasticSearch 和 Prometheus 的告警判定 边缘机房 B 的 n9e-edge 负责机房 B 的 VictoriaMetrics 的告警判定  那如何指定不同的数据源和告警引擎之间的关联关系呢？其实是在数据源的管理页面：\n上图中：\n URL 是中心 n9e 读取数据的地址，在上例架构中，需要配置为 B 机房 VictoriaMetrics 的公网地址 时序库内网地址是 n9e-edge 连接 VictoriaMetrics 的地址，如果 URL 已经是一个内网地址了，这个配置项就可以留空，留空之后 n9e-edge 就会使用 URL 中的地址。上例中，由于 n9e-edge 和 VictoriaMetrics 在同一个机房，所以这个地址应该配置为内网地址，这样告警判定更可靠 Remote Write URL 是 VictoriaMetrics 的 remote write 写入地址，用于记录规则，即 recording rule，n9e-edge 负责处理记录规则，把结果写回时序库，所以需要知道时序库的 remote write 地址，因为是给 n9e-edge 用的，所以使用内网地址。如果你没有用到夜莺的记录规则，这里可以不用配置 关联告警引擎集群，上图选择的是 edge-b，这是 B 机房 n9e-edge 的名字（由 edge.toml 的 EngineName 字段指定），这样配置之后，就建立了 B 机房 n9e-edge 和 B 机房 VictoriaMetrics 之间的关联关系，就会由这个 n9e-edge 来处理 B 机房 VictoriaMetrics 的告警规则和记录规则  新版本的夜莺，n9e-edge 依赖一个 redis，所以需要在 B 机房部署一个 redis 给 n9e-edge 使用，注意，n9e-edge 所用的 redis 和中心机房 n9e 所用的 redis 不是一个。架构图中我特意标注了 R1、R2 两个名字，表示两个 redis，分别给 n9e 和 n9e-edge 使用。\n最后说一下 categraf，如果网络链路比较好，categraf 可以把数据直接上报到中心机房的 n9e，比如中心机房和 A 机房的 categraf 都可以直接对接到中心机房的 n9e，但是 B 机房部署了 n9e-edge，那 B 机房的 categraf 就应该对接到 B 机房的 n9e-edge。\n配置样例 # 要达到上述架构，各个组件的配置文件应该如何配置？这里给出一个示例。\n中心机房 n9e 配置 # 中心机房 n9e 的默认配置文件是 etc/config.toml：\n[HTTP.APIForService] Enable = true [HTTP.APIForService.BasicAuth] user001 = \u0026quot;ccc26da7b9aba533cbb263a36c07dcc5\u0026quot; user002 = \u0026quot;ccc26da7b9aba533cbb263a36c07dcc6\u0026quot;  重点就是 HTTP.APIForService 这块的配置。默认 Enable 是 false 是为了安全考虑，即默认不支持 n9e-edge 架构，如果要支持，需要改成 true。n9e-edge 调用 n9e 的接口时，可以使用 BasicAuth 认证，即 HTTP.APIForService.BasicAuth 下面的部分，上例中配置了两个用户，分别是 user001 和 user002，密码是 ccc26da7b9aba533cbb263a36c07dcc5 和 ccc26da7b9aba533cbb263a36c07dcc6。其实配置一个用户就行，我配置两个只是为了演示。另外，如果你的 n9e 暴露在公网，千万要修改 BasicAuth 的默认密码，不然很容易被攻击。\n边缘机房 n9e-edge 配置 # 边缘机房 n9e-edge 的默认配置文件是 etc/edge/edge.toml，首先 n9e-edge 要调用中心 n9e 的接口，所以要配置中心 n9e 的地址：\n[CenterApi] Addrs = [\u0026quot;http://N9E-CENTER-SERVER:17000\u0026quot;] BasicAuthUser = \u0026quot;user001\u0026quot; BasicAuthPass = \u0026quot;ccc26da7b9aba533cbb263a36c07dcc5\u0026quot; # unit: ms Timeout = 9000  N9E-CENTER-SERVER:17000 表示中心 n9e 的地址，你按照自己的环境调整即可。BasicAuthUser 和 BasicAuthPass 是中心 n9e 的 BasicAuth 用户名和密码，如果中心 n9e 没有开启 BasicAuth，这两个字段可以不填。还是那句话，千万要修改 BasicAuth 的默认密码，不然很容易被攻击。\n新版本 n9e-edge 依赖 redis，所以要配置 redis 地址，默认应该是在 edge.toml 的最下面，自行修改即可。如果你是老版本，不依赖 redis，那就不用配置了。如何分辨你的版本的 n9e-edge 是否依赖 redis？就看你下载下来的 edge.toml 默认配置中是否带有 redis 配置，带了就说明依赖 redis。\n边缘机房 categraf 配置 # 主要是注意 2 个地方，writer 的地址和 heartbeat 的地址，都配置为 n9e-edge 的地址：\n... [[writers]] url = \u0026quot;http://N9E-EDGE:19000/prometheus/v1/write\u0026quot; ... [heartbeat] enable = true # report os version cpu.util mem.util metadata url = \u0026quot;http://N9E-EDGE:19000/v1/n9e/heartbeat\u0026quot; ...  N9E-EDGE:19000 表示 n9e-edge 的地址，注意，n9e-edge 默认监听的端口是 19000，也可以在 edge.toml 中自行修改。\nibex 配置 # ibex 部分，即故障自愈的功能，这个功能有些公司担心安全问题不开放。如果你们要开启这个功能，同样的道理，在 edge.toml 中开启：\n[Ibex] Enable = true RPCListen = \u0026quot;0.0.0.0:20090\u0026quot;  然后边缘机房的 categraf 连边缘机房的 n9e-edge 的 20090 端口即可，即 categraf 的 config.toml 要做如下配置：\n[ibex] enable = true ## ibex flush interval interval = \u0026quot;1000ms\u0026quot; ## n9e ibex server rpc address servers = [\u0026quot;N9E-EDGE-IP:20090\u0026quot;] ## temp script dir meta_dir = \u0026quot;./meta\u0026quot;  N9E-EDGE-IP:20090 表示 n9e-edge 的 RPC 地址。注意这是 RPC 地址，不是 HTTP 地址，所以，不要在 N9E-EDGE-IP 前面画蛇添足加上 http:// 啦。\n其他适用场景 # 除了网络链路不好的场景之外，有时为了安全考虑，网络也会有分区，比如某个网络区域只有一台中转机可以连通中心的 n9e，其他机器都不能连通，这时候就可以在中转机上部署 n9e-edge，然后其他机器的 categraf 连中转机的 n9e-edge 即可。\n","description":"本文讲解夜莺监控（Nightingale）的架构设计。包括中心化集群的设计以及边缘机房下沉部署模式。","title":"夜莺架构设计"},{"RelPermalink":"/zh/docs/prologue/flashcat/","contents":"夜莺监控（Nightingale）的主力开发人员是全职在做开源，如果没有收入养家糊口，项目也就无法持续了。所以他们创办了一家企业：北京快猫星云科技有限公司，简称“快猫”，推出了两款商业产品：\n 一站式智能观测平台Flashcat 一站式告警响应平台Flashduty  其中 Flashcat 可以看做是夜莺的商业版，定位是统一的观测平台，开源版则只是侧重在指标监控，二者的区别可以参考这篇文章：《夜莺开源版和商业版的区别》。\nFlashDuty 则是类似 PagerDuty 的一站式告警响应平台（即 On-call 中心），支持对接 Zabbix、Prometheus、夜莺、各云监控、Elastalert 等各类监控系统，收拢告警事件到一个平台，统一对告警做收敛降噪、排班、认领升级、响应、派发等。可以免费注册试用。\n监控、可观测性领域的知识确实非常驳杂，如果您有预算需要乙方协助，可以考虑快猫的产品，多方共赢 👉 免费与快猫做产品思路交流。\n","description":"监控领域确实非常驳杂，如果您需要乙方协助，可以考虑夜莺监控（Nightingale）商业版，商业版提供了更多的功能和服务。","title":"夜莺商业版"},{"RelPermalink":"/zh/docs/prologue/videos/","contents":"为了方便大家快速上手使用夜莺监控（Nightingale），我们制作了一系列入门视频教程，涵盖了从安装部署到基本使用的各个方面。以下是这些视频的列表（建议两倍速播放，快速浏览一遍）：\n 夜莺项目介绍、资料地址等，必看 夜莺架构讲解 基础功能入门体验 安装 Categraf 对接夜莺 介绍 Categraf 常见插件 通知规则入门讲解  ","description":"夜莺监控（Nightingale）的入门视频教程，帮助用户快速上手使用夜莺。","title":"入门视频教程"},{"RelPermalink":"/zh/docs/install/pre-intro/","contents":"常用的安装方式有：\n 二进制方式部署 Docker compose 方式部署 Helm 方式部署  首推二进制方式，原因：\n 夜莺只有一个二进制文件，没有太多依赖，管理起来比较简单，通常大家对 systemd 都比较熟悉，直接用 systemd 管理夜莺的进程就行了 Docker compose 方式比二进制方式性能上稍差，而且 Docker compose 方式需要额外 Docker 相关的知识，还有国内网络导致的镜像拉取问题，有时也会比较难受 Helm 方式用于部署在 Kubernetes 中，但是监控系统是个 P0 级的系统，所有系统都挂了，监控也不能挂，所以如果部署在 Kubernetes 中，那当 Kubernetes 挂的时候，监控也会挂，此时，别的团队可能会来怼你，怨你怎么不提前规划好  不管是哪种安装方式，安装完成后，夜莺的默认用户名是 root，密码是 root.2020。夜莺默认监听的端口是 17000，边缘模式下用的 n9e-edge 端口是 19000。\n如果你用到了边缘模式，请务必阅读 边缘模式说明 章节。\n","description":"夜莺监控（Nightingale）支持多种不同的安装方式，包括二进制方式部署、Docker compose 方式部署、Helm 方式部署，到底选择哪一种？本文会给一些建议。","title":"安装前置说明"},{"RelPermalink":"/zh/docs/install/upgrade/","contents":"V6、V7、以及 V8 各个小版本之间的升级，方法相同。\n升级步骤 #  备份数据：在升级之前，备份 MySQL 数据库的内容、备份二进制、备份 etc 和 integrations 目录，以防万一，有了后路之后就可以放心大胆操作了 如果是二进制部署，替换二进制、替换 integrations 目录（可以直接把老的 integrations 目录挪走 mv integrations integrations.bak，直接使用新的 integrations 目录），配置文件可以 diff 一下新老配置，手工补齐一下差异点（实际上应该几乎不用修改配置文件，因为已经很久没有调整过了） 如果是容器部署的，拉取一下最新的镜像，配置文件 diff 一下，补齐差异点，再重启一下容器即可  关于 DB 表结构 # 如果夜莺所用的 DB 账号是有建表、改表权限的话，您不需要手动去修改 DB 表结构，夜莺会在启动时自动检查表结构是否需要升级，如果需要升级，则会自动改表。如果夜莺所用的 DB 账号没有建表、改表权限，则需要手工调整，近期的改动可以参考 migrate.sql。如果自动改表失败，请提 issue，我们会尽快跟进。\n理论上数据库同时支持 MySQL 和 Postgres，不过社区缺少 Postgres 的长期贡献者，所以建议优先使用 MySQL。\n","description":"夜莺监控（Nightingale）不同版本如何升级，应该注意什么，应该替换哪些文件","title":"升级"},{"RelPermalink":"/zh/docs/install/binary/","contents":"如果您尚未阅读《安装前置说明》 章节，请先阅读，之后再阅读本章节。\n下载 # 从 GitHub 下载最新版本，然后你会得到一个类似 n9e-${version}-linux-amd64.tar.gz 的压缩包。这是 X86 CPU 架构的发布包，如果你需要 ARM 架构的就下载那个 arm64 的包，没有提供 Windows 版本的发布包，因为夜莺监控是一个服务端项目，通常运行在 Linux 系统上。\n如果你想在 Windows 和 Mac 上运行夜莺也是 OK 的，只是需要你自行编译了，编译也比较简单，可以参考项目代码仓库下的 Makefile 文件内的逻辑。\n将下载的压缩包解压缩到 /opt/n9e 目录下。\nmkdir /opt/n9e \u0026amp;\u0026amp; tar zxvf n9e-${version}-linux-amd64.tar.gz -C /opt/n9e  单节点测试安装 # 这种模式下，只是为了测试，既不用依赖 MySQL 也不用依赖 Redis（实际是使用的 SQLite 和内存型 Redis：miniredis），启动比较简单，直接解压后启动即可。\n启动进程 # cd /opt/n9e \u0026amp;\u0026amp; nohup ./n9e \u0026amp;\u0026gt; n9e.log \u0026amp;  因为只是测试模式，就直接使用 nohup 启动了，生产环境肯定是需要使用 systemd 来托管 n9e 进程的。\n检查进程 # # check process is runing or not ss -tlnp|grep 17000  登录 # 打开浏览器访问 http://localhost:17000。默认用户名是 root，默认密码是 root.2020。\n 请把 localhost 替换成你的服务器 IP 地址。\n 单节点正式安装 # 生产环境中，我们建议使用 MySQL 和 Redis 来存储数据。\n修改配置 # 修改 /opt/n9e/etc/config.toml 配置文件，配置 MySQL 和 Redis 的连接信息。\nDB 部分：\n[DB] DBType = \u0026quot;mysql\u0026quot; DSN = \u0026quot;YourUsername:YourPassword@tcp(127.0.0.1:3306)/n9e_v6?charset=utf8mb4\u0026amp;parseTime=True\u0026amp;loc=Local\u0026quot;  Redis 部分：\n[Redis] Address = \u0026quot;127.0.0.1:6379\u0026quot; Password = \u0026quot;YourRedisPassword\u0026quot; RedisType = \u0026quot;standalone\u0026quot;  启动进程 # 启动 n9e 二进制即可，夜莺会自动创建数据库表。当然，这需要你的 DB 连接账号具备创建数据库表、改表的权限。\nnohup ./n9e \u0026amp;\u0026gt; n9e.log \u0026amp; ## 检查进程是否启动成功 ps -ef | grep n9e ## 检查端口是否正常在监听 ss -tlnp | grep 17000  nohup 可以快速启动验证，有问题查看 n9e.log 日志文件。\n使用 systemd 管理 # 生产环境建议使用 systemd 来管理 n9e 进程。下面是一个简单的 systemd 配置示例：\n[Unit] Description=Nightingale Monitoring Service After=network.target [Service] Type=simple ExecStart=/opt/n9e/n9e WorkingDirectory=/opt/n9e Restart=always RestartSec=5 StandardOutput=syslog StandardError=syslog SyslogIdentifier=n9e [Install] WantedBy=multi-user.target  将上述内容保存为 /etc/systemd/system/n9e.service，然后执行以下命令：\n## 设置夜莺进程开机自启动 sudo systemctl enable n9e ## 启动夜莺进程 sudo systemctl start n9e  登录 # 打开浏览器访问 http://localhost:17000。默认用户名是 root，默认密码是 root.2020。\n 请把 localhost 替换成你的服务器 IP 地址。\n 集群模式 # 在《夜莺架构设计》中已经讲解过集群模式的逻辑，这里不再赘述。从部署角度，只需要搞多个机器，每个机器部署一个 n9e 进程，配置好 MySQL 和 Redis 的连接信息即可。多个 n9e 进程复用同一套 MySQL 和 Redis，所以这多个 n9e 进程的配置文件是完全一样的。\n边缘模式 # 边缘模式的说明请一定先阅读：夜莺监控 - 边缘告警引擎架构详解！！！\n边缘模式要用到 n9e-edge 这个二进制，可以在 n9e-${version}-linux-amd64.tar.gz 压缩包里找到。n9e-edge 需要和中心端的 n9e 通信，同步告警规则，所以 n9e-edge 的配置文件中需要给出中心端 n9e 的连接信息。\n边缘集群 # 边缘机房的 n9e-edge 也可以部署多个实例组成集群，同一个集群内多个 n9e-edge 的配置文件也要保持一致，配置文件中的 EngineName 相同的实例，会被看做一套引擎集群的多个实例，取一个和中心端 n9e 不一样的名字。中心端的 n9e 的 EngineName 默认叫 default，边缘端 n9e-edge 的 EngineName 默认叫 edge。\n如果你有多个边缘机房，需要每个边缘机房的 n9e-edge 的 EngineName 都不一样，比如 edge1、edge2 等等。这样区分之后，才能做到不同的数据源指定不同的告警引擎。\nn9e-edge 启动 # 注意 n9e-edge 进程启动的时候要指定配置目录，而非指定配置文件，比如：\nnohup ./n9e-edge --configs etc/edge \u0026amp;\u0026gt; edge.log \u0026amp;  上面的 etc/edge 就是配置目录。要是写成 --configs etc/edge/edge.toml 就不对喽。\n","description":"使用二进制方式部署夜莺监控项目","title":"二进制部署"},{"RelPermalink":"/zh/docs/install/compose/","contents":"下载 # 参考二进制安装章节，下载夜莺监控的发布包，里面会有 Docker compose 相关的配置文件，也可以直接下载夜莺的源码仓库，里面也可以找到 Docker compose 的配置文件。\n启动 # 不管是下载发布包还是源码仓库，解压缩之后都会有一个 docker/compose-bridge 目录，进入这个目录执行 docker-compose up -d 命令即可（国内网络，镜像下载可能会失败，您需要自行解决科学上网的问题）。\nroot@ubuntu-linux-22-04-desktop:/opt/n9e/docker/compose-bridge# docker compose up -d [+] Running 5/5 ✔ Container victoriametrics Started 0.6s ✔ Container redis Started 0.6s ✔ Container mysql Started 0.6s ✔ Container nightingale Started 0.2s ✔ Container categraf Started 0.2s root@ubuntu-linux-22-04-desktop:/opt/n9e/docker/compose-bridge# docker compose ps NAME IMAGE COMMAND SERVICE CREATED STATUS PORTS categraf m.daocloud.io/docker.io/flashcatcloud/categraf:latest \u0026quot;/entrypoint.sh\u0026quot; categraf 2 minutes ago Up 3 seconds mysql mysql:8 \u0026quot;docker-entrypoint.s…\u0026quot; mysql 2 minutes ago Up 4 seconds 0.0.0.0:3306-\u0026gt;3306/tcp, :::3306-\u0026gt;3306/tcp, 33060/tcp nightingale m.daocloud.io/docker.io/flashcatcloud/nightingale:latest \u0026quot;sh -c /app/n9e\u0026quot; nightingale 2 minutes ago Up 3 seconds 0.0.0.0:17000-\u0026gt;17000/tcp, :::17000-\u0026gt;17000/tcp, 0.0.0.0:20090-\u0026gt;20090/tcp, :::20090-\u0026gt;20090/tcp redis redis:6.2 \u0026quot;docker-entrypoint.s…\u0026quot; redis 2 minutes ago Up 4 seconds 0.0.0.0:6379-\u0026gt;6379/tcp, :::6379-\u0026gt;6379/tcp victoriametrics victoriametrics/victoria-metrics:v1.79.12 \u0026quot;/victoria-metrics-p…\u0026quot; victoriametrics 2 minutes ago Up 4 seconds 0.0.0.0:8428-\u0026gt;8428/tcp, :::8428-\u0026gt;8428/tcp  Docker compose 启动了多个容器，分别是：\n victoriametrics：时序数据库，和 Prometheus 兼容，性能更好 redis：缓存数据库，夜莺使用 Redis 来存储 jwt token 和机器的心跳元信息 mysql：关系型数据库，夜莺使用 MySQL 来存储用户信息、告警规则、仪表盘等配置类数据 nightingale：夜莺监控的核心服务 categraf：监控数据采集器，负责采集主机的 CPU、内存、磁盘等指标数据  登录 # 使用浏览器访问 http://localhost:17000 打开夜莺监控的页面，默认用户名是 root，默认密码是 root.2020。\n 请把 localhost 替换成你的服务器 IP 地址。\n 集群模式 # 集群模式下，多个 n9e 要共享同一套 MySQL 和 Redis，所以就不能简单的使用默认的 Docker compose 了，您需要修改 etc-nightingale 目录下的 config.toml 配置文件，配置统一的 MySQL 和 Redis 的连接信息。\n边缘模式 # 边缘模式需要用到 n9e-edge 进程，不过社区并未提供 n9e-edge 的 Docker 镜像，所以边缘模式下还是需要使用二进制方式部署 n9e-edge 进程。边缘模式的详细说明请参考：夜莺监控 - 边缘告警引擎架构详解。\n","description":"使用 Docker Compose 方式部署夜莺监控项目，快速启动进程做测试。","title":"Docker Compose"},{"RelPermalink":"/zh/docs/install/helm/","contents":"你可以使用 n9e helm chart 在 Kubernetes 集群中运行夜莺。\n默认的夜莺用户名是 root，密码是 root.2020。\n不过，我们不建议您把夜莺部署到 Kubernetes 中，因为监控系统太过重要，如果 Kubernetes 集群出现问题，可能会导致监控系统无法正常工作。而此时您可能希望通过监控数据排查 Kubernetes 的问题，导致循环依赖。尤其是，其他团队此时想使用监控系统发现用不了，可能会来怼你。\n","description":"使用 Helm chart 安装夜莺监控（Nightingale），将夜莺监控部署在 Kubernetes 中。","title":"Helm"},{"RelPermalink":"/zh/docs/install/configuration/","contents":"中心端 n9e 的配置文件是 etc/config.toml，边缘告警引擎 n9e-edge 的配置文件是 etc/edge/edge.toml。这里我们先分块讲解 n9e 的配置文件。\nGlobal # [Global] RunMode = \u0026quot;release\u0026quot;  这是夜莺研发人员用的配置项，普通用户不需要关心，永远保持 release 即可。\nLog # [Log] # stdout, stderr, file Output = \u0026quot;stdout\u0026quot; # log write dir Dir = \u0026quot;logs\u0026quot; # log level: DEBUG INFO WARNING ERROR Level = \u0026quot;DEBUG\u0026quot; # # rotate by time # KeepHours = 4 # # rotate by size # RotateNum = 3 # # unit: MB # RotateSize = 256   Output：日志输出方式，支持 stdout、stderr、file，只有在 file 模式下才会把日志输出到文件，才会用到下面的其他配置项 Dir：日志文件的存放目录 Level：日志级别，支持 DEBUG、INFO、WARNING、ERROR KeepHours：日志文件保留时间，单位小时。日志既可以按照时间切分，也可以按照大小切分，如果按照时间切分，就用这个配置项，每小时一个日志文件，如果按照大小切分，就用下面两个配置项 RotateNum：日志文件保留数量 RotateSize：日志文件大小，单位 MB  HTTP # [HTTP] # http listening address Host = \u0026quot;0.0.0.0\u0026quot; # http listening port Port = 17000 # https cert file path CertFile = \u0026quot;\u0026quot; # https key file path KeyFile = \u0026quot;\u0026quot; # whether print access log PrintAccessLog = false # whether enable pprof PProf = true # expose prometheus /metrics? ExposeMetrics = true # http graceful shutdown timeout, unit: s ShutdownTimeout = 30 # max content length: 64M MaxContentLength = 67108864 # http server read timeout, unit: s ReadTimeout = 20 # http server write timeout, unit: s WriteTimeout = 40 # http server idle timeout, unit: s IdleTimeout = 120   Host：HTTP 服务监听地址，一般都是 0.0.0.0，表示监听所有网卡 Port：HTTP 服务监听端口 CertFile：HTTPS cert 文件路径 KeyFile：HTTPS key 文件路径 PrintAccessLog：是否打印访问日志 PProf：是否开启 pprof，如果开启的话，在 /api/debug/pprof/ 下可以看到 pprof 的信息 ExposeMetrics：是否暴露 Prometheus 的 /metrics 接口，用于暴露夜莺自身的监控指标 ShutdownTimeout：HTTP 服务优雅关闭超时时间，单位秒 MaxContentLength：HTTP 请求最大长度，单位字节 ReadTimeout：HTTP 读超时时间，单位秒 WriteTimeout：HTTP 写超时时间，单位秒 IdleTimeout：HTTP 空闲超时时间，单位秒  HTTP.ShowCaptcha # [HTTP.ShowCaptcha] Enable = false   Enable：是否开启验证码功能  HTTP.APIForAgent # [HTTP.APIForAgent] Enable = true # [HTTP.APIForAgent.BasicAuth] # user001 = \u0026quot;ccc26da7b9aba533cbb263a36c07dcc5\u0026quot;   Enable：是否开启 Agent 的 API 接口，正常来讲必然是要开启的，所以这个配置项一般都是 true BasicAuth：Agent 的 API 接口支持 BasicAuth，这里配置 BasicAuth 用户名和密码，一般内网通信的话，不需要配置 BasicAuth，如果是公网通信的话，建议配置 BasicAuth，而且，密码一定不要使用默认的，容易被攻击 上例中 user001 是 BasicAuth 的用户名，ccc26da7b9aba533cbb263a36c07dcc5 BasicAuth 的密码，如果想要配置多个用户，可以继续添加，比如：  [HTTP.APIForAgent.BasicAuth] user001 = \u0026quot;ccc26da7b9aba533cbb263a36c07dcc5\u0026quot; user002 = \u0026quot;d4f5e6a7b8c9d0e1f2g3h4i5j6k7l8m9\u0026quot;  注意：如果你配置了 BasicAuth，那么 Agent 端的 n9e 配置文件中也需要配置相应的用户名和密码，否则 Agent 端无法连接到中心 n9e。\n默认配置里 Enable 设置为 true，HTTP.APIForAgent.BasicAuth 为空，表示启用面向 Agent 的那些 API 接口，同时不启用 BasicAuth。\nHTTP.APIForService # [HTTP.APIForService] Enable = false [HTTP.APIForService.BasicAuth] user001 = \u0026quot;ccc26da7b9aba533cbb263a36c07dcc5\u0026quot;   Enable：是否开启 Service 的 API 接口，边缘告警引擎 n9e-edge 和中心 n9e 通信就依赖中心端的这部分接口，所以如果你用到了 n9e-edge，就需要启用，即设置为 true BasicAuth：Service 的 API 接口支持 BasicAuth，这里配置 BasicAuth 用户名和密码，一般内网通信的话，不需要配置 BasicAuth，如果是公网通信的话，建议配置 BasicAuth，而且，密码一定一定不要使用默认的，容易被攻击 上例中 user001 是 BasicAuth 的用户名，ccc26da7b9aba533cbb263a36c07dcc5 BasicAuth 的密码，如果想要配置多个用户，可以继续添加，比如：  [HTTP.APIForService.BasicAuth] user001 = \u0026quot;ccc26da7b9aba533cbb263a36c07dcc5\u0026quot; user002 = \u0026quot;d4f5e6a7b8c9d0e1f2g3h4i5j6k7l8m9\u0026quot;  注意：如果你配置了 BasicAuth，那么边缘告警引擎 n9e-edge 的配置文件中也需要配置相应的用户名和密码，否则 n9e-edge 无法连接到中心 n9e。 默认配置里 Enable 设置为 false，表示不启用面向其他 Service 的那些 API 接口，此时 n9e-edge 也无法连接到中心 n9e。\nHTTP.JWTAuth # [HTTP.JWTAuth] # unit: min AccessExpired = 1500 # unit: min RefreshExpired = 10080 RedisKeyPrefix = \u0026quot;/jwt/\u0026quot;  夜莺的认证使用 jwt 的方式，这里配置 jwt 的过期时间，单位分钟，AccessExpired 是 access token 的过期时间，RefreshExpired 是 refresh token 的过期时间。jwt 机制下这俩 token 的作用可以问一下 GPT，这里不再赘述。夜莺会把部分 jwt 相关的信息存到 redis 中，RedisKeyPrefix 是 redis 的 key 前缀，一般不用改。\nHTTP.ProxyAuth # [HTTP.ProxyAuth] # if proxy auth enabled, jwt auth is disabled Enable = false # username key in http proxy header HeaderUserNameKey = \u0026quot;X-User-Name\u0026quot; DefaultRoles = [\u0026quot;Standard\u0026quot;]  如果你想把夜莺嵌入到你自己的系统中，可以考虑使用 ProxyAuth 方式，类似 Grafana 的 ProxyAuth。相当于用户在你自己的系统中登录，你可以拿到用户名，然后把用户名放到 X-User-Name 这个 Header 中传给夜莺，夜莺就会认为这个用户已经登录了。DefaultRoles 是默认角色，如果你不传角色，夜莺就会把这个用户当做 Standard 角色处理。\n实际上据我观察，目前并没有社区用户使用这个功能，所以请慎重使用。\nHTTP.RSA # [HTTP.RSA] OpenRSA = false  夜莺在登录的时候，用户密码是明文传输的，如果夜莺站点是 HTTPS 的倒是还好，如果是 HTTP 的，就建议开启 RSA 加密，这样用户密码就不会明文传输了。\nDB # [DB] # mysql postgres sqlite DBType = \u0026quot;sqlite\u0026quot; # postgres: host=%s port=%s user=%s dbname=%s password=%s sslmode=%s # postgres: DSN=\u0026quot;host=127.0.0.1 port=5432 user=root dbname=n9e_v6 password=1234 sslmode=disable\u0026quot; # mysql: DSN=\u0026quot;root:1234@tcp(localhost:3306)/n9e_v6?charset=utf8mb4\u0026amp;parseTime=True\u0026amp;loc=Local\u0026quot; DSN = \u0026quot;n9e.db\u0026quot; # enable debug mode or not Debug = false # unit: s MaxLifetime = 7200 # max open connections MaxOpenConns = 32 # max idle connections MaxIdleConns = 8  DBType 和 DSN 是最为关键的，两个配置联动。DBType 支持 mysql、postgres、sqlite 三种数据库，DSN 是数据库连接信息，如果是 sqlite，就是数据库文件路径，如果是 mysql 或 postgres，就是数据库连接信息。\n夜莺从 v8 版本开始，默认 DBType 设置的是 sqlite，这样方便用户快速体验，不需要安装数据库。但是，生产环境中，还请使用 mysql 或 postgres。\nPostgres 和 MySQL 的 DSN 配置可以参考注释中的例子。其他配置是数据库连接相关的配置，根据自己的环境来修改即可。一般中小型环境，MaxOpenConns 设置为 32，MaxIdleConns 设置为 8 就可以了。\nRedis # [Redis] # standalone cluster sentinel miniredis RedisType = \u0026quot;miniredis\u0026quot; # address, ip:port or ip1:port,ip2:port for cluster and sentinel(SentinelAddrs) Address = \u0026quot;127.0.0.1:6379\u0026quot; # Username = \u0026quot;\u0026quot; # Password = \u0026quot;\u0026quot; # DB = 0 # UseTLS = false # TLSMinVersion = \u0026quot;1.2\u0026quot; # Mastername for sentinel type # MasterName = \u0026quot;mymaster\u0026quot; # SentinelUsername = \u0026quot;\u0026quot; # SentinelPassword = \u0026quot;\u0026quot;  Redis 除了用于存储 jwt 相关的登录认证信息，还用于存放机器的心跳上报的 metadata。夜莺中支持的机器失联告警规则，就是根据 Redis 中机器的心跳时间来判断的，如果很长时间没有心跳了，就认为机器失联了。\n 如果 Redis 响应较慢，可能会导致失联告警的误判。即机器明明是存活的，但是 Redis 中的心跳信息没有及时更新，最终导致夜莺误判机器失联了。V8.beta11 版本开始，增加了 Redis 操作相关的监控指标，需要关注这些指标，及时发现 Redis 响应慢的问题。\n RedisType 支持 standalone、cluster、sentinel、miniredis 四种，从夜莺 v8 版本开始，夜莺默认使用 miniredis，这样方便用户快速体验，不需要安装 Redis。但是，生产环境中，还请使用其他模式。\nAddress 是 Redis 的连接地址，根据 RedisType 的不同，配置方式也不同：\n standalone：RedisType 是 standalone 时，Address 就是 Redis 实例的地址，格式是 ip:port cluster：RedisType 是 cluster 时，Address 就是 Redis 集群的地址，格式是 ip1:port,ip2:port sentinel：RedisType 是 sentinel 时，Address 就是 Redis Sentinel 的地址，格式是 ip1:port,ip2:port，哨兵模式下，还需要配置 MasterName、SentinelUsername、SentinelPassword UseTLS：是否使用 TLS TLSMinVersion：TLS 最小版本，只有在 UseTLS 为 true 时才生效  Alert # 夜莺从某个版本开始，为了降低部署复杂度，把 webapi 和告警引擎模块合并在一起了，Alert 这里的配置项是告警引擎的配置项。\nAlert.Heartbeat # [Alert.Heartbeat] # auto detect if blank IP = \u0026quot;\u0026quot; # unit ms Interval = 1000 EngineName = \u0026quot;default\u0026quot;   IP：告警引擎的 IP 地址，如果是空的话，夜莺会自动探测。每个告警引擎都会写心跳信息到 MySQL，这样一来，每个告警引擎都知道所有活着的告警引擎列表，进而就可以做告警规则的分片处理了。比如有 100 条告警规则，有两个 n9e 组成集群，那么每个 n9e 大概会处理 50 条告警规则，当其中一个告警引擎挂掉的时候，另一个告警引擎就会接管这 100 条告警规则。 Interval：心跳间隔，单位毫秒 EngineName：告警引擎的名字，一般中心端就维持 default 即可，边缘告警引擎 n9e-edge 的话，可以自定义 EngineName，比如 edge1、edge2 等。相同 EngineName 的告警引擎会被认为是一个集群。  Center # 中心端 n9e 的特有配置，边缘告警引擎 n9e-edge 没有这些配置项。即老版本的 n9e-webapi 相关的特有的配置。\n[Center] MetricsYamlFile = \u0026quot;./etc/metrics.yaml\u0026quot; I18NHeaderKey = \u0026quot;X-Language\u0026quot; [Center.AnonymousAccess] PromQuerier = true AlertDetail = true   MetricsYamlFile：指标配置文件路径，你在快捷视图里看到的指标的解释说明就是来自这个配置文件。后来上线了指标视图，这个配置文件就不那么重要了，甚至后面计划下掉快捷视图的功能。 I18NHeader：这是一个研发人员用的配置项，普通用户不需要关心。 Center.AnonymousAccess：匿名访问相关的配置项。PromQuerier 是指是否允许匿名查询各数据源的接口，AlertDetail 是指是否允许匿名查看告警详情。内网环境可以开启，公网环境一定要关闭。  仪表盘有个公开访问的功能，甚至可以设置为不需要登录就可以访问，但是这个前提是 PromQuerier 需要设置为 true，即如果 PromQuerier = false，那么即使设置了仪表盘为公开访问，也是需要登录的。\nPushgw # 夜莺虽然不直接存储监控数据，但是提供了多种接收监控数据的接口，比如 Prometheus remote write 协议的接口、OpenTSDB 协议的接口等。接收到数据之后，夜莺会把监控数据转发给后端时序库，所以这里夜莺就相当于一个 Pushgateway，跟 Pushgateway 相关的配置项就在 Pushgw 下面了。\n[Pushgw] # use target labels in database instead of in series LabelRewrite = true ForceUseServerTS = true   LabelRewrite：夜莺有个机器管理的菜单，可以给机器打标签，并且这些标签会附加到机器相关的时序数据里。但是，如果上报的数据中有个标签和机器管理里的标签冲突了，以哪个为准呢？如果 LabelRewrite 为 true，就以机器管理里的标签为准，否则以上报的标签为准。 ForceUseServerTS：是否强制使用服务端的时间戳，来覆盖接收到的监控数据的时间戳。之前没有这个配置项，由于很多公司的机器时间没有校准导致各种困惑，所以夜莺提供了这个配置，建议开启，统一使用服务端的时间戳得了。  Pushgw.DebugSample # [Pushgw.DebugSample] ident = \u0026quot;xx\u0026quot; __name__ = \u0026quot;cpu_usage_active\u0026quot;  这个配置是为了调试、排查问题用的。这个配置其实是一个监控指标的过滤条件，如果上报给夜莺的指标符合这个过滤条件，就会打印到日志中。一般不需要配置，注释掉即可。\nPushgw.WriterOpt # [Pushgw.WriterOpt] QueueMaxSize = 1000000 QueuePopSize = 1000 QueueNumber = 0  这部分配置默认是注释的，因为正常来讲，用户是不需要关注的，如果夜莺接收到太多数据，在内存里拥塞了，最终丢了指标，此时需要考虑调整这里的配置。\n夜莺会在内存里创建 QueueNumber 个队列，收到监控数据之后，就会把数据放到这些队列中，QueueNumber 的默认配置是 0，表示不指定具体数量，按照 CPU 核数来创建队列。每个队列的最大容量是 QueueMaxSize，默认是 1000000，表示每个队列最多可以存储 100 万条数据。\n然后每个队列对应一个 goroutine，这个 goroutine 每次从队列中取出指标的数量是 QueuePopSize，默认是 1000，表示每次从队列中取出 1000 条数据，作为一个批次写入到后端时序库。这样做的好处是可以充分利用多核 CPU 的性能。所以，QueueNumber 的数量，本质就等于并发写入后端时序库的并发量。\nPushgw.Writers # 这里是配置后端时序库的 remote write 写入地址，所有支持 remote write 协议的时序库都可以配置在这里。一般来讲，只需要配置一个即可，如果你想同时写入多个时序库，可以配置多个。\n[[Pushgw.Writers]] Url = \u0026quot;http://127.0.0.1:9090/api/v1/write\u0026quot; BasicAuthUser = \u0026quot;xx\u0026quot; BasicAuthPass = \u0026quot;xx\u0026quot; [[Pushgw.Writers]] Url = \u0026quot;http://127.0.0.1:8482/api/v1/write\u0026quot; BasicAuthUser = \u0026quot;xx\u0026quot; BasicAuthPass = \u0026quot;xx\u0026quot;   Url：时序库的 remote write 写入地址 BasicAuth：如果时序库需要 BasicAuth 认证，可以配置 BasicAuth 的用户名和密码 Headers：如果时序库需要额外的 Header，可以配置在这里 Timeout：写入超时时间，单位是毫秒 DialTimeout：连接超时时间，单位是毫秒  Pushgw.Writers.WriteRelabels # 写往时序库的数据，在写入之前可以做 relabel 的操作，这个配置项就是 relabel 的配置项。和 Prometheus 的 relabel 配置项类似，只不过 Prometheus 用的 yaml 格式，夜莺用的 toml 格式。\nIbex # 故障自愈引擎 Ibex 的配置项。即远程执行脚本的那个功能。原本这个功能是单独拆开的一个模块叫 ibex，后来合并到 n9e 里了，所以这个配置项也在 n9e 里。\n[Ibex] Enable = true RPCListen = \u0026quot;0.0.0.0:20090\u0026quot;   Enable：是否开启 Ibex 服务端功能 RPCListen：Ibex 的 RPC 服务监听地址  n9e-edge 的配置 # 边缘告警引擎 n9e-edge 的配置文件是 etc/edge/edge.toml，大部分配置和中心 n9e 的配置相同。更多信息可以参考这篇文章：《夜莺监控 - 边缘告警引擎架构详解》。\n","description":"讲解夜莺监控的配置文件，对各个配置项的作用做详细讲解","title":"配置讲解"},{"RelPermalink":"/zh/docs/agent/intro/","contents":"夜莺作为一个告警引擎，不需要和采集器整合，直接对接各类数据源，根据用户配置的告警规则，查询数据源的数据，然后做告警判定。\n即：如果你们已经采集了各类监控数据并存储到时序库中了，那就把时序库作为数据源配置到夜莺中，夜莺就可以直接查询时序库中的数据了。不需要用到本章提到的各类采集器。\n但是很多新用户并未构建自己的采集能力，因此我们提供了一些采集器的对接方案，方便用户快速上手。不过夜莺仍然不提供存储能力，这些采集器采集了数据推给夜莺，夜莺再把数据转存到时序库。\n夜莺的配置文件 etc/config.toml 中有个 [[Pushgw.Writers]] 的部分，就是用来配置时序库的地址的。夜莺收到数据后会把数据转发到这些地址，走的是 Prometheus remote write 协议。\n","description":"夜莺监控（Nightingale）可以对接各类采集器，比如 Categraf、Telegraf、Alloy、Datadog-agent 等，这些采集器将监控数据推送给夜莺，夜莺转存到时序库。","title":"前置说明"},{"RelPermalink":"/zh/docs/agent/categraf/","contents":"Categraf 是一个可以采集指标和日志的代理。Categraf 使用 prometheus remote write 作为指标数据推送协议，因此可以将指标推送到夜莺，日志的话，Categraf 是对接写给 Kafka。\n配置 # Categraf 的配置文件: conf/config.toml\n[writer_opt] # default: 2000 batch = 2000 # channel(as queue) size chan_size = 10000 [[writers]] url = \u0026quot;http://N9E:17000/prometheus/v1/write\u0026quot; # Basic auth username basic_auth_user = \u0026quot;\u0026quot; # Basic auth password basic_auth_pass = \u0026quot;\u0026quot; # timeout settings, unit: ms timeout = 5000 dial_timeout = 2500 max_idle_conns_per_host = 100 [heartbeat] enable = true # report os version cpu.util mem.util metadata url = \u0026quot;http://N9E:17000/v1/n9e/heartbeat\u0026quot; # interval, unit: s interval = 10 # Basic auth username basic_auth_user = \u0026quot;\u0026quot; # Basic auth password basic_auth_pass = \u0026quot;\u0026quot; ## Optional headers # headers = [\u0026quot;X-From\u0026quot;, \u0026quot;categraf\u0026quot;, \u0026quot;X-Xyz\u0026quot;, \u0026quot;abc\u0026quot;] # timeout settings, unit: ms timeout = 5000 dial_timeout = 2500 max_idle_conns_per_host = 100  我们建议您使用 Categraf 采集机器的 CPU、内存等常规指标，因为 Categraf 和夜莺的对接最为丝滑。Categraf 会自动采集机器的元信息并且和夜莺对接提供告警自愈能力。\n至于 MySQL、Redis、Oracle、ElasticSearch、Kafka 等各类监控对象的数据采集，您也可以使用 Categraf，也可以使用您熟悉的其他采集器。\n边缘模式 # 如果您采用了夜莺的边缘模式，即在某个边缘机房部署了 n9e-edge 组件，那边缘机房的 Categraf 就可以直接将数据推送到边缘机房的 n9e-edge 组件上，不需要推送到中心机房的夜莺。即：Categraf 配置文件中的 writer 和 heartbeat 的两个 url 都改为边缘机房的 n9e-edge 地址即可。\n","description":"使用 Categraf 作为夜莺监控的采集器，采集指标、日志等数据，和夜莺项目丝滑对接。Categraf 是一个开源的采集器，支持 Prometheus remote write 协议。通过 Prometheus remote write 协议，Categraf 可以将指标数据推送到夜莺监控。Categraf 还可以采集日志数据，并将其写入 Kafka。","title":"Categraf"},{"RelPermalink":"/zh/docs/agent/telegraf/","contents":"简介 # Telegraf 是一个用于收集、处理、聚合和写入指标的 agent，来自 InfluxData 公司。\nTelegraf 支持多种输出插件，我们可以使用 opentsdb 或 prometheusremotewrite 插件将指标发送到夜莺。下面是以 opentsdb 为例的配置。\n安装 # #!/bin/sh version=1.20.4 tarball=telegraf-${version}_linux_amd64.tar.gz wget https://dl.influxdata.com/telegraf/releases/$tarball tar xzvf $tarball mkdir -p /opt/telegraf cp -far telegraf-${version}/usr/bin/telegraf /opt/telegraf cat \u0026lt;\u0026lt;EOF \u0026gt; /opt/telegraf/telegraf.conf [global_tags] [agent] interval = \u0026quot;10s\u0026quot; round_interval = true metric_batch_size = 1000 metric_buffer_limit = 10000 collection_jitter = \u0026quot;0s\u0026quot; flush_interval = \u0026quot;10s\u0026quot; flush_jitter = \u0026quot;0s\u0026quot; precision = \u0026quot;\u0026quot; hostname = \u0026quot;\u0026quot; omit_hostname = false [[outputs.opentsdb]] host = \u0026quot;http://127.0.0.1\u0026quot; port = 17000 http_batch_size = 50 http_path = \u0026quot;/opentsdb/put\u0026quot; debug = false separator = \u0026quot;_\u0026quot; [[inputs.cpu]] percpu = true totalcpu = true collect_cpu_time = false report_active = true [[inputs.disk]] ignore_fs = [\u0026quot;tmpfs\u0026quot;, \u0026quot;devtmpfs\u0026quot;, \u0026quot;devfs\u0026quot;, \u0026quot;iso9660\u0026quot;, \u0026quot;overlay\u0026quot;, \u0026quot;aufs\u0026quot;, \u0026quot;squashfs\u0026quot;] [[inputs.diskio]] [[inputs.kernel]] [[inputs.mem]] [[inputs.processes]] [[inputs.system]] fielddrop = [\u0026quot;uptime_format\u0026quot;] [[inputs.net]] ignore_protocol_stats = true EOF cat \u0026lt;\u0026lt;EOF \u0026gt; /etc/systemd/system/telegraf.service [Unit] Description=\u0026quot;telegraf\u0026quot; After=network.target [Service] Type=simple ExecStart=/opt/telegraf/telegraf --config telegraf.conf WorkingDirectory=/opt/telegraf SuccessExitStatus=0 LimitNOFILE=65535 StandardOutput=syslog StandardError=syslog SyslogIdentifier=telegraf KillMode=process KillSignal=SIGQUIT TimeoutStopSec=5 Restart=always [Install] WantedBy=multi-user.target EOF systemctl daemon-reload systemctl enable telegraf systemctl restart telegraf systemctl status telegraf  ","description":"使用 Telegraf 作为夜莺监控（Nightingale）的采集器，Telegraf 来自 InfluxData 公司，是一个用于收集、处理、聚合和写入指标的 agent。Telegraf 支持多种输出插件，我们可以使用 opentsdb 或 prometheusremotewrite 插件将指标发送到夜莺。","title":"Telegraf"},{"RelPermalink":"/zh/docs/agent/datadog-agent/","contents":"配置 # Datadog-agent 的配置文件路径为 /etc/datadog-agent/datadog.yaml，修改配置文件中的 dd_url 项。\ndd_url: http://nightingale-address/datadog  nightingale-address 为你的夜莺地址。\n重启 # 重启 Datadog-Agent。\nsystemctl restart datadog-agent  ","description":"使用 Datadog-Agent 作为夜莺监控（Nightingale）的采集器，Datadog-Agent 是 Datadog 公司提供的一个开源的监控代理，支持多种数据采集方式。通过配置 Datadog-Agent，可以将指标数据推送到夜莺监控。","title":"Datadog-Agent"},{"RelPermalink":"/zh/docs/usage/datasource/","contents":"夜莺支持对接各类数据源，前期支持的数据源，比如 Prometheus、VictoriaMetrics、ElasticSearch 等，既支持查询看图，也支持告警。后面随着项目发展，夜莺定位为一个告警引擎，所以新对接的数据源，比如 ClickHouse、MySQL、Postgres 等，都是只支持告警，不支持查询看图。\n不管是要查看数据源里的数据，还是对数据源里的数据进行告警，都需要先配置数据源。在 集成中心-数据源 中添加数据源，选择对应的数据源类型，填写数据源的地址、用户名、密码等信息，点击保存即可。\n配置数据源时，除了要填写数据源的连接地址，另一个关键点是要选择关联的告警引擎，如果你的数据源是在边缘机房的，并且为边缘机房搭建了专属的 n9e-edge，那么就选择对应的 n9e-edge 作为关联的告警引擎。\n数据源配置中，表单各项基本都对应有 tooltip（就是各个 form 表单旁边的小问号 icon，鼠标放上去可以看到用法提示），这里就不再赘述了。\n配置完了数据源之后，可以到即时查询页面查询一下时序库的数据，如果能查到数据，则表明数据源的配置是 OK 的。\n常见问题 # 1. 夜莺的配置文件 config.toml 中已经配置了数据源的 writer 地址，是否还需要在页面上重复配置？\n是的。config.toml 中的 writer 地址，是用于数据转发链路，而页面上的数据源配置，是用于查询和告警的。两者是不同的概念。另外，writer 地址应该是一个 remote write 地址，而页面上的数据源配置通常是数据源的基准地址。另外，很多用户也没有使用夜莺转发监控指标，所以也就没有配置 config.toml 中的 writer 地址，仅配置了页面上的数据源。\n2. 我想采用边缘模式对边缘机房的时序库做告警，但是中心端的 n9e 无法连通边缘的时序库，这种情况还能用夜莺做统一告警吗？\n可以。这类边缘时序库，仍然需要在页面上添加，添加的时候选择「保存」而非选择「测试并保存」，这样一来，中心端的夜莺就不会校验连通性，可以直接保存成功。同时，数据源配置的时候，要配置上时序库内网地址，告警引擎选择和时序库能连通的 n9e-edge 告警引擎，届时 n9e-edge 会使用时序库内网地址进行查询和告警。\n这种情况的边缘时序库，仍然可以告警，但是在夜莺的页面上就没法查询其数据了。因为夜莺的页面查询数据是通过中心端的 n9e 进行的，而中心端的 n9e 无法连通边缘时序库，所以无法查询。\n","description":"夜莺监控（Nightingale）支持对接各类数据源，包括 Prometheus、ElasticSearch 和 Grafana Loki 等。通过配置数据源，夜莺可以查询展示这些数据源中的监控数据，也可以对这些数据源中的数据进行告警。","title":"数据源"},{"RelPermalink":"/zh/docs/usage/ad-hoc/","contents":"夜莺支持 Ad-hoc 查询，可以在界面上直接查询数据源的数据。菜单入口在 数据查询 下面，选择 指标 可以查询指标数据，选择 日志 可以查询日志数据。\n指标查询 # 下面是一个指标查询样例：\n这个页面和 Prometheus 的 graph 页面类似，支持查询时序指标数据。当然也做了一些增强，增加了内置指标、历史记录等等一些能力。上图中是一个 range vector，且使用的 Table 视图，此时夜莺会多做一步，计算各个数据的时间差，就是最右侧那个 +15，方便我们排查是否有数据丢失的情况，比如大都是规律的时间差，和采集频率一致，但是突然发现有两个时间差比较大，是好几倍的采集频率，那就表示有数据采集或传输失败了。\n 经常被新手询问的问题是，这个页面一进来为啥看不到任何数据。这是符合预期的，需要先输入 Promql 进行查询，然后才能看到数据。而非是说一进来这个页面就可以看到数据。Promql 是使用 Prometheus、Nightingale 的前置知识，建议先学习 Promql 的基础知识，资料参考：《Promql系列教程》\n 如果使用的采集器是 Categraf，可以查询 cpu_usage_active 这个指标，如果能查到，说明数据源配置是 OK 的。如果使用的采集器是 Node-Exporter，那可以查询 node_load1 这个指标，如果能查到，说明数据源配置是 OK 的。\n日志查询 # 日志查询主要是支持的 ElasticSearch 数据源，配置 ElasticSearch 数据源的时候，有个版本字段很多人会有困惑，如果你是 6.x 版本的 ElasticSearch，那么就选择 6.0+ 版本，如果是 7.x 版本的 ElasticSearch，就选择 7.0+ 版本，如果是更高版本，也直接选择 7.0+ 版本，如果遇到不兼容的情况，提 issues 反馈即可。\n配置完了数据源之后，可以在 数据查询-日志 页面进行查询，下面是一个日志查询样例：\n和 Kibana 的日志查询页面很像，夜莺这里既可以支持按照索引模式查询，也可以不创建索引模式，直接查询索引（支持通配符），不过直接查询索引不是一个好的实践，后面可能会下掉这个功能。另外查询语法支持 KQL 和 Lucene（即 query string）两种，对于 ElasticSearch 的玩家而言，这些概念都不陌生，这里就不赘述了。\n数据源配置成功之后，下一步就可以进入重头戏了，配置告警规则，体验夜莺的告警引擎能力。\n","description":"夜莺监控（Nightingale）支持 Ad-hoc 查询，可以在界面上直接查询数据源的数据。既可以查询时序指标数据，也可以查询日志数据。","title":"即时查询"},{"RelPermalink":"/zh/docs/usage/metric-alerting/","contents":"夜莺监控（Nightingale）把告警分成告警+通知两个部分，告警指的是通过规则，周期性判定，最终产生告警事件，通知指的是告警事件的后续 Pipeline 和通知流程。本章节先介绍告警部分，最终能产生告警事件咱就算成功。\n告警原理 # 夜莺支持两个告警模式，普通模式和高级模式（高级模式暂未开源，后面也计划开源）：\n 普通模式：在 Promql 中配置告警阈值，查询条件 和 阈值设置 在一起，没有特殊需求的话就使用普通模式即可，这个模式就和 Prometheus 的告警逻辑是一样的，性能比较好。不过告警恢复时要想拿到恢复时的值稍微麻烦点 高级模式：查询条件 和 阈值设置 分开，如果有多个查询条件需要做加减乘除计算，可以使用高级模式，在告警事件的现场值中会将每个查询条件的值展示出来，在告警恢复时也可以轻松拿到恢复时的值  普通模式的原理 # 普通模式下，夜莺会根据用户配置的执行频率，周期性查询数据源，查询条件就是用户配置的 Promql，查询方式是 instant query，即调用的数据源的 /api/v1/query 接口，查到几条数据就生成几条告警事件。比如 Promql 是 cpu_usage_active \u0026gt; 80，夜莺拿着这个 Promql 去查询时序库，时序库返回的结果肯定是 CPU 利用率大于 80% 的那些数据点，都是触发了阈值的数据点，所以夜莺应该生成告警事件。\n如果用户在告警规则里配置了大于 0 的 持续时长，此时就会更复杂一些，夜莺会在持续时长内按照执行频率多次执行查询，每次都查到某个数据才生成告警；如果 持续时长 置为 0，表示只要有一次查询到数据，就生成告警。\n如果之前生成了告警事件，后来再次查询时发现没有数据了，此时就会生成恢复事件，毕竟查不到数据了嘛，就说明时序库里没有数据达到阈值条件了，故而时序库不再返回任何数据。针对告警恢复，还有一个高级配置叫 留观时长，表示在恢复事件生成后，夜莺会继续观察一段时间，如果在留观时长内又查询到数据了，就不会生成恢复事件（继续维持告警状态）；如果留观时长内每次都没有查询到数据了，才会最终生成恢复事件。\n从上文分析来看，告警恢复时，时序库不返回任何数据，所以夜莺无法拿到恢复时的值，这也是很多用户在使用普通模式时的一个痛点。夜莺为此设计了一个方式来解决这个问题，具体可以参考这篇文章《告警恢复时如何拿到恢复时的值？》。\n高级模式的原理 # 高级模式下，阈值条件不放到 Promql 里，Promql 中只写过滤条件，比如 Promql：\ncpu_usage_active{cpu=\u0026quot;cpu-total\u0026quot;}  这样一来，夜莺拿着这个 Promql 去查询时序库，时序库每次都是返回 CPU 利用率的所有数据点（性能稍差），然后夜莺再根据用户配置的 阈值判断 规则，对返回的数据在内存里进行判断，如下图所示：\n高级模式和普通模式，关键区别是阈值判定是在 Promql 里进而交给时序库来做，还是在夜莺的内存里来做。高级模式下，如果触发了恢复事件，恢复事件里的 TriggerValue 会自动填充为恢复时刻的值，相比普通模式，获取恢复时的值更简单。\n高级模式下，还会出现一个 数据缺失 的判断逻辑，俗称 NoData 告警，夜莺的行为是：周期性查询数据源，查到了数据，就塞到内存里，下次再查询，还查到了，那万事大吉，如果下次再查时，某条数据没查到，那这条数据就要告警。\n功能说明 # 了解了原理，我们就来配置一个告警规则，演示一下如何使用夜莺的指标告警功能。\n创建入口 # 菜单入口在 告警-规则管理-告警规则，如下图所示：\n首先要选中左侧的业务组，如果没有任何业务组需要先自行创建一个，因为告警规则可能会很多，需要分门别类管理，也需要权限管控，所以告警规则是和业务组绑定的。\n 业务组是一个扁平的列表，但是可以渲染成树形结构。只要在业务组名称中使用 / 符号，就可以渲染成树形结构。比如 DBA/MySQL 和 DBA/Redis，就会渲染成上图的树形样式。当然，前提是要在 系统配置-站点配置 菜单中设置业务组展示模式为树形，同时设置业务组分隔符为 /。\n 下面我们着重讲解一下告警规则的各个配置项的含义。\n 🟢 提示：规则配置页面，各个 form 表单旁边都有 tooltip（就是小问号 icon，鼠标放上去可以看到用法提示），请一定要记得看哪。\n 基础配置 #  规则名称：告警规则的名称，比如“机器负载高”，规则名称中可以引用变量，比如 {{ $labels.instance }}，但极为不建议这样做，因为这样会导致最终生成的告警事件名称各异，想要对告警事件做聚合查看时非常不方便。 附加标签：在这里配置的附加标签，会追加到生成的告警事件的标签中，后续可以用于告警事件的聚合和过滤。 备注：对告警规则更加详细的描述，支持配置 $labels 和 $value 等变量。  规则配置 #  数据源：选择数据源类型和筛选条件，用于指定当前这条告警规则生效到哪些数据源，因为很多公司有多套 Prometheus，这样可以方便管理规则。 告警条件：就是配置 Promql，可以在 Promql 中做一些条件筛选和四则运算，比如这个 Promql：http_api_request_success{region=\u0026quot;beijing\u0026quot;} / http_api_request_total{region=\u0026quot;beijing\u0026quot;} \u0026lt; 0.995 表示：求取 beijing 这个 region 的所有 HTTP 请求的成功率，如果成功率小于 99.5% 就告警。如果告警引擎通过此 Promql 查到了数据，说明有有异常点产生，如果多次查询持续异常，最终满足了持续时间，就会产生一个告警事件。 多告警条件和级别抑制：在一条告警规则中，可以添加多个 Promql 查询条件，此时会自动出现一个 级别抑制 的功能开关，如果打开了级别抑制开关，两个条件同时产生告警的话，只会发送高级别的告警，会对低级别的告警进行抑制，减少打扰。 执行频率和持续时长：这俩配置在页面上都提供了 tooltip，鼠标放上去可以看到用法提示。执行频率就相当于 Prometheus 中的 evaluation_interval，持续时长就相当于 Prometheus 中的 for，如果持续时长为 0，表示只要有一次查询到数据，就生成告警事件。  事件 relabel # 这部分页面上提供了说明文档，请自行查阅。在 Prometheus 中有个 relabel 机制，相信很多人都不陌生（如果之前尚未了解，可以自行 Google 一下，挺有用的一个设计），Prometheus 是针对时序数据做 relabel，夜莺这里是针对生成的告警事件做 relabel。\n举个场景例子，比如原本有个标签是 instance=10.1.2.3:9090，可以通过 relabel 提取其中的 IP 信息，生成一个新的标签 ident=10.1.2.3，夜莺里的告警自愈功能是需要从告警事件中提取机器信息的，实际就是提取的 ident 标签的值，通过 relabel 提取机器信息写入 ident 标签，方便后续做告警自愈（当前，前提是你在 Categraf 里配置的 hostname=\u0026quot;$ip\u0026quot;）。\n生效配置 # 这部分也在页面提供了使用说明，请自行查阅。这块最重点的配置是生效时间段，比如某个告警规则只在白天生效，另一个告警规则只在晚上生效，就可以通过生效时间段来配置。\n通知配置 # 老版本是在告警规则里直接配置告警接收人和通知媒介，如果要批量修改则比较费劲。新版本把通知逻辑提取出来，抽象为通知规则，来处理告警事件产生之后的所有逻辑。后面会对通知规则做详细介绍。\n通知配置部分，其他各个字段均有 tooltip，鼠标放上去可以看到用法提示，这里就不再赘述了。\n告警自愈，即：告警产生之后自动去告警的机器（或指定的特定中控机）执行特定的脚本。所谓的告警的机器，这个信息从哪里取？就是取自告警事件的 ident 标签，那具体执行哪个自愈脚本呢？就是通过通知配置下面的 告警自愈 字段来指定。\n附加信息，就类似 Prometheus 告警规则中的 Annotations，告警事件生成之后，夜莺会把这些附加信息追加到告警事件中，后续可以在消息模板中引用，最终在钉钉、飞书、邮件等通知中展示。\n实操演示 # 为了尽快产生告警事件，我这里配置了一个必然会触发的 Promql：\ncpu_usage_active \u0026gt; 0   🟢 cpu_usage_active 这个指标是 Categraf 采集的，表示 CPU 利用率，CPU 利用率显然必然会大于 0，所以这个规则很快就可以触发告警事件。如果你没有使用 Categraf，就没有这个指标了，请使用你自己的时序库中的指标来做测试。\n 上例中，为了加速产生告警事件，我把执行频率设置为 15s，把持续时长设置为 0，这样一来，夜莺每 15s 就会查询一次数据源，如果查到了数据就会生成告警事件。\n稍等片刻，即可发现告警规则左侧的状态字段，变成一个红色的感叹号，表示触发了告警事件，点击之后在侧拉板可以看到这个规则产生的相关告警事件。当然，你也可以在告警事件菜单看到当前的活跃告警（未恢复的告警称为活跃告警）和所有历史告警。\n上面的第一条告警事件就是刚刚测试的，其他的事件是之前测试的，不用关心哈。告警事件产生了，说明告警规则配置的没问题，后面就是配置通知规则了，指定什么样的告警事件发给谁，通过什么通知媒介（电话、短信、邮件、飞书、钉钉、企微等，称为通知媒介）来发。\n","description":"夜莺监控（Nightingale）支持指标告警，根据用户配置的告警规则，周期性查询数据源，当数据源中的数据满足告警阈值时，触发告警。","title":"指标告警"},{"RelPermalink":"/zh/docs/usage/logs-alerting/","contents":"夜莺监控（Nightingale）支持日志告警，可以针对 ElasticSearch、Loki、ClickHouse 等数据源中的日志数据配置告警规则，周期性查询数据源，当数据源中的数据满足告警阈值时，触发告警。日志告警和指标告警的区别主要是查询条件的写法不同。其他各个字段都是通用的，请一定先阅读指标告警的内容，这里不再赘述。\nElasticSearch 告警原理 # ElasticSearch 支持不同的查询语法，比如 DSL、KQL、Lucene、EQL、SQL 等，夜莺作为一个告警引擎，本质就是让用户配置查询语句，然后周期性查询数据源，对查到的数据做阈值判断，满足阈值条件就触发告警。\n最先支持的查询语法是 Lucene，即 query_string 方式，查到数据之后做一个基本的统计，比如做一个计数，统计一下查到的日志行数，或者针对日志中的某个字段做统计，计算其平均、最大值、分位值等。然后把统计结果和用户配置的阈值进行对比，满足阈值条件就触发告警。\nElasticSearch 告警配置 # 首先是配置数据源，即当前告警规则要生效到哪些 ElasticSearch 数据源上，这个和指标告警本质是一样的逻辑。\n 🟢 数据源的类型那里，只有配置了对应类型的数据源，这里才会展示。即：如果你只配置了 Prometheus 类型的数据源，创建告警规则的时候，是看不到 ElasticSearch、TDEngine、ClickHouse 等其他类型的。\n 然后配置查询统计条件：\n首先要选择索引，支持通配符，我上面配置的是 fc*，然后最关键的是过滤条件，我上面配置的是 message.status:\u0026gt;100，过滤 message.status 字段大于 100 的日志。这个过滤条件是 Lucene 的语法，和 Kibana 的查询语法是不一样的。日志必然有个日期字段，需要通过配置告知夜莺，哪个字段是日期字段，然后配置一个时间间隔，上图配置的是 5 分钟，夜莺就根据日期字段过滤最近 5 分钟的数据。\n然后下面是统计分析方法，上例中选择的是 count，表示统计日志行数，并且没有任何 Group By 条件。\n最后是阈值判断，即把上面 count 的结果，和阈值做比对，如果符合条件就产生告警事件。上例中阈值是 \u0026gt; 0 就告警，即 count 的结果大于 0 就告警。\n稍等片刻，我们可以看到产生的告警事件：\nElasticSearch 过滤条件 # 过滤条件（即上例中的 message.status:\u0026gt;100）还有哪些写法？可以点击过滤条件旁边的那个小问号的图标，会在侧拉板中展示过滤条件的写法样例说明。一些典型的写法如下：\n status:active 查询 status 字段包含 active 的记录 title:(quick OR brown) 查询 title 字段包含 quick 或 brown 的记录 author:\u0026quot;John Smith\u0026quot; 查询 author 字段包含完整短语 “John Smith” 的记录 count:[1 TO 5] 数据范围查询，闭区间，即包含 1 和 5 date:[2022-01-01 TO 2022-12-31] 日期范围查询 age:\u0026gt;=10 数值大小过滤，大于等于 10  注意，为了避免犯错，建议字段后面的冒号:前后都不要加空格。另外，不同的条件之间可以使用 AND、OR 连接，比如 status:active AND age:\u0026gt;=10。更多写法请参考 ElasticSearch 的官方文档。\n","description":"夜莺监控（Nightingale）支持日志告警，可以针对 ElasticSearch、Loki、ClickHouse 中的日志数据配置告警规则，周期性查询数据源，当数据源中的数据满足告警阈值时，触发告警。","title":"日志告警"},{"RelPermalink":"/zh/docs/usage/notify-rules/","contents":"告警规则负责产生告警事件，通知规则负责把告警发送出去，不同的告警可以选择不同的通知媒介，比如高级别的告警打电话、发短信、发钉钉，低级别的告警发邮件等。\n设计初衷 # 老版本的夜莺没有通知规则的概念，是在告警规则里直接配置通知媒介和通知接收人，虽然直观，但是不够灵活，有如下问题：\n 告警规则中启用抑制之后，通知媒介仍然只能写死的问题。之前版本的告警规则中如果启用了抑制规则，通常意味着，不同的阈值想要使用不同的级别，进而使用不同的通知媒介发送告警，比如 Critical 级别的告警使用电话、短信，Info 级别的告警使用 Email。但是之前版本的告警规则中，通知媒介是写死的，无法做到不同的级别不同的媒介。 接入电话、短信等通知方式不方便。这次我们提供了通用的 HTTP、脚本发送方式，HTTP 的参数、Header、Body 都可以自定义，这样一来，可以更方便接入不同通知媒介了。 之前的通知方式和告警规则强耦合，不方便改动。新版本抽象了「通知规则」的概念，告警规则直接关联的是通知规则，通知规则中可以定义灵活的发送方式。每个小研发团队通常只需要定义一个通知规则，然后所有的告警规则都关联这个通知规则即可。后面改动通知规则也是非常方便的，改一个地方即可影响所有告警规则。 之前版本消息模板比较死板，每个类型的通知媒介只能固定使用一个消息模板。新版本支持消息模板自定义，而且每个通知媒介可以关联不同的消息模板，比如 DBA 团队和 大数据 团队都要使用钉钉机器人发告警，但是希望使用不同的消息模板，现在就可以做到了。  逻辑示意 # 新版本的告警事件发送逻辑，整体流程变成如下这个样子：\n之前的版本，是在告警规则里直接配置通知媒介+告警接收人，耦合严重。新版本是在告警规则里关联通知规则，具体如何发送是在通知规则里定义的，这样一来，告警规则和通知规则解耦，多个告警规则可以关联一个通知规则，如果想要改动通知方式，只需要改动通知规则即可。\n配置说明 # 通知规则可以支持不同的通知媒介，而且可以定义不同的媒介适用的范围，比如电话这个通知媒介，只适用于 Critical 的告警，而 Email 则适用于 Critical、Warning、Info 所有告警。下面是一个通知规则配置样例：\n对于通知媒介，我们会内置一些，方便大家开箱即用：\n打开通知媒介的配置，其中有个「变量配置」不太好理解。我说个场景：比如 DBA 团队和 BigData 团队都想使用企微这个通知媒介发告警，但是他们想使用不同的企微机器人，即 Webhook 地址基本相同，但是 URL 参数中的 Key 不同（不同的 Key 代表不同的机器人）。此时应该怎么做？\n在夜莺的设计里，不希望创建两个不同的通知媒介。还是希望只有企微一个通知媒介，但是这个通知媒介支持传参，DBA 同学在配置告警通知规则的时候，选择企微这个通知媒介的同时，要填写自己的机器人的 Key，BigData 同学也是一样，也是配置企微通知媒介 + BigData 的企微机器人 Key。这样一来，一个通知媒介就可以支持多个机器人了。\n如何让通知媒介支持参数呢？就是在媒介的变量配置中进行创建。内置的企微通知媒介就是创建了两个参数，一个 Key（表示企微机器人Key），一个 Bot Name（机器人名称，自定义的，纯粹是为了方便记忆，类似备注的效果）。进而，在企微媒介的 HTTP 配置中，就可以引用这个参数，比如：\n这个场景相对简单，媒介通知的时候，获取用户填写的 Key 即可。还有更复杂的场景。比如发短信，此时媒介参数如何定义？如果直接定义成 Phone，然后让用户在通知规则中手写手机号，那就有点费劲了。而且用户的联系方式如果发生变化，除了要到个人中心修改自己的手机号，还要到通知规则里改，太过麻烦。而手机号已经在个人的联系方式中了，那直接把二者贯通即可。\n对于这类场景，可以概括为：媒介需要的参数来自用户的 Profile 信息。这个时候，就需要在媒介的变量配置中，引用用户的 Profile 信息。比如：\n媒介变量这里，联系方式选择 Phone，然后就会有一系列的魔法，魔法效果是：\n 通知规则那里，系统根据媒介里的 Phone 联系方式，知道用户想发通知给某些人，通知规则那里就可以选择联系人或团队了，而不是手写手机号。 在 HTTP 的 request body 或 query string 中，可以引用一个魔法变量：{{ $sendto }}，表示被通知对象的手机号。这样一来，通知媒介就可以根据这个变量，把告警通知发给正确的人了。{{ $sendto }} 这个设计是从 Zabbix 学的，如果你用过 Zabbix，应该会很熟悉。  具体配置举例 #  对接钉钉告警 对接企微告警 对接飞书告警 对接钉钉告警，如何配置 at 人 对接钉钉、飞书、企微通知 对接阿里云短信  另外，在微信视频号：SRETALK 上也放置了一个视频教程，演示如何接入飞书告警，您可以自行搜索查看。\n邮件告警配置 # 上面给的文档链接讲解了常用的 IM 告警媒介，这里再补充一个邮件告警的配置说明。要想发送告警邮件，核心有三个地方需要注意：\n SMTP 发信服务器的配置 告警接收人得配置个人收件箱 邮件通知的消息模板  1. SMTP 发信服务器的配置 # 进入 通知媒介 菜单，找到内置的 Email 通知媒介，进去编辑，填写 SMTP 发信服务器的相关信息，比如我是这么配置的：\n2. 用户在个人中心配置自己的收件邮箱地址 # 点击右上角的头像，进入个人信息配置页面，填写自己的收件邮箱地址即可。\n3. 配置通知规则 # 为了测试方便，我这里创建了一个全新的通知规则（你也可以在既有的通知规则上改动，增加邮件媒介），生效到所有级别的告警事件，即任一告警事件产生，都要走邮件通知给我。配置如下：\n我上面配置的是发给我个人，你也可以发给某个团队。然后点击通知测试，选择一个历史告警事件，就可以测试邮件通知了。最后，把通知规则配置到告警规则里就可以了。\n4. 邮件通知的消息模板 # 在 消息模板 菜单下，找到 Email 消息模板，里边有两个变量：\n content：邮件正文内容 subject：邮件主题  这俩字段都使用 go template 语法，您可以根据自己的需求调整邮件内容和主题。\n","description":"夜莺监控（Nightingale）支持通知规则，可以配置通知方式、接收人等信息。当告警事件触发时，夜莺会根据通知规则发送通知。比如高级别的告警打电话、发短信、发钉钉，低级别的告警发邮件等。","title":"通知规则"},{"RelPermalink":"/zh/docs/usage/dashboard/","contents":"夜莺监控虽然侧重点是告警，但是也支持仪表盘功能，虽然没有 Grafana 道行深，但是常见的图表类型都支持，可以满足日常使用。\n快速导入 # 之前整理过机器的仪表盘，您可以直接导入使用，快速看到效果。导入的方式：\n不同的采集器采集的监控指标名字和标签各异，所以需要分别制作仪表盘。如果你使用的是 Categraf，可以导入如下两个仪表盘：\n 机器概览数据：categraf-overview.json 机器详细数据：categraf-detail.json  如果你使用的是 Node Exporter，可以导入如下仪表盘：\n Node 关键指标：exporter-detail.json  实际上，这几个仪表盘都可以在夜莺的菜单 集成中心-模板中心-搜索 Linux 找到：\nCategraf 概览页面的仪表盘样例：\nCategraf 机器详细数据的仪表盘样例：\n模板中心已经内置了很多组件的仪表盘，但是质量参差不齐，回头腾出手来我们会挨个再整理一遍，力求开箱即用。不过组件实在是太多，人手有限，欢迎广大社区用户一起参与整理贡献，将您整理好的仪表盘提交到 Github 夜莺仓库的 integrations 目录下面的各个组件下的 dashboards 目录下，通过 PR 提交即可。\n集成 Grafana # 你也可以继续使用 Grafana 看图，毕竟各有所长，组合使用更佳。也可以通过夜莺菜单 集成中心-系统集成，直接把 Grafana 通过 iframe 的方式嵌入夜莺。\n嵌入方法姑且分两种，一种是安全的嵌入，通过 SSO 打通用户登录，另一种是匿名访问的方式嵌入。\n安全的嵌入 # 请参考这篇文章：夜莺和 Grafana 深度整合打通认证\n匿名嵌入 # Grafana 默认不支持被别的系统嵌入，需要修改一些配置，具体要修改的内容如下：\n1、启用 embedding\n在 Grafana 配置文件中找到 allow_embedding 的配置项，设置为 true。\n2、启用 anonymous\n找到 auth.anonymous 配置段，把 enabled 设置为 true，org_role 设置为 Viewer，org_name 根据你自己的环境配置即可。\n3、对于 HTTPS 的 Grafana\n在 security 配置段，把 cookie_secure 设置为 true, cookie_samesite 设置为 none。\n另外，不同版本的 Grafana 可能配置方式有差异，如果您发现文档有误，点击下面的 “Edit this page on GitHub” 可以直接编辑本页面，提交 PR 修改文档。\n","description":"夜莺监控（Nightingale）支持仪表盘功能，可以将监控数据以图表的形式展示出来。通过仪表盘，用户可以直观地查看各类监控指标的变化趋势和状态。","title":"仪表盘"},{"RelPermalink":"/zh/docs/practice/linux/","contents":" 对于监控系统，基础功能的强弱确实非常关键，但是如何在不同的场景落地实践，则更为关键。在《监控实践》章节，搜罗各类监控实践经验，会以不同的组件分门别类，您如果对某个组件有好的实践经验，欢迎提 PR，把您的文章链接附到对应的组件目录下。\n  Linux 主机监控最佳实践 透过 Node-Exporter 彻底搞懂机器监控  FAQ # 1. 我的机器列表里可以看到机器，也可以看到机器的CPU、内存等信息，但是仪表盘查不到数据 #  💡 注意：机器列表里那些 CPU、内存等信息，不是存储在时序库的，而是存储在 Redis 中的，是 Categraf 调用夜莺的 heartbeat 接口时上报上来的，和 Remote write 走的是两个路径。\n 这个问题从如下几个方面排查：\n1、看 Categraf 的日志\n作为 IT 从业人员，第一反应就是应该看相关组件的日志，Categraf 的日志默认打在 stdout，如果是 systemd 托管的 Categraf，则使用 journalctl 查看，比如 journalctl -u categraf.service。如果对 Linux 不太熟悉，直接在命令行里前台启动 Categraf，可以更方便查看日志，即：\n./categraf  如上就是直接把 Categraf 进程启动在前台，日志会直接输出到终端，方便查看。\n2、确认 Categraf 的配置\n机器列表里可以正常看到内容，说明 Categraf 的配置里的 heartbeat 部分配置是正常的。仪表盘看不到监控数据，可能是 writer 部分的配置有问题，writer 部分的 url 应该配置为夜莺的地址，urlpath 是 /prometheus/v1/write。\n3、确认夜莺的配置\nCategraf 把数据推给夜莺，夜莺不直接存储数据，而是转发给 TSDB，TSDB 可以是 Prometheus 或者 VictoriaMetrics 等，夜莺把数据发给哪些 TSDB？是由夜莺的配置文件 config.toml 中的 Pushgw.Writers 来决定的。\n需要确保 Pushgw.Writers 中的配置是正确的，且夜莺的 n9e 进程可以正常访问到这些 TSDB。\n4、查夜莺的日志\n如果数据转发给时序库失败，夜莺的日志会有相关提示，查看夜莺的日志可以帮助定位问题。社区里新手用户常见的错误是夜莺写数据给 Prometheus，但是 Prometheus 的启动参数有问题，没有开启 remote write 接口，导致夜莺写数据失败。这类错误通常会在夜莺的日志中有提示，可以直接看到应该给 Prometheus 增加什么参数，照着修改即可。\n5、时间校准\n比如本地笔记本电脑的时间和服务端的时间是否一致，监控系统对时间是很敏感的。如果时间没有校准，可能会导致数据无法正常展示。\n6、查看仪表盘的配置\n有些仪表盘是查看时序库里的所有数据，有些仪表盘是只能查看所属业务组下面的机器的监控数据（通过仪表盘变量控制的），如果是后者类型的仪表盘，就需要确保业务组下面有机器。\n2. 我可否把监控数据写到 TDEngine 等其他时序库 # 首先，你需要了解 Prometheus remote write 协议（可以问问 Google 或 GPT）。Categraf 采集的数据是通过 Prometheus remote write 协议推送给夜莺的，夜莺也是通过 Prometheus remote write 协议把数据转发给时序库的。\n所以，如果某个时序库支持接收 Prometheus remote write 协议的数据，那么就可以接入 Categraf 或夜莺。这个信息从哪里得到？去看（或搜）时序库的文档，如果它支持接收 Prometheus remote write 协议的数据，那么它大概率会在文档里提及。如果它的文档里没有写，大概率就是不支持或支持的不好不推荐使用。\n3. 机器失联监控怎么做？ # 在 Prometheus 里，每台机器部署 Node-Exporter，Prometheus 主动去抓取 Node-Exporter 的数据，这种方式叫做PULL。这种方式的好处是，Prometheus 可以知道机器是否失联，因为如果机器失联，Prometheus 就无法抓取到数据。抓取成功的话，会有个 up 指标，值为 1；如果抓取失败，则 up 指标的值为 0。\n所以，在 Prometheus PULL 模式下，可以使用 up 指标来监控机器是否失联。\n夜莺默认使用 Categraf 采集机器的监控数据，Categraf 不暴露 /metrics 接口，而是通过 remote write 协议把数据推给夜莺，这种模式称为PUSH。在这种模式下，不会有 up 指标，那如何监控机器是否失联呢？\n夜莺的告警规则里，提供了一个 Host 类型的告警规则，可以配置失联告警：\n通常配置为对所有机器生效即可，如果你有一些特殊的机器，不想做失联告警，可以把这些机器放到特殊的业务组或者打上特殊的标签，然后在机器筛选这里，给过滤掉。\n或者使用 PING 监控对机器发起 PING 探测，然后对 PING 的探测结果配置告警规则，也是可以的。有很多监控工具都支持 PING 探测，比如 Telegraf、Categraf、Blackbox Exporter 等。\n","description":"夜莺监控（Nightingale）支持对 Linux 主机的监控，可以通过 Categraf 或 Node Exporter 等采集器采集主机的各类指标数据，并在仪表盘中展示。并使用夜莺监控的告警能力进行告警配置。","title":"Linux OS"},{"RelPermalink":"/zh/docs/practice/proc/","contents":" 对于监控系统，基础功能的强弱确实非常关键，但是如何在不同的场景落地实践，则更为关键。在《监控实践》章节，搜罗各类监控实践经验，会以不同的组件分门别类，您如果对某个组件有好的实践经验，欢迎提 PR，把您的文章链接附到对应的组件目录下。\n 进程监控分两部分，一部分是操作系统内整体进程数量统计，另一部分是单一进程指标采集。\n总体进程数量 # 以 Categraf 为例，Categraf 提供了 processes 插件用于统计机器上的进程数量，比如总进程数量多少、Running 状态的进程数量多少、Sleeping 状态的进程数量多少等。针对 processes 插件采集的数据，我们整理过专门的仪表盘：\n https://github.com/ccfos/nightingale/blob/main/integrations/Linux/dashboards/categraf-processes.json\n 这类指标有什么用？通常是非预期的启动了大量进程的场景。比如笔者之前遇到：crontab 写挫了，脚本 hang 住了，而且没有在 cron 脚本里检测之前的进程是否退出，导致每次 crontab 执行时都启动了一个新的进程，最终导致机器上有大量的同名进程在运行，最终酿成事故。这个时候就可以通过 processes 插件采集的指标来发现问题。\n单一进程指标 # 单一进程指标，指的是进程占用的 CPU、内存、句柄等指标。有多种方式可以采集。\n 在进程里埋点。比如 Java 程序可以使用 micrometer 或者 Spring Boot Actuator 等方式来采集指标，Go 程序可以使用 Prometheus 的 Go 语言客户端库来采集指标。 在进程外采集。比如使用 Process Exporter、Categraf 的 procstat 插件等采集进程指标。  通常来讲，在进程里埋点是更推荐的做法。不但可以采集进程的 CPU、内存 等常规指标，也可以采集更多运行时指标，比如 Java 程序可以采集 JVM 的一些指标，Go 程序可以采集一些 goroutine、gc 的指标。所有优秀的开源软件，都会暴露自身的监控指标。作为业务研发人员，水平参差不齐，可能有些人不清楚埋点的重要性，此时也可使用进程外采集的方式来做补充。\n Spring Boot Actuator 是可以通过配置调整来直接暴露 Prometheus 格式的 metrics 数据的，所以不需要额外的插件来采集，直接使用 Categraf 的 prometheus 插件即可。或者直接在 Prometheus 或 vmagent 里配置抓取规则也可以。\n 以 Categraf 的 procstat 插件为例，其文档参考 这里。重点要关注的指标是：\n procstat_lookup_count 进程数量，如果为 0，表示对应的进程挂了 procstat_rlimit_num_fds_soft 进程的软限制句柄数，如果是 1024，通常表示系统参数没有调优好 procstat_cpu_usage_total 进程 CPU 使用率 procstat_mem_usage_total 进程内存使用率 procstat_num_fds_total 进程打开的文件句柄数 procstat_read_bytes_total 进程读取的总字节数 procstat_write_bytes_total 进程写入的总字节数  单一进程的仪表盘可以参考：\n https://github.com/ccfos/nightingale/blob/main/integrations/Procstat/dashboards/categraf-procstat.json\n FAQ # 1. procstat 插件监控多个进程怎么做？\n配置样例如下：\n[[instances]] search_exec_substring = \u0026quot;mysqld\u0026quot; gather_total = true gather_per_pid = true gather_more_metrics = [ \u0026quot;threads\u0026quot;, \u0026quot;fd\u0026quot;, \u0026quot;io\u0026quot;, \u0026quot;uptime\u0026quot;, \u0026quot;cpu\u0026quot;, \u0026quot;mem\u0026quot;, \u0026quot;limit\u0026quot;, ] [[instances]] search_exec_substring = \u0026quot;n9e-plus\u0026quot; gather_total = true gather_per_pid = true gather_more_metrics = [ \u0026quot;threads\u0026quot;, \u0026quot;fd\u0026quot;, \u0026quot;io\u0026quot;, \u0026quot;uptime\u0026quot;, \u0026quot;cpu\u0026quot;, \u0026quot;mem\u0026quot;, \u0026quot;limit\u0026quot;, ]  2. procstat 配置中的 gather_more_metrics 里边的 jvm 参数是干啥的\n如果 gather_more_metrics 包含 jvm 则会认为要采集的目标进程是个 Java 进程，会调用系统的 jstat 命令采集 JVM 的一些基础指标。jstat 是安装 JDK 时自带安装的一个工具，在 JDK 的 bin 目录下。这里经常会有一个坑，就是用户在 gather_more_metrics 配置了 jvm，机器上也有 jstat，使用如下命令测试采集的时候也可以采集到数据：\n./categraf --test --inputs procstat  但是重启 Categraf 正式采集之后，却又采集不到了。通常的原因是：Categraf 使用 systemd 托管的，而 systemd 并不知道 JDK 的环境变量，所以找不到 jstat 命令导致的。解决方法是配置 Categraf 的 service 文件，添加 JDK 的环境变量。比如：\nEnvironment=\u0026quot;PATH=/usr/lib/jvm/java-11-openjdk-amd64/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\u0026quot;  ","description":"本文介绍了进程监控的实践经验，包括总体进程数量统计和单一进程指标采集。对 Categraf 的 processes 插件和 procstat 插件做了详细说明，并提供了相关仪表盘的链接。","title":"进程监控"},{"RelPermalink":"/zh/docs/practice/port/","contents":" 对于监控系统，基础功能的强弱确实非常关键，但是如何在不同的场景落地实践，则更为关键。在《监控实践》章节，搜罗各类监控实践经验，会以不同的组件分门别类，您如果对某个组件有好的实践经验，欢迎提 PR，把您的文章链接附到对应的组件目录下。\n 端口监控，是进程存活性探测的典型方式，相比统计进程数量，端口监控更为靠谱，因为进程有时会 hang 住，导致进程数量统计正常，但是端口无法正常响应。\n一般来说，端口探测分三种协议：\n TCP 协议 UDP 协议 HTTP 协议  依据服务监听的端口协议类型不同，使用的探测方式也不同。\nTCP/UDP 协议 # TCP/UDP 协议的端口监控，适合针对 RPC 类的服务，可以使用 Categraf 的 net_response 插件来实现。\n Categraf net_response 插件说明  这里最应该关注的指标是：net_response_result_code，如果这个指标的值是 0，表示一切正常，如果非 0 则表示异常，不同的值表示不同的异常类型。\n 0: Success 1: Timeout 2: ConnectionFailed 3: ReadFailed 4: StringMismatch  在夜莺的集成中心-模板中心可以找到相关的仪表盘。\nHTTP 协议 # HTTP 协议的探测和 TCP/UDP 协议类似，Categraf 也提供了 http_response 插件来实现。相比 TCP/UDP 协议，HTTP 协议的端口监控可以更进一步，除了探测端口是否可用，还可以探测 HTTP 响应内容（返回的状态码、返回的 Response body）是否符合预期，如果是 HTTPS 站点，还可以探测证书过期时间。\n Categraf http_response 插件说明  用于告警的指标是 http_response_result_code 只要这个指标是 0 就是正常的，如果这个指标非 0，就是异常的，不同的值代表不同的含义：\nSuccess = 0 ConnectionFailed = 1 Timeout = 2 DNSError = 3 AddressError = 4 BodyMismatch = 5 CodeMismatch = 6  http_response_cert_expire_timestamp 是证书过期的时间戳，http_response_cert_expire_timestamp - time() 表示证书还有多久过期，单位是秒。\n在夜莺的集成中心-模板中心可以找到相关的仪表盘。\n","description":"本文介绍了端口监控的实践经验，包括 TCP/UDP 协议和 HTTP 协议的端口监控。使用 Categraf 的 net_response 和 http_response 插件来实现端口监控，并提供了相关的仪表盘链接。","title":"端口监控"},{"RelPermalink":"/zh/docs/practice/exec/","contents":" 对于监控系统，基础功能的强弱确实非常关键，但是如何在不同的场景落地实践，则更为关键。在《监控实践》章节，搜罗各类监控实践经验，会以不同的组件分门别类，您如果对某个组件有好的实践经验，欢迎提 PR，把您的文章链接附到对应的组件目录下。\n Categraf 虽然已经内置了很多采集插件，但是总会有一些自定义监控数据采集的需求场景，此时可以考虑使用 Categraf 的 input.exec 插件。这个插件可以执行用户指定的脚本（可以是 Shell、Python、Perl 等脚本，也可以是 Go、C++ 的二进制，只要是个可执行文件就行），然后截获脚本的 stdout，解析为监控数据。\n EXEC 插件使用文档  之前有些社区用户提供了一些插件脚本样例，可以参考：Categraf Exec 插件脚本样例。也欢迎大家继续提交样例。\n","description":"本文介绍 Categraf 的自定义监控插件脚本的机制。插件脚本使用 Shell、Python、Go 等都可以，把执行文件的路径告诉 Categraf 即可，Categraf 就会按照配置的时间间隔周期性执行这些脚本，把输出的内容作为监控数据采集。","title":"插件脚本"},{"RelPermalink":"/zh/docs/practice/mysql/","contents":" 对于监控系统，基础功能的强弱确实非常关键，但是如何在不同的场景落地实践，则更为关键。在《监控实践》章节，搜罗各类监控实践经验，会以不同的组件分门别类，您如果对某个组件有好的实践经验，欢迎提 PR，把您的文章链接附到对应的组件目录下。\n  使用 Categraf 监控 MySQL 的入门教程 根据夜莺模板中心的引导，建设 MySQL 监控 如何发现及处理 MySQL 主从延迟问题 MySQL 监控原理讲解 使用 Exporter 监控 MySQL 解决 MySQL 的 max_prepared_stmt_count 问题  除了 MySQL 的性能数据的监控，我们也可以自定义 SQL 来监控 MySQL 中的数据（通过 Categraf 的 mysql 插件即可做到），这通常会有两个用途：\n 扩展性能监控指标，默认的性能监控数据不够用的话，可以通过这种方式来扩展 监控业务数据，这个场景就极为广泛了，比如监控订单数据、用户数据等。这个场景容易被大家忽略，但有时有奇效  ","description":"本文介绍如何对 MySQL 做监控，MySQL 作为国内最常用的数据库之一，使用广泛资料也很多。对 MySQL 的监控分两个方面，一个是 MySQL 的性能数据的监控，另一个是 MySQL 的业务数据的监控","title":"MySQL"},{"RelPermalink":"/zh/docs/practice/redis/","contents":" 对于监控系统，基础功能的强弱确实非常关键，但是如何在不同的场景落地实践，则更为关键。在《监控实践》章节，搜罗各类监控实践经验，会以不同的组件分门别类，您如果对某个组件有好的实践经验，欢迎提 PR，把您的文章链接附到对应的组件目录下。\n  Categraf 采集 Redis 监控数据 使用 Cprobe 监控 MySQL、Redis、MongoDB、Oracle、Postgres 等  Redis 监控采集原理 # 不管使用 Categraf 还是 Redis-Exporter 采集 Redis 的监控数据，原理都是类似的，通过 Redis 连接地址、用户名密码等信息连到 Redis 上，执行 info 之类的命令获取监控数据。\n如何接入 Redis-Exporter # 有些用户用了 Categraf 采集机器指标、进程指标、自定义插件，但是没有使用 Categraf 采集 Redis 的监控数据，而是使用了 Redis-Exporter。然后就比较困惑：如何把 Redis-Exporter 采集的数据接入到夜莺中？\n有两个办法：\n 直接在你的时序库里配置 Scrape 规则，抓取 Redis-Exporter 的数据 使用 Categraf 的 input.prometheus 插件，抓取 Redis-Exporter 的数据  ","description":"Redis 监控数据的采集有多种方式，可以使用 Categraf、Redis-Exporter、Cprobe 等各类工具，其原理都是类似的，无非就是连到 Redis 实例上，执行 info 之类的命令获取监控数据","title":"Redis"},{"RelPermalink":"/zh/docs/practice/oracle/","contents":" 对于监控系统，基础功能的强弱确实非常关键，但是如何在不同的场景落地实践，则更为关键。在《监控实践》章节，搜罗各类监控实践经验，会以不同的组件分门别类，您如果对某个组件有好的实践经验，欢迎提 PR，把您的文章链接附到对应的组件目录下。\n Oracle 监控数据的采集有多种方式，可以使用 Categraf、Cprobe 等各类工具，其原理都是类似的，无非就是连到 Oracle 实例上，执行相关命令获取监控数据。本文以 Categraf v0.4.15 以上版本为例，介绍 Oracle 监控数据的采集配置方法。\nOracle 插件配置概述 # Categraf 的所有插件配置，默认都在 conf 目录下，Oracle 的配置目录是 conf/input.oracle，该目录下有两个配置文件：\n oracle.toml：Oracle 插件的主配置文件，配置不同 Oracle 实例的连接、认证信息；Categraf 可以同时连接多个 Oracle 实例，配置文件中可以配置多个实例的连接信息，即不同的 [[instances]] 配置段。 metric.toml：Oracle 插件通过执行各类 SQL 采集 Oracle 监控数据，有些 SQL 是通用的，希望所有的 Oracle 实例都去执行采集，有些 SQL 是特定实例的，只有特定实例才去执行采集，通用的 SQL 都在 metric.toml 中配置，特定实例的 SQL 在 oracle.toml 中配置。  oracle.toml # oracle.toml 配置样例如下：\n# 默认的采集频率，下面配置的所有的 oracle 的实例默认都会使用这个采集频率 # 如果某个实例需要不同的采集频率，可以在实例配置中使用 interval_times 来调整 # 各个实例的最终采集频率 = interval * interval_times # 如果这里的 interval 也没有配置，那就使用 Categraf 全局配置中的 interval（默认是 15 秒） # 单位是秒，所以默认是 15 秒采集一次监控数据 interval = 15 # 这是第一个 Oracle 实例的配置，使用一大块 [[instances]] 来配置 # [[instances]] 使用双中括号包裹，双中括号在 TOML 中表示数组 # 即可以配置多个 [[instances]] 区块，也就是可以配置多个 Oracle 实例 # 建议不要使用 sys 用户来进行采集，因为在 oracle 12c 及之后版本，go-ora 的 ping 方法在判断 oracle up 状态时，不准确 [[instances]] address = \u0026quot;10.1.2.3:1521/orcl\u0026quot; username = \u0026quot;monitor\u0026quot; password = \u0026quot;123456\u0026quot; is_sys_dba = false is_sys_oper = false disable_connection_pool = false max_open_connections = 5 # 这个实例最终的采集频率是 interval * interval_times interval_times = 1 # 这里可以为当前实例附加一些维度标签，这些维度标签最终会附加到当前实例的监控数据上面 labels = { region=\u0026quot;cloud\u0026quot; } # instances 下面的 metrics 配置段，表示当前实例需要采集的监控数据 # 注意，这个 metrics 配置段是当前实例特有的，其他实例不会去执行这些 SQL [[instances.metrics]] mesurement = \u0026quot;sessions\u0026quot; label_fields = [ \u0026quot;status\u0026quot;, \u0026quot;type\u0026quot; ] metric_fields = [ \u0026quot;value\u0026quot; ] timeout = \u0026quot;3s\u0026quot; request = ''' SELECT status, type, COUNT(*) as value FROM v$session GROUP BY status, type ''' [[instances]] address = \u0026quot;192.168.10.10:1521/orcl\u0026quot; username = \u0026quot;monitor\u0026quot; password = \u0026quot;123456\u0026quot; is_sys_dba = false is_sys_oper = false disable_connection_pool = false max_open_connections = 5 labels = { region=\u0026quot;local\u0026quot; } # 第二个实例下面没有对应的 instances.metrics 配置段，说明没有独属于这个实例的采集 SQL # 即：第二个实例仅会执行 metric.toml 中配置的通用 SQL  Oracle 监控数据采集原理：周期性执行 SQL，把返回的结果转换为 Prometheus 时序数据格式，发送到服务端。SQL 执行的结果是多行多列的二维表格，那我们就需要通过配置告诉 Categraf，哪些列作为时序数据的标签（label），哪些列作为时序数据的值（metric value）。\n mesurement: 自定义的一个指标前缀 request: 查询监控数据的 SQL 语句 label_fields: SQL 查到的内容，会有多列，哪些列作为时序数据的 label metric_fields: SQL 查到的内容，会有多列，哪些列作为时序数据的值 field_to_append: 是否要把某列的内容附到监控指标名称里，作为指标的后缀 timeout: SQL 执行的超时时间 ignore_zero_result: 是否忽略查询结果中值为 0 的行，如果不忽略（设置为 false）且没有查到数据的话会打印一行错误日志，如果忽略了（设置为 true），则查不到数据的时候不会打印错误日志  metric.toml # 这里配置了一些常用的 Oracle 监控数据采集 SQL，Categraf 会定期执行这些 SQL，获取所有 Oracle 实例的监控数据。这里的 SQL 具体含义、作用，可能 Oracle DBA 才比较熟悉，欢迎各位 Oracle DBA 写文章分享这些 SQL 的含义和作用，完事可以把您的文章链接提个 PR 放到本页文档里，让更多人受益。\n","description":"Oracle 监控数据的采集有多种方式，可以使用 Categraf、Cprobe 等各类工具，其原理都是类似的，无非就是连到 Oracle 实例上，执行相关命令获取监控数据","title":"Oracle"},{"RelPermalink":"/zh/docs/practice/java/","contents":" 对于监控系统，基础功能的强弱确实非常关键，但是如何在不同的场景落地实践，则更为关键。在《监控实践》章节，搜罗各类监控实践经验，会以不同的组件分门别类，您如果对某个组件有好的实践经验，欢迎提 PR，把您的文章链接附到对应的组件目录下。\n Java 类的程序如何监控？通常有如下几种方式：\n Actuator Micrometer JMX 组件自身暴露指标  Actuator # 如果你是 Spring Boot 的 App，可以直接使用 Actuator 来暴露指标。可以使用如下提示词来提问 GPT：\n如何开启 actuator，暴露 Prometheus 格式的监控指标？  我把 AI 的回复贴在这里，大概率应该是对的，你可以尝试，如果发现问题，欢迎提 issue 或 pr。\n要在 Spring Boot 项目中开启 Actuator 并暴露 Prometheus 监控指标，你需要完成以下几个步骤：\n1. 引入依赖 # 在你的 pom.xml 中添加以下依赖：\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-actuator\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;io.micrometer\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;micrometer-registry-prometheus\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt;  如果你使用的是 Gradle：\nimplementation 'org.springframework.boot:spring-boot-starter-actuator' implementation 'io.micrometer:micrometer-registry-prometheus'  2. 配置 application.properties 或 application.yml # 确保 Actuator 的端点和 Prometheus 指标端点是暴露的。例如：\nmanagement.endpoints.web.exposure.include=* management.endpoint.prometheus.enabled=true management.metrics.export.prometheus.enabled=true  或者 YAML 格式：\nmanagement: endpoints: web: exposure: include: \u0026quot;*\u0026quot; endpoint: prometheus: enabled: true metrics: export: prometheus: enabled: true  3. 启动应用 # 启动你的 Spring Boot 应用后，Actuator 的 Prometheus 端点会默认暴露在 /actuator/prometheus。\n4. 验证指标端点 # 用浏览器或 curl 访问：\nhttp://localhost:8080/actuator/prometheus  你将看到 Prometheus 格式的监控指标，使用 Prometheus 或 Categraf 来抓取即可。\n注意：\n 如果你想只暴露部分端点，比如只暴露 prometheus 和 health，可以调整配置 management.endpoints.web.exposure.include=prometheus,health 如需更高级配置（自定义指标等），可以在代码中注入 MeterRegistry 并注册自定义指标。  Micrometer # 如果你不是 Spring Boot 的 App，也可以使用 Micrometer 来暴露 Prometheus 格式的监控指标。Micrometer 是一个独立的库，可以与任何 Java 应用程序集成。Actuator 实际上是基于 Micrometer 的。你可以使用如下提示词来提问 GPT：\n如果没有使用 actuator，仅仅使用了 micrometer，应该如何把指标导出到 Prometheus？  我把 AI 的回复贴在这里，大概率应该是对的，你可以尝试，如果发现问题，欢迎提 issue 或 pr。\n1. 添加 Micrometer 和 Prometheus 依赖 # 以 Maven 为例：\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;io.micrometer\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;micrometer-core\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;io.micrometer\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;micrometer-registry-prometheus\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt;  2. 注册 PrometheusMeterRegistry # 在你的应用代码中，手动创建并注册 PrometheusMeterRegistry，比如：\nimport io.micrometer.prometheus.PrometheusMeterRegistry; import io.micrometer.prometheus.PrometheusConfig; import io.micrometer.core.instrument.MeterRegistry; PrometheusMeterRegistry prometheusRegistry = new PrometheusMeterRegistry(PrometheusConfig.DEFAULT); // 你可以通过 MeterRegistry 来注册自定义指标 // prometheusRegistry.counter(\u0026quot;my_custom_counter\u0026quot;).increment();  3. 暴露 Prometheus 指标 HTTP 接口 # Micrometer 并不会自动暴露 HTTP 接口，你需要自己实现一个 HTTP 端点，例如用 Spring MVC 或其他 Web 框架：\nimport org.springframework.web.bind.annotation.GetMapping; import org.springframework.web.bind.annotation.RestController; @RestController public class PrometheusController { private final PrometheusMeterRegistry prometheusRegistry; public PrometheusController(PrometheusMeterRegistry prometheusRegistry) { this.prometheusRegistry = prometheusRegistry; } @GetMapping(\u0026quot;/prometheus\u0026quot;) public String scrape() { return prometheusRegistry.scrape(); } }  或者，如果不是 Spring 项目，可以用类似 Jetty、Undertow、Netty 等 WebServer 直接暴露 /prometheus 路径，将 prometheusRegistry.scrape() 的内容作为响应。最后使用 Prometheus 或 Categraf 来抓取这个端点即可。\nJMX # 如果你要监控的 Java 程序不是自研的程序，而是一个开源组件，比如 Tomcat、Kafka、Zookeeper 等，通常这些组件会通过 JMX 暴露监控指标。你可以使用如下提示词来提问 GPT：\n普通的 Java 中间件，比如 Tomcat、Kafka，应该如何采集其监控指标？   推荐使用 JMX Exporter，这是一个 jar 包，以 javaagent 的方式运行。 下载 jmx_exporter 的 jar 包 找到组件的启动命令，在启动参数中添加 javaagent 相关的参数，比如 -javaagent:/path/to/jmx_prometheus_javaagent-\u0026lt;version\u0026gt;.jar=PORT:/path/to/config.yaml 指定 jmx_exporter 的 jar 的路径、要暴露的指标端口以及配置文件的路径。  这样会在指定端口上暴露 Prometheus 指标（如 http://localhost:PORT/metrics）。然后使用 Prometheus 或 Categraf 来抓取这个端点即可。\n但是注意，不同的组件需要不同的配置文件，jmx_exporter 提供了很多例子，具体地址是：https://github.com/prometheus/jmx_exporter/tree/main/examples。你可以向 AI 继续提问：\n config.yaml 的配置项分别代表什么意思 Java MBean 是个什么东西 如何配置 JMX Exporter 采集某个特定的 MBean 把 jmx_exporter 提供的样例配置扔给 AI，让 AI 帮你分析一下这个配置的具体含义  组件自身暴露指标 # 有些组件自身就内置了一些方式来暴露监控指标，比如 Tomcat，在 HTTP 端点 /manager/status/all 上可以看到各类监控指标。Categraf 提供的 tomcat 采集插件就是基于这个端点来采集监控指标的。配置方法是：\n1、修改 tomcat-users.xml ，增加下面的内容，相当于是创建了一个用户来访问 /manager/status/all 端点：\n\u0026lt;role rolename=\u0026quot;admin-gui\u0026quot; /\u0026gt; \u0026lt;user username=\u0026quot;tomcat\u0026quot; password=\u0026quot;s3cret\u0026quot; roles=\u0026quot;manager-gui\u0026quot; /\u0026gt;  2、注释掉文件 webapps/manager/META-INF/context.xml 的以下内容：\n\u0026lt;Valve className=\u0026quot;org.apache.catalina.valves.RemoteAddrValve\u0026quot; allow=\u0026quot;127\\.\\d+\\.\\d+\\.\\d+|::1|0:0:0:0:0:0:0:1\u0026quot; /\u0026gt;  3、在 Categraf 的 conf/input.tomcat/tomcat.toml 中配置 Tomcat 采集地址和认证信息即可。\n 注意：JMX 方式是通用的，但是各个组件自身暴露指标的方式不尽相同，上面只是用 Tomcat 举例，其他的组件就需要分别查阅其文档了。\n ","description":"Java 类的程序如何监控？通常有如下几种方式：Actuator、Micrometer、JMX、组件自身暴露指标。本文介绍了这些方式的配置方法和使用场景。","title":"Java 类程序"},{"RelPermalink":"/zh/docs/usecase/alerting/","contents":"夜莺监控（Nightingale）的功能侧重点是告警引擎，为了做得灵活，整个告警流程涉及到的功能点比较多，本文从原理和数据流的角度，介绍一下相关知识，理解这些知识，对于您使用夜莺、排查告警问题，都会有帮助。\n数据流原理概述 #  用户在 Web UI 配置告警规则，规则保存在 DB 中（通常是 MySQL）。 告警引擎（n9e 进程内置一个告警引擎，边缘模式下 n9e-edge 进程里也内置告警引擎）从 DB 同步告警规则到内存中（通常 n9e-edge 无法直接读 DB，是调用的中心端 n9e 的接口获取的告警规则）。 告警引擎会为每条告警规则创建一个 goroutine（协程，姑且可以理解为轻量级线程），按照用户在告警规则里配置的频率，周期性查询存储，对数据做异常判定，最终生成告警事件。 产生告警事件后，要先持久化到 DB 中（通常是 MySQL），然后再走后面的通知规则。 通知规则包含两部分，一个是若干事件处理器（比如 relabel、event update、event drop、ai summary 等），另一个是若干告警通知配置（比如 Critical 的告警事件关联电话、短信通知媒介，Warning 的告警事件只关联邮件媒介）。  告警规则 # 告警规则核心就是配置一个查询条件，比如 Prometheus 数据源就是配置 PromQL，ClickHouse 数据源就是配置 SQL，然后再配置一个阈值（Prometheus 场景下，阈值包含在 PromQL 中，不需要单独配置），达到阈值并满足持续时长，就告警。\n告警引擎针对每条规则创建一个 goroutine（协程），周期性地查询数据源，判断是否满足告警条件。以 Prometheus 数据源举例，其原理是：\n 夜莺周期性调用数据源的 /api/v1/query 接口，把当前时间和 PromQL 作为查询条件传给这个接口。 数据源如果返回多条记录，大概率就要生成多条告警事件，接下来要看持续时长，如果持续时长为 0，立马生成告警事件，如果持续时长大于 0，就要把这条记录放到一个缓存中，等到持续时长满足条件后，再生成告警事件，在持续时长过程中，如果后面的执行周期查不到数据了，就会把这条记录从缓存中删除，也就不会生成告警事件了。  这里经常遇到的问题是，告警引擎在查询的时候没有查到数据，故而无法生成告警事件，但是后面排查的时候发现那个时间点却是有数据满足阈值的，百思不得其解，这种情况，可能的原因有两个：\n 因为监控数据的上报有延迟导致的，在这里夜莺只是一个 client，数据源是 server，数据源没有返回数据，就要去看 server 侧的问题，看 server 侧的数据为啥没有返回，通常是数据有各种因素延迟了。 查询超时了，日志文件里通常可以看到相关日志，可以在数据源配置页面调大查询超时时间，或者排查数据源为啥返回慢了，另外硬件方面也可能有问题，比如 client、server 两边是否有网卡丢包。超时的日志，可以检索关键字：alert-${datasource-id}-${alert-rule-id}  其中：\n ${datasource-id} 是数据源的 ID，在数据源详情页面可以看到 ${alert-rule-id} 是告警规则的 ID，编辑告警规则时，在 URL 中可以看到  告警问题排查时，首先要看是否产生了告警事件，如果产生了告警事件，说明告警规则没问题，接下来再排查后面通知相关的问题，如果告警事件都没有产生，那就是告警规则和数据源的问题，首先要确认告警规则的配置再谈其他。\n事件持久化 # 告警事件产生后需要写入 DB（通常是 MySQL），于是你才能在告警事件列表中看到这个事件。有时会写失败，写失败的话在日志里通常会有体现，排查 WARNING 和 ERROR 日志即可。\n告警规则关联通知规则 # 告警事件产生之后，应该走后续的哪个通知规则？即告警规则和通知规则如何建立关联关系？有两个办法建立关联关系：\n 告警规则里直接配置通知规则。即这个告警规则产生的所有告警事件，都要走这些通知规则。 告警规则里不配通知规则，而是配置订阅规则，即：在订阅规则里按照各种条件筛选告警事件，筛选到的告警事件，走订阅规则里配置的通知规则。  上面两种方式都可以，前者更直观，如果没有特殊需求，推荐使用前者。但是对于一些全局的事件处理，比如我想把夜莺监控中产生的所有告警事件都走一个 Callback 处理器，此时可以使用订阅规则，订阅所有的告警事件，统一关联一个全局通知规则，在这个全局通知规则里配置 Callback 处理器。\n通知规则配置 # 下图是通知规则的编辑页面，我在图中标注了各个区块的作用：\n大部分表单项的标题位置，都有一个小问号图标，鼠标悬停在上面会有提示信息，大家可以参考提示信息来配置。\n 💡 这个页面里包含一些通知测试的按钮，点击之后，可以选择已生成的告警事件做通知规则的测试，便于您快速验证通知规则是否符合预期。另外要注意，告警事件持久化发生在通知规则之前，所以通知规则里的各个事件处理器，不会对 DB 中的告警事件产生修改。\n 事件处理器 #  💡 事件 Pipeline 并没有一个单独的菜单入口，作为通知规则的一部分，是在通知规则的编辑页面里，点击「事件处理」区块的小齿轮图标可以展开事件处理器的配置侧拉板。\n 事件处理器是一个高级机制，允许您对告警事件做各种处理，比如：\n 对告警事件做 relabel，拆分一些标签，修改一些标签等 更新告警事件，夜莺把告警事件传给第三方（比如 CMDB ）接口，第三方可以对告警事件做修改，然后把修改之后的内容返回，继续走后续事件处理逻辑，方便与外部系统做打通 丢弃告警事件，一些告警事件不需要通知，可以在这里做复杂的判断，符合条件的丢弃掉 生成 AI 摘要，把告警事件传给 DeepSeek 等，让 AI 帮忙生成摘要和解法，把 AI 生成的内容放到事件中，后续通过通知媒介发出来  这里有两个概念要注意：\n 事件处理的 Pipeline，就是点击通知规则-事件处理右侧那个按钮展开的侧拉板，里边就是 Pipeline 的列表 每个 Pipeline 可以包含多个 Processor（处理器），如果想提高复用性，也可以简单来搞，每个 Pipeline 只包含一个 Processor。  每个处理器，页面上都有一个文档说明链接，点击之后可以查看详细的文档说明。也可以参考下面两个链接的资料：\n 事件处理器说明 自定义通知媒介 开源夜莺监控实现发版时告警静默  通知配置 # 这部分在前面已经讲解过，这里不再赘述，请参考：\n 通知规则设计初衷和使用说明  ","description":"夜莺监控（Nightingale）最重要的功能就是告警引擎。本文介绍了夜莺的告警原理和数据流，把整个告警流程中涉及到的相关功能都介绍一下。","title":"告警原理和流程说明"},{"RelPermalink":"/zh/docs/usecase/bizgroup/","contents":"夜莺中要管理很多东西，比如：告警规则、屏蔽规则、订阅规则、自愈脚本、仪表盘，在创建这些东西的时候，都要先选择一个业务组，因为这些东西都要归属到某个业务组。还有机器也是，安装了 categraf 之后，categraf 就会自动向夜莺注册机器信息，此时这个机器会出现在未归组机器列表种，管理员需要把这个机器归到某个业务组下，业务组的人才能使用。\n业务组在夜莺中使用频繁，本篇讲解夜莺监控中的业务组的概念，以及相关的设计初衷。\n需求来源 # 夜莺中要管理很多东西，比如：告警规则、屏蔽规则、订阅规则、自愈脚本、机器等。如果各个东西都放在一个表格里让大家查看、管理，那就比较混乱了，需要有个机制来分门别类。\n于是，我们引入了“业务组”的概念。业务组就是一个分组机制，比如 DBA 把 MySQL 的告警规则放到一个业务组里（组名姑且叫 DBA/MySQL），把 Postgres 的告警规则放到另一个业务组里（组名姑且叫 DBA/Postgres）；比如 Kubernetes 运维人员，按照集群对 Kubernetes 的宿主机做了拆分，不同的集群的机器放到不同的业务组下，比如分成 K8S/集群A、K8S/集群B 等等。\n演进 # 早期版本的夜莺，业务组渲染为扁平的列表，后来发现，其实业务组需要层级结构，比如上面的四个业务组：\n DBA/MySQL DBA/Postgres K8S/集群A K8S/集群B  渲染为树形结构的话就更方便查看：\nDBA ├── MySQL └── Postgres K8S ├── 集群A └── 集群B  所以新版本的夜莺，为了兼容老版本，业务组存储到 DB 的时候，仍然是扁平的列表，但在前端展示的时候，可以根据名称里的分隔符渲染为树形结构。比如上面的例子，名称里的分隔符是 /，当然你也可以使用其他分隔符，比如 -、_ 等等。在夜莺的菜单 系统配置-站点设置 里，可以设置业务组展示模式和分隔符。\n 🟢 推荐使用 / 作为分隔符。\n 问题 # 在夜莺里，业务组是全局共享的，既可以把规则挂到业务组上，也可以把机器挂到业务组上，这有个好处，就是方便复用业务组，即业务组创建一次之后，在多个地方都可以使用。\n但是这样做也有一个问题，那就是不同的东西，其分组的颗粒度是不同的。比如我们对机器分组的话，可能会分的比较细，比如：\n DBA/MySQL/Proxy/RegionA DBA/MySQL/Proxy/RegionB  但当我们对告警规则、仪表盘这些东西分组的时候，可能就不会分的那么细了，比如 DBA 所有的仪表盘，可能全部放在 DBA 下面就好了。\n这个问题目前不好解决，除非业务组不搞成全局复用的，机器有机器的分组，告警规则有告警规则的分组，仪表盘有仪表盘的分组，这样就会导致有些业务组要重复创建，在机器那创建完了还要在告警规则那再创建一次。鱼与熊掌不可兼得。\n划分业务组的最佳实践 # 虽然业务组既可以用于各类规则的分类，也可以用于机器的分组，但是颗粒度不同，通常机器的分组颗粒度更细，而规则的分组颗粒度较粗。通常，先按照机器分组来规划业务组，然后各类规则、仪表盘等挂到中间层级的业务组上就差不多了。下面咱们先说机器的分组。\n不知道读者是否听过“服务树”这个概念，业务组的划分和“服务树”是类似的，通常来讲，顶层是对组织结构的建模，即顶层节点是部门、业务、团队之类的这种信息，比如：\n 基础架构/运维/容器云 是运维团队里的容器云团队 基础架构/运维/数据库 是运维团队里的数据库运维团队 XBU/业务1/产品1 是某个 BU 下面的业务1下面的产品1团队 XBU/业务1/产品2 是某个 BU 下面的业务1下面的产品2团队  如果公司的组织架构比较扁平，这个信息的层级会少一些，如果公司组织架构的层级比较多，可以多加几层。\n顶层是对组织结构的建模，中层是对系统服务建模，通常中层分两层，系统-模块，比如 Kubernetes 是一个系统，里边的 apiserver、etcd、scheduler 等是不同的模块。\n最后说业务组的底层，底层通常是按照集群划分，比如量确实很大，集群上面还可以引入地域的概念，如果量没那么大，只需要按集群划分即可，如果只有一个集群，取消底层集群节点都是可以的。\n于是，最终容器云平台的业务组可能是这么划分的：\n 基础架构/运维/容器云/KubeUI/Webapi/华南集群 基础架构/运维/容器云/KubeUI/Webapi/华北集群 基础架构/运维/容器云/KubeUI/Report/华南集群 基础架构/运维/容器云/KubeUI/Report/华北集群 基础架构/运维/容器云/Kubernetes/etcd/华南集群 基础架构/运维/容器云/Kubernetes/etcd/华北集群 基础架构/运维/容器云/Kubernetes/apiserver/华南集群 基础架构/运维/容器云/Kubernetes/apiserver/华北集群 基础架构/运维/容器云/Kubernetes/scheduler/华南集群 基础架构/运维/容器云/Kubernetes/scheduler/华北集群 基础架构/运维/容器云/Kubernetes/node/华南集群 基础架构/运维/容器云/Kubernetes/node/华北集群  业务组按照机器的颗粒度划分完了之后，规则之类的应该挂在上层，比如 Webapi 的告警规则，可以专门创建一个 基础架构/运维/容器云/KubeUI/Webapi-Rules 的业务组，然后把 Webapi 的告警规则挂到这个业务组上。\n如果 Webapi 和 Report 的告警规则都很少，直接一并创建一个 基础架构/运维/容器云/KubeUI-Rules 的业务组，把 Webapi 和 Report 的告警规则都挂到这个业务组上，也是可以的。\n仪表盘通常更少，直接创建一个 基础架构/运维/容器云-Dashboards 的业务组，容器云团队所有的仪表盘都挂到这个业务组上，就可以了。\n当然，上面的划分逻辑只是一个思路参考，无法适合所有公司，比如有些企业主要用夜莺监控一堆设备（分散在不同地域、工厂），不是服务，那在业务组划分的时候，可以考虑按照地域、工厂等维度进行划分。\nFAQ # 找不到业务组操作入口 # Question：V8 新版本，在人员组织下面怎么找不到业务组的菜单了，那如何对业务组增删改查？\nAnswer：业务组出现在很多个功能菜单下面，比如告警规则、屏蔽规则、仪表盘、自愈脚本等，可以直接在这些地方对业务组进行增删改查，不需要到一个单独的业务组菜单去操作了。鼠标挪到业务组上，会自动出现编辑 icon，点击编辑 icon 可以对业务组进行编辑、删除，业务组上面有个小加号的 icon，可以新增业务组。\n","description":"夜莺监控（Nightingale）中的业务组概念，如何划分业务组，以及相关的设计初衷。业务组的划分和服务树类似，通常顶层是组织结构建模，中层是系统服务建模，底层是集群划分。","title":"业务组"},{"RelPermalink":"/zh/docs/usecase/mute/","contents":"夜莺监控（Nightingale）中的屏蔽规则（菜单入口：告警-规则管理-屏蔽规则TAB）通常用于下面的场景：\n 提前屏蔽掉预期内的告警，典型的就是做一些维护动作，比如某个机器要重启，提前屏蔽这个机器相关的告警 有些问题急忙修复不了，已经知悉，持续告警通知也没意义，就先临时屏蔽掉  原理 # 告警事件经由告警引擎产生后，在持久化到 DB 之前，会先经过屏蔽规则的判断，如果匹配了屏蔽规则，就不会持久化到 DB，更无法通知用户。工作时机如下图：\n屏蔽规则，本质上就是配置了一堆过滤条件，用于过滤想要屏蔽的告警事件。如何过滤呢，显然，就是根据告警事件的属性和标签来过滤。比如：\n 事件是哪个数据源产生的 事件的级别 事件的标签  比如下面的例子：\n 数据源类型：Prometheus，只有数据源类型是 Prometheus 的告警事件，才会被屏蔽 数据源：没配，表示不做限制 事件等级：三个级别都勾选了，表示所有级别的告警事件都要被屏蔽 事件标签：配置了两个标签，相当于：ident in (\u0026quot;10,1.2.3\u0026quot;, \u0026quot;10.1.2.4\u0026quot;) and rulename =~ \u0026quot;宕机\u0026quot;  上面所有的过滤条件，整体是and 的关系，即所有的条件都命中了某个事件，那个事件才会被屏蔽。\nFAQ # 1. 我已经配置了屏蔽规则，相关告警事件为啥还是可以看到？\n通常是因为：事件先产生了，才去配置的屏蔽规则。屏蔽规则是事后补救的，不能对已经产生的事件起作用。\n2. 事件标签里的多个条件也是 and 关系，但是用户没有理解\n如下图，用户在事件标签过滤那里，配置了两个条目，标签 key 都是 ident：\n用户的本意是 10.1.2.113 和 10.1.2.114 这俩机器任意一台都要被屏蔽，但是事与愿违，这里是 and 的关系，相当于是：ident = \u0026quot;10.1.2.113\u0026quot; and ident = \u0026quot;10.1.2.114\u0026quot;，显然，这个条件永远不会命中任何事件。实际上，用户应该使用 in 操作符，如下所示：\n3. 屏蔽规则的生效范围，仅限当前业务组\n这个其实在页面上有提示。为了避免误操作，屏蔽规则的生效范围仅限当前业务组。也就是说，屏蔽规则只能屏蔽当前业务组下的告警事件，其他业务组下的告警事件不会受影响。\n即：屏蔽规则和告警规则如果在不同业务组下，屏蔽规则不会对其生效。\n如果屏蔽规则是全局生效的，就会比较危险，比如某个用户随便配置了一个告警规则，过滤条件可以匹配所有告警事件，那么公司所有的告警事件都会被屏蔽。\n","description":"夜莺监控（Nightingale）中的屏蔽规则，如何配置屏蔽规则，以及相关的设计初衷。屏蔽规则可以屏蔽告警事件，避免告警事件打扰到用户。","title":"屏蔽规则"},{"RelPermalink":"/zh/docs/usecase/subscribe/","contents":"夜莺监控（Nightingale）中的订阅规则，其菜单入口在：告警-规则管理-订阅规则TAB。\n为何有此设计 # 夜莺的告警规则中，可以直接配置通知规则，很直观，这个告警规则产生的告警事件就走这个通知规则。Datadog、Open-Falcon 都是类似这样的设计，基本是够用的。但是如果你了解 Zabbix、Prometheus，你会发现，它们产生告警事件之后，要发给谁，其实走的是一个后续订阅的逻辑，即：\n 告警规则中，只定义查询条件、阈值等，即告警规则仅是负责事件产生，至于如何通知、通知给谁，告警规则不管这些 用户使用订阅的机制，从所有告警事件中做筛选，对这些筛到的告警事件，指定相关的通知规则（通知给谁、如何通知）  这种方式实际上更灵活，缺点就是不够直观。夜莺呢？两种方式都支持，对于普通用户，优先建议使用“在告警规则中直接配置通知规则”的方式，把“订阅规则”，用在一些相对少见的场景，比如：\n 我的服务依赖了其他服务，这些服务不归我管（这些服务的告警规则通知给它们的负责人，而不是通知给我），但是这些服务如果故障，可能会影响我的服务，所以我希望订阅这些服务的 SLI 相关的告警事件（这是社区某些用户提到的需求场景，虽然写在这里，但是笔者实际不认可请你自行斟酌，笔者认为，每个服务都应该制作一个仪表盘，仪表盘里罗列了依赖的其他服务的 SLI 数据，自己的服务出故障时，应该统一去看这个仪表盘来判断是自身的问题还是依赖的下游服务的问题） 某些通用告警规则产生的告警事件，希望分发给不同的人，此时没法在告警规则中直接绑定通知规则，此时可以搭配订阅规则来实现 一些全局的操作，比如全局回调，可以通过订阅规则来实现。比如希望：对于系统产生的任何一条告警事件，都要回调某个 Webhook 地址，此时可以配置一个全局的订阅规则，匹配所有的告警事件，然后配置一个 Webhook 通知规则。   💡 请认真阅读上面这段文字，理解订阅规则的设计初衷。非常非常非常重要。\n 配置方法 # 订阅规则包含三部分配置：\n 名称：订阅规则的名称，建议使用有意义的名称，让别人一眼看到就知道这个订阅规则是干什么用的，方便维护 筛选配置：各个维度筛选告警事件，注意，是筛选告警事件，筛选到的这些告警事件，就会走下面的通知规则 通知规则：筛选到的告警事件，走这些通知规则  整体逻辑比较清晰，其中筛选配置的配置项较多，下面逐一介绍。\n 数据源类型：用于筛选告警事件是经由哪个数据源类型产生的 数据源：用于筛选告警事件是经由哪个数据源产生的 事件等级：用于筛选告警事件的级别，可以选择多个级别，默认全选，相当于 severity in (\u0026quot;Info\u0026quot;, \u0026quot;Warning\u0026quot;, \u0026quot;Critical\u0026quot;)，全选其实就相当于在“事件等级”这个维度上不做筛选过滤 订阅告警规则：用于筛选告警事件是哪个告警规则产生的 业务组：用于筛选告警事件是哪个业务组产生的，告警事件肯定是某个告警规则触发的，所以告警事件的业务组就是告警规则所属的业务组（当前版本是v8.0.0，后续会考虑优化这个地方，后续会同时考虑告警事件中的机器所属的业务组） 事件标签：用于筛选告警事件的标签，注意运算符的用法，具体解释放在下面 订阅事件持续时长：右侧有个小问号的 icon，提供了这个功能的使用说明，这里不再赘述。  上面的各个筛选条件，不同的条目之间整体是 and 的关系，其中事件标签这部分可以配置多个过滤条目，不同条目之间也是 and 的关系，如果你想匹配多个标签值，可以使用 in 操作符，或者使用正则表达式 =~。\n对于运算符，具体解释如下：\n == 匹配某个具体的标签值，只能填写一个，如果想同时匹配多个，应该使用 in 操作符 =~ 填写正则表达式，灵活匹配标签值 in 匹配多个标签值，类似 SQL 里的 in 操作 not in 不匹配的标签值，可填写多个，类似 SQL 里的 not in 操作，用于排除多个标签值 != 不等于，用于排除特定的某个标签值 !~ 正则不匹配，填写正则，匹配这个正则的标签值都将被排除，类似 PromQL 中的 !~  场景举例：订阅所有时序告警 # 比如我想订阅所有时序指标相关的告警，然后统一走一个 Webhook 通知规则，用于一些自动化处理逻辑。此时可以配置数据源类型为 Prometheus，事件级别全选，然后其他所有过滤条件都不配置。\n","description":"讲解夜莺监控（Nightingale）中的订阅规则，适用于一些特殊的告警事件通知场景，比如全局的回调、细颗粒度的通知控制等。","title":"订阅规则"},{"RelPermalink":"/zh/docs/usecase/processor/","contents":"事件处理器（Event Processor）是夜莺 v8 版本引入的一个概念，当告警事件产生之后，在发送通知之前，可以使用事件处理器对告警事件做额外的处理，开源版本支持 Relabel、Callback、Event Update、Event Drop、AI Summary 5 类处理器，不同的处理器可以组成一个 Pipeline，对告警事件做一系列灵活的处理。场景比如：\n 跟内部的 CMDB 打通，附加一些更丰富的信息到告警事件上 调用 DeepSeek 的接口，对告警事件做一些智能分析，然后把分析结果附加到告警事件上 把所有告警事件发送到自己的系统，相当于镜像一份，做后续的分析处理 一些特定的告警事件可以 Drop 掉，比如一些恢复事件不想发送通知  这里涉及多个概念，通知规则、事件处理器（Processor）、事件处理管道（Pipeline），稍作解释：\n 一个通知规则里可以配置多个事件处理管道（Pipeline），顺序执行 一个事件处理管道（Pipeline）里可以配置多个事件处理器（Processor），也是顺序执行  上面的截图可以看出，入口菜单在 通知-通知规则，通知规则可能会有很多，在新增或编辑某个具体的通知规则时，可以看到有个 事件处理 的配置区域，这里可以引用多个提前创建好的事件管道（Pipeline），那在哪里对事件管道（Pipeline）增删改呢？入口比较隐藏，在 事件处理 右侧那个小齿轮里，点击可以展开一个侧拉板，在侧拉板里对事件管道（Pipeline）增删改。\n创建、编辑事件管道（Pipeline）时，又会展开一个新的侧拉板，在这个新侧拉板里编辑 Pipeline，我们可以在 Pipeline 里配置多个事件处理器（Processor）：\n点击事件处理器类型字段旁边的 使用说明 可以查看事件处理器的使用说明文档。\nRelabel 处理器 # Relabel 处理器，类似 Prometheus 中对监控指标的 Relabel 操作，只不过夜莺这里，是对告警事件的 Relabel，告警事件里也有标签字段，也有需求对标签做一些加工处理，所以这里提供了 Relabel 处理器。\nRelabel 处理器的具体使用说明，在夜莺的页面上点击事件处理器类型字段旁边的 使用说明，即可查看。\nCallback 处理器 # 事件触发后，夜莺可以通过 Callback 通知外部系统，外部系统可以根据事件内容进行自动化处理。比如我见过有些公司自研了一套告警通知的系统，不用夜莺的通知机制，就直接把所有告警事件通过 Callback 处理器发送到自研的系统。\n下面做一个简单的演示：\n 首先创建一个“通知规则”，因为 Callback 处理器属于某个 Pipeline，而 Pipeline 又属于某个通知规则。 在“通知规则”里，引用事件处理的 Pipeline，Pipeline 需要提前创建好（在通知规则编辑页面，点击处理器右侧的小齿轮打开侧拉板，在侧拉板里创建、编辑 Pipeline），下面截图是一个 Pipeline 的详情页面，里边有一个 Callback 处理器。   这里的 http://10.99.1.107:8888/print 是我的一个测试程序，可以把接收到的 HTTP 请求打印出来，方便演示。这个程序也是一个开源小程序，地址在 github gohttpd。\n 创建了 Pipeline 之后，回到通知规则页面，在事件处理那里，选择刚才创建的 Pipeline。\n接下来，就可以去配置“告警规则”做测试了，测试一下产生的告警能否被第三方程序接收到。\n为了尽快看到效果，可以创建一个肯定会触发阈值的告警规则，然后在通知规则那里，选择刚才创建的通知规则：\n稍等片刻，去观察 http://10.99.1.107:8888/print 这个程序是否收到回调的 HTTP 请求。我的环境里看到的结果如下：\n从上图可以看出，HTTP request 中包含了告警事件的信息，其内容如下：\n{ \u0026quot;id\u0026quot;: 1097371, \u0026quot;cate\u0026quot;: \u0026quot;prometheus\u0026quot;, \u0026quot;cluster\u0026quot;: \u0026quot;prom\u0026quot;, \u0026quot;datasource_id\u0026quot;: 1, \u0026quot;group_id\u0026quot;: 2, \u0026quot;group_name\u0026quot;: \u0026quot;DBA-Postgres\u0026quot;, \u0026quot;hash\u0026quot;: \u0026quot;54f5543591c6dc0e30139cae196a1eee\u0026quot;, \u0026quot;rule_id\u0026quot;: 54, \u0026quot;rule_name\u0026quot;: \u0026quot;测试事件回调\u0026quot;, \u0026quot;rule_note\u0026quot;: \u0026quot;\u0026quot;, \u0026quot;rule_prod\u0026quot;: \u0026quot;metric\u0026quot;, \u0026quot;rule_algo\u0026quot;: \u0026quot;\u0026quot;, \u0026quot;severity\u0026quot;: 2, \u0026quot;prom_for_duration\u0026quot;: 0, \u0026quot;prom_ql\u0026quot;: \u0026quot;cpu_usage_active{ident=\\\u0026quot;ulric-flashcat.local\\\u0026quot;} \\u003e 0\u0026quot;, \u0026quot;rule_config\u0026quot;: { \u0026quot;queries\u0026quot;: [{ \u0026quot;from\u0026quot;: 0, \u0026quot;prom_ql\u0026quot;: \u0026quot;cpu_usage_active{ident=\\\u0026quot;ulric-flashcat.local\\\u0026quot;} \\u003e 0\u0026quot;, \u0026quot;range\u0026quot;: { \u0026quot;display\u0026quot;: \u0026quot;now-undefineds to now-undefineds\u0026quot;, \u0026quot;end\u0026quot;: \u0026quot;now-undefineds\u0026quot;, \u0026quot;start\u0026quot;: \u0026quot;now-undefineds\u0026quot; }, \u0026quot;severity\u0026quot;: 2, \u0026quot;to\u0026quot;: 0, \u0026quot;unit\u0026quot;: \u0026quot;none\u0026quot; }] }, \u0026quot;prom_eval_interval\u0026quot;: 15, \u0026quot;callbacks\u0026quot;: [], \u0026quot;runbook_url\u0026quot;: \u0026quot;\u0026quot;, \u0026quot;notify_recovered\u0026quot;: 1, \u0026quot;target_ident\u0026quot;: \u0026quot;ulric-flashcat.local\u0026quot;, \u0026quot;target_note\u0026quot;: \u0026quot;\u0026quot;, \u0026quot;trigger_time\u0026quot;: 1749180264, \u0026quot;trigger_value\u0026quot;: \u0026quot;33.06867\u0026quot;, \u0026quot;trigger_values\u0026quot;: \u0026quot;\u0026quot;, \u0026quot;trigger_values_json\u0026quot;: { \u0026quot;values_with_unit\u0026quot;: { \u0026quot;v\u0026quot;: { \u0026quot;value\u0026quot;: 33.06867479671808, \u0026quot;unit\u0026quot;: \u0026quot;\u0026quot;, \u0026quot;text\u0026quot;: \u0026quot;33.07\u0026quot;, \u0026quot;stat\u0026quot;: 33.06867479671808 } } }, \u0026quot;tags\u0026quot;: [\u0026quot;__name__=cpu_usage_active\u0026quot;, \u0026quot;cpu=cpu-total\u0026quot;, \u0026quot;ident=ulric-flashcat.local\u0026quot;, \u0026quot;rulename=测试事件回调\u0026quot;], \u0026quot;tags_map\u0026quot;: { \u0026quot;__name__\u0026quot;: \u0026quot;cpu_usage_active\u0026quot;, \u0026quot;cpu\u0026quot;: \u0026quot;cpu-total\u0026quot;, \u0026quot;ident\u0026quot;: \u0026quot;ulric-flashcat.local\u0026quot;, \u0026quot;rulename\u0026quot;: \u0026quot;测试事件回调\u0026quot; }, \u0026quot;original_tags\u0026quot;: [\u0026quot;\u0026quot;, \u0026quot;\u0026quot;, \u0026quot;\u0026quot;, \u0026quot;\u0026quot;], \u0026quot;annotations\u0026quot;: {}, \u0026quot;is_recovered\u0026quot;: false, \u0026quot;last_eval_time\u0026quot;: 1749180264, \u0026quot;last_sent_time\u0026quot;: 1749180264, \u0026quot;notify_cur_number\u0026quot;: 1, \u0026quot;first_trigger_time\u0026quot;: 1749180264, \u0026quot;extra_config\u0026quot;: { \u0026quot;enrich_queries\u0026quot;: [] }, \u0026quot;status\u0026quot;: 0, \u0026quot;claimant\u0026quot;: \u0026quot;\u0026quot;, \u0026quot;sub_rule_id\u0026quot;: 0, \u0026quot;extra_info\u0026quot;: null, \u0026quot;target\u0026quot;: null, \u0026quot;recover_config\u0026quot;: { \u0026quot;judge_type\u0026quot;: 0, \u0026quot;recover_exp\u0026quot;: \u0026quot;\u0026quot; }, \u0026quot;rule_hash\u0026quot;: \u0026quot;dc128d86d65326499bd03ecfbe56e4c3\u0026quot;, \u0026quot;extra_info_map\u0026quot;: null, \u0026quot;notify_rule_ids\u0026quot;: [3], \u0026quot;notify_version\u0026quot;: 0, \u0026quot;notify_rules\u0026quot;: null }  测试正常。如果您有类似需求，就可以使用这种 Callback 处理器来对接，在您的程序中做一些自动化的逻辑。\nEvent Update 处理器 # 事件处理器中，还有一个 Event Update 处理器，和 Callback 的配置方式一样，这俩工作逻辑也很像，区别如下：\n夜莺在调用 Callback 地址的时候，是不关注 HTTP Response 的，而在调用 Event Update 的时候，会把 HTTP Response 的内容作为新的告警事件走后续处理。\n所以，Event Update 如其名，就是用来修改告警事件的。通常用于附加一些额外信息到告警事件中，比如：\n 把事件交给 AI 分析，得到一些结论性质的信息，附加到事件中 去 CMDB 查询一些元信息，附加到事件中  注意，告警事件的结构不能乱改，比如直接在 JSON 顶层增加一个字段，后续流程是不认的。通常建议把新内容附加到 annotations 字段，我上面 Callback 处理器的例子中，annotations 是空的所以看不出来数据结构，实际 annotations 是一个 map 结构，map key 和 map value 都是字符串类型，你要附加内容的时候，也需要遵循这个结构。\n 高级玩家也可以修改 Event 的其他字段，但是你得清楚你的修改对后续的影响，普通用户就只需要把内容附加到 annotations 字段，然后把整个新的 Event 序列化为 JSON 放到 HTTP Response 的 body 中即可。\n Event Drop 处理器 # 事件处理器中，还有一个 Event Drop 处理器，顾名思义，就是用来丢弃告警事件的。比如：\n 有些场景，虽然产生了告警事件，但是不想走后面的通知逻辑，就可以使用 Event Drop 处理器来丢弃这个事件。  要 Drop 掉一些告警事件，那肯定要做过滤，通常可以利用标签、注解、级别等各种字段做过滤，这个过滤规则可能会写的很复杂，那这个功能怎么设计才能如此灵活呢？我们想了一个稍微复杂但是极度灵活的办法，就是用户直接使用 go template 语法配置一段 template，template 中可以引用告警事件，使用 if 等语法来做过滤。只要这个 go template 最终渲染的结果是 true，就会丢弃这个事件。\n具体使用说明，在夜莺的页面上点击 Event Drop 事件处理器类型字段旁边的 使用说明，即可查看。\nAI Summary 处理器 # AI Summary 处理器的文档也很齐全，如下图：\n点击 AI Summary 事件处理器类型字段旁边的 使用说明，即可查看 AI Summary 处理器的使用说明文档。下面各个字段右侧都有一个小问号的 icon，鼠标挪上去也可以看到相关提示说明。\n","description":"夜莺监控 Nightingale 使用事件处理器（Event Processor）进行事件自动化处理。可以和第三方系统联动，自动化处理告警事件。","title":"事件处理器 Pipeline"},{"RelPermalink":"/zh/docs/usecase/media/","contents":" 在阅读本节之前，请一定确保你已经阅读过《通知规则》章节的内容，而且《通知规则》章节中提到的那些外部链接资料，也都阅读过了。\n 下面我来模拟一个场景。假设我想使用企微应用（和企微机器人不是一个东西）来做告警通知，我们来捋一下整个流程。\n基础配置 # 1、企微应用通知的时候，需要知道被通知的人的企微账号。夜莺里默认没有这个信息，我们可以自定义一个 wecomid 的联系方式的字段，然后各个用户自行配置一下。\n上图中，wecomid 是我自定义的字段名，点击那个“联系方式管理”（只有管理员有权限），可以创建新的联系方式，这里我创建了一个新的联系方式叫 wecomid，用于配置各个用户的企微 ID。\n2、创建一个自定义通知媒介，对应我自己的程序，当用户在夜莺里配置要发告警消息给这个通知媒介的时候，夜莺就会调用我的程序，我的程序就会去调用企微接口，使用企微应用的方式发送通知消息（当然，我这里不是实际发送，只是一个演示，仍然使用在 事件处理器 章节介绍的 gohttpd 小程序做演示）。\n上图通知媒介的几个关键字段解释如下：\n 媒介类型：可以自定义，我这里随便取了个名字叫 wecomapp，通知媒介通常要和消息模板配合使用，只要消息模板的媒介类型也叫 wecomapp，媒介和消息模板就可以关联起来了。 联系方式：选择刚才创建的 wecomid 联系方式，这样夜莺在调用我的程序的时候，就会把告警接收人的企微ID传给我。 URL：我的程序的地址，夜莺会通过 HTTP POST 的方式调用这个地址，请求体的内容可以在下面定义。 请求体：用于定义回调的 HTTP request body 内容，可以引用几个变量，这个例子里我把三个关键变量都引用了  我的请求体：\n{ \u0026quot;events\u0026quot;: {{ jsonMarshal $events }}, \u0026quot;sendtos\u0026quot;: {{ jsonMarshal $sendtos }}, \u0026quot;tpl\u0026quot;: {{ jsonMarshal $tpl }} }   $events 是要发送的告警事件列表，虽然是个列表，实际开源版永远都只会有一条事件 $sendtos 是要发送给哪些接收者，最终是一个企微ID的列表，如果联系方式那里配置的是 Phone，这个 $sendtos 就是手机号列表 $tpl 是消息模板的内容，下面马上介绍  消息模板 # 最终在调用企微的接口发告警消息的时候，显然不是要把整个事件 JSON 发出来，那用户没法看。我们需要把事件格式化展示（比如 markdown 的方式），就像其他的通知媒介，都有对应的消息模板，自定义的通知媒介也需要有消息模板。下面我们就创建一个消息模板：\n消息模板里可以创建多个字段（比如邮件模板，就需要自定义标题和内容，所以有两个字段），不过在企微应用这个场景里，不需要多个字段，我们就创建一个 content 字段即可，后面我们可以使用 markdown 格式来定义 content 字段的内容。比如：\n我把 markdown 里的内容也贴出来供你参考：\n**规则标题**: {{$event.RuleName}} **监控指标**: {{$event.TagsJSON}} **发送时间**: {{timestamp}}  我这里仅仅演示，所以 markdown 里渲染的字段比较少，你后面可以参考其他的模板来丰富这个内容。\n 💡 注意，消息模板的媒介类型需要和通知媒介的媒介类型一致，这样才能关联起来，故而我这里还是写的 wecomapp。\n 测试 # 现在我们就可以去测试一下了，创建一个通知规则：\n为了方便测试，我这个通知规则没有配置任何过滤条件，即任何一个告警事件产生都会发给“企微应用”这个自定义通知媒介。\n最后，我们去创建一个告警规则，关联刚才创建的通知规则：\n稍等片刻，去观察 http://10.99.1.107:8888/print 这个程序是否收到回调的 HTTP 请求。我的环境里看到的结果如下：\n我把 HTTP request body 的内容贴出来给你参考：\n{ \u0026quot;events\u0026quot;: [{ \u0026quot;id\u0026quot;: 1097655, \u0026quot;cate\u0026quot;: \u0026quot;prometheus\u0026quot;, \u0026quot;cluster\u0026quot;: \u0026quot;prom\u0026quot;, \u0026quot;datasource_id\u0026quot;: 1, \u0026quot;group_id\u0026quot;: 2, \u0026quot;group_name\u0026quot;: \u0026quot;DBA-Postgres\u0026quot;, \u0026quot;hash\u0026quot;: \u0026quot;f75556af7cedbe250d3d8ab709634c96\u0026quot;, \u0026quot;rule_id\u0026quot;: 56, \u0026quot;rule_name\u0026quot;: \u0026quot;测试自定义通知媒介2\u0026quot;, \u0026quot;rule_note\u0026quot;: \u0026quot;\u0026quot;, \u0026quot;rule_prod\u0026quot;: \u0026quot;metric\u0026quot;, \u0026quot;rule_algo\u0026quot;: \u0026quot;\u0026quot;, \u0026quot;severity\u0026quot;: 2, \u0026quot;prom_for_duration\u0026quot;: 0, \u0026quot;prom_ql\u0026quot;: \u0026quot;cpu_usage_active{ident=\\\u0026quot;ulric-flashcat.local\\\u0026quot;} \\u003e 0\u0026quot;, \u0026quot;rule_config\u0026quot;: { \u0026quot;queries\u0026quot;: [{ \u0026quot;from\u0026quot;: 0, \u0026quot;prom_ql\u0026quot;: \u0026quot;cpu_usage_active{ident=\\\u0026quot;ulric-flashcat.local\\\u0026quot;} \\u003e 0\u0026quot;, \u0026quot;range\u0026quot;: { \u0026quot;display\u0026quot;: \u0026quot;now to now\u0026quot;, \u0026quot;end\u0026quot;: \u0026quot;now\u0026quot;, \u0026quot;start\u0026quot;: \u0026quot;now\u0026quot; }, \u0026quot;severity\u0026quot;: 2, \u0026quot;to\u0026quot;: 0, \u0026quot;unit\u0026quot;: \u0026quot;none\u0026quot; }] }, \u0026quot;prom_eval_interval\u0026quot;: 15, \u0026quot;callbacks\u0026quot;: [], \u0026quot;runbook_url\u0026quot;: \u0026quot;\u0026quot;, \u0026quot;notify_recovered\u0026quot;: 1, \u0026quot;target_ident\u0026quot;: \u0026quot;ulric-flashcat.local\u0026quot;, \u0026quot;target_note\u0026quot;: \u0026quot;\u0026quot;, \u0026quot;trigger_time\u0026quot;: 1749196393, \u0026quot;trigger_value\u0026quot;: \u0026quot;33.06867\u0026quot;, \u0026quot;trigger_values\u0026quot;: \u0026quot;\u0026quot;, \u0026quot;trigger_values_json\u0026quot;: { \u0026quot;values_with_unit\u0026quot;: { \u0026quot;v\u0026quot;: { \u0026quot;value\u0026quot;: 33.06867479671808, \u0026quot;unit\u0026quot;: \u0026quot;\u0026quot;, \u0026quot;text\u0026quot;: \u0026quot;33.07\u0026quot;, \u0026quot;stat\u0026quot;: 33.06867479671808 } } }, \u0026quot;tags\u0026quot;: [\u0026quot;__name__=cpu_usage_active\u0026quot;, \u0026quot;cpu=cpu-total\u0026quot;, \u0026quot;ident=ulric-flashcat.local\u0026quot;, \u0026quot;rulename=测试自定义通知媒介2\u0026quot;], \u0026quot;tags_map\u0026quot;: { \u0026quot;__name__\u0026quot;: \u0026quot;cpu_usage_active\u0026quot;, \u0026quot;cpu\u0026quot;: \u0026quot;cpu-total\u0026quot;, \u0026quot;ident\u0026quot;: \u0026quot;ulric-flashcat.local\u0026quot;, \u0026quot;rulename\u0026quot;: \u0026quot;测试自定义通知媒介2\u0026quot; }, \u0026quot;original_tags\u0026quot;: [\u0026quot;\u0026quot;, \u0026quot;\u0026quot;, \u0026quot;\u0026quot;, \u0026quot;\u0026quot;], \u0026quot;annotations\u0026quot;: {}, \u0026quot;is_recovered\u0026quot;: false, \u0026quot;last_eval_time\u0026quot;: 1749196393, \u0026quot;last_sent_time\u0026quot;: 1749196393, \u0026quot;notify_cur_number\u0026quot;: 1, \u0026quot;first_trigger_time\u0026quot;: 1749196393, \u0026quot;extra_config\u0026quot;: { \u0026quot;enrich_queries\u0026quot;: [] }, \u0026quot;status\u0026quot;: 0, \u0026quot;claimant\u0026quot;: \u0026quot;\u0026quot;, \u0026quot;sub_rule_id\u0026quot;: 0, \u0026quot;extra_info\u0026quot;: null, \u0026quot;target\u0026quot;: null, \u0026quot;recover_config\u0026quot;: { \u0026quot;judge_type\u0026quot;: 0, \u0026quot;recover_exp\u0026quot;: \u0026quot;\u0026quot; }, \u0026quot;rule_hash\u0026quot;: \u0026quot;3c73b1b7f98f4c5a0178c85dedabf008\u0026quot;, \u0026quot;extra_info_map\u0026quot;: null, \u0026quot;notify_rule_ids\u0026quot;: [4], \u0026quot;notify_version\u0026quot;: 0, \u0026quot;notify_rules\u0026quot;: null }], \u0026quot;sendtos\u0026quot;: [\u0026quot;qinxiaohui\u0026quot;], \u0026quot;tpl\u0026quot;: { \u0026quot;content\u0026quot;: \u0026quot;**规则标题**: 测试自定义通知媒介2 \\\\n**监控指标**: [__name__=cpu_usage_active cpu=cpu-total ident=ulric-flashcat.local rulename=测试自定义通知媒介2] \\\\n**发送时间**: 2025-06-06 15:53:13 \u0026quot; } }  这个 request body 中不但有事件详情，还有 tpl，tpl 是渲染好的内容，你可以直接拿着这个内容去调用企微的接口。其中 sendtos 是企微 ID 的列表，因为我们在企微应用这个通知媒介里配置的联系方式是 wecomid，所以最终的 sendtos 里就是企微 ID 的列表，如果你在通知媒介里配置的联系方式是 Phone，那么 sendtos 里就是手机号的列表。\n数据都拿到了，后面就是你的自定义逻辑以及调用企微的接口了。这里我使用 gohttpd 只是为了演示请求体的内容，显然 gohttpd 工具不具备发送企微应用消息的能力，你需要自己实现这个逻辑。即：需要你自己写一个程序，监听 HTTP 端口，提供一个 HTTP POST 接口，就像上面的 gohttpd 一样，接收夜莺的回调请求，然后解析请求体，拿到事件详情、接收人列表和消息模板内容，最后调用企微的接口发送消息。\n","description":"夜莺监控 Nightingale 支持自定义通知媒介，可以通过 HTTP、脚本等方式发送告警事件。本文介绍如何使用企微应用作为自定义通知媒介，发送告警事件通知。","title":"自定义通知媒介"},{"RelPermalink":"/zh/docs/usecase/sso/","contents":"夜莺监控（Nightingale）支持单点登录（SSO）功能，支持 LDAP、CAS、OAuth2、OIDC 等多种协议。SSO 功能可以让用户通过统一的身份认证系统登录夜莺监控，简化用户管理和登录流程，也降低了安全风险。\n对于 CAS、OAuth2、OIDC 三种方式，用户通过 SSO 登录夜莺之后，夜莺会判断当前登录的用户是否存在于夜莺的用户表中，如果不存在，则会自动创建一个用户，如果存在，夜莺会用 SSO 中的用户信息覆盖夜莺中已有用户的信息（前提是配置项 CoverAttributes = true，后文会介绍），这样的好处是用户只需要在 SSO 那里维护手机号、邮箱即可，夜莺会在用户登录时自动同步（当然，仅是在登录时同步，所以用户至少要通过 SSO 登录过一次夜莺，否则夜莺中没有这个用户的信息）。\n配置 OIDC # 这是最推荐的方式，如果你的 SSO 同时支持 OIDC 和 OAuth2，建议使用 OIDC。\n配置项说明 # 下面是 OIDC 各个配置项的说明：\n# 是否开启 OIDC 单点登录，夜莺可以同时开启多个 SSO 方式 Enable = false # 登录页面会展示 SSO 登录地址的超链接，DisplayName 用于配置超链接的文本内容 DisplayName = 'OIDC' # IDC 登录验证通过后，需要跳转到夜莺，下面是配置夜莺用于 OIDC 的回调地址 # 您需要把 n9e.com 替换为您的夜莺地址，/callback 是固定的路径 RedirectURL = 'http://n9e.com/callback' # OIDC SSO 服务器根地址，换成您的 OIDC 服务器地址 SsoAddr = 'http://sso.example.org' # OIDC SSO 服务器的登出地址，用户在夜莺中点击登出时会跳转到这个地址，即可完成夜莺和 SSO 的同步登出 SsoLogoutAddr = 'http://sso.example.org/session/end' # OIDC 给夜莺分配的 ClientId 和 ClientSecret，必须要配置，一般是在 SSO 服务器上注册应用时获取的 ClientId = '' ClientSecret = '' # 用户通过 SSO 登录夜莺，夜莺发现用户在夜莺的用户表中不存在时，会自动创建一个用户 # 创建用户的时候，需要给这个用户一个角色，下面是配置默认角色的列表 DefaultRoles = ['Standard'] # 用户通过 SSO 登录夜莺时，夜莺会向 SSO 服务器请求用户信息，并将用户信息写入夜莺的用户表中 # 如果 CoverAttributes = true 则会覆盖夜莺中已有的用户信息，比如手机号、邮箱等。通常这里就是配置为 true 即可 CoverAttributes = true # Scope 是 OIDC 协议中的一个概念，表示请求获取的用户信息字段列表，通常就是下面的这些字段 Scopes = ['openid', 'profile', 'email', 'phone'] # 用户在 OIDC 中信息字段和夜莺中的用户信息字段不是 100% 一一对应的 # 所以在下面配置：夜莺的各个字段对应 OIDC 中的哪些字段 # Username、Nickname、Phone、Email 就是夜莺中的用户信息字段 # 后面的 sub、nickname、phone_number、email 就是 OIDC 中的用户字段名 # 请根据您的 OIDC 服务器的用户信息字段进行调整 [Attributes] Username = 'sub' Nickname = 'nickname' Phone = 'phone_number' Email = 'email'  配置项 FAQ # 1. 用户使用 OIDC 可以登录成功，但是用户名、手机号等获取不到\n可以调整夜莺的日志级别为 DEBUG（在 config.toml 中调整），然后重启夜莺，过滤日志关键字：sso_exchange_user: oidc info，再测试一遍登录，可以查看从单点登录系统获取到的用户信息有哪些，然后根据实际情况调整 Attributes 中的字段映射。\n对接 Authing 演示 # 下面使用 Authing 作为 OIDC 的 SSO 服务器进行演示。首先，要在 Authing 上创建一个应用，获取 ClientId 和 ClientSecret。\n然后在夜莺中配置 OIDC 的相关信息：\nEnable = true DisplayName = 'OIDC' RedirectURL = 'http://192.168.127.151:17000/callback' SsoAddr = 'https://n9e.authing.cn/oidc' SsoLoginOutAddr = 'https://n9e.authing.cn/oidc/session/end' ClientId = '65befb5b452d4854f9731b9b' ClientSecret = '0af4...' CoverAttributes = true DefaultRoles = ['Standard'] Scopes = ['openid', 'profile', 'username', 'email', 'phone'] [Attributes] Username = 'username' Nickname = 'nickname' Phone = 'phone_number' Email = 'email'  上面的 192.168.127.151:17000 是我这个测试环境的夜莺地址，您需要替换为自己的夜莺地址。\n对接飞书演示 # 飞书也支持 OIDC 协议，我们对这种方式也做一个说明。参考飞书的官方文档创建应用：配置应用单点登录，相关配置：\n 授权模式：可以把 authorization_code 和 refresh_token 都选上 Scope：可以把 openid profile email phone offline_access 都选上 回调地址：填写 http://n9e.com/callback，注意把 n9e.com 替换为您的夜莺地址，需要公网可达，除非您的飞书也是私有化内网部署的  配置完成之后即可拿到 Issuer（即 SSO Server 地址）、ClientId 和 ClientSecret，配置到夜莺中。另外，也可以拿到 SSO Logout 地址，是一个类似这样的地址：\nhttps://anycross.feishu.cn/sso/....../oidc/revoke  这个地址也配置到夜莺的 SsoLogoutAddr 中，虽然配置了这个地址，但是无法联动登出，下面是飞书文档的 官方解释说明：\n 由于 SSO 应用的登录态是从飞书登录态派生出的，因此不支持单点登出，即在 SSO 应用登出的时候，不能同时登出飞书。虽然平台提供了单点登出的地址，但这个地址是为了防止三方系统将其设置为必填项，地址本身并不生效。\n 最终夜莺中的配置如下：\nEnable = true DisplayName = 'OIDC' RedirectURL = 'http://n9e.com/callback' SsoAddr = 'https://anycross.feishu.cn/sso/XXXXX' SsoLoginOutAddr = 'https://anycross.feishu.cn/sso/XXXXX/oidc/revoke' ClientId = 'xxx' ClientSecret = 'xxx' CoverAttributes = true DefaultRoles = ['Standard'] Scopes = ['openid', 'profile', 'email', 'phone'] [Attributes] Username = 'name' Nickname = 'name' Phone = 'phone_number' Email = 'email'   上面的 n9e.com 需要替换为您自己的夜莺地址，需要公网可达，除非您的飞书也是私有化内网部署的。\n 对接 Keycloak 演示 # 之前有网友写过一篇文章，讲解 Grafana 和夜莺一起对接 Keycloak，大家可以参考：Grafana 和夜莺通过 Keycloak 深度对接整合。\n配置 OAuth2 # 如果您的 SSO 既支持 OIDC 又支持 OAuth2，建议使用 OIDC，实在没办法再使用 OAuth2，OAuth2 坑多。\n配置项说明 # # 是否开启 OAuth2 单点登录，夜莺可以同时开启多个 SSO 方式 Enable = false # 登录页面会展示 SSO 登录地址的超链接，DisplayName 用于配置超链接的文本内容 DisplayName = 'OAuth2' # SSO 登录验证通过后，需要跳转到夜莺，下面是配置夜莺用于 OAuth2 的回调地址 # 您需要把 n9e.com 替换为您的夜莺地址，/callback/oauth 是固定的路径 RedirectURL = 'http://n9e.com/callback/oauth' # OAuth2 SSO 服务器根地址，换成您的 OAuth2 服务器地址 SsoAddr = 'https://sso.example.com/oauth2/authorize' # OAuth2 SSO 服务器的登出地址，用户在夜莺中点击登出时会跳转到这个地址，即可完成夜莺和 SSO 的同步登出 SsoLogoutAddr = 'https://sso.example.com/oauth2/authorize/session/end' # 获取 OAuth2 token 的地址 TokenAddr = 'https://sso.example.com/oauth2/token' # OAuth2 提供的用户信息地址，夜莺会通过这个地址获取用户信息 UserInfoAddr = 'https://sso.example.com/api/v1/user/info' # 从 OAuth2 或许用户信息时，需要把上一步获取到的 token 放到请求头中 # token 可以放在 header 中，也可以放在 formdata 或 querystring 中，需要根据您的 OAuth2 服务器的要求进行配置 TranTokenMethod = 'header' # OAuth2 给夜莺分配的 ClientId 和 ClientSecret，必须要配置，一般是在 SSO 服务器上注册应用时获取的 ClientId = '' ClientSecret = '' # 用户通过 SSO 登录夜莺，夜莺发现用户在夜莺的用户表中不存在时，会自动创建一个用户 # 创建用户的时候，需要给这个用户一个角色，下面是配置默认角色的列表 DefaultRoles = ['Standard'] # 用户通过 SSO 登录夜莺时，夜莺会向 SSO 服务器请求用户信息，并将用户信息写入夜莺的用户表中 # 如果 CoverAttributes = true 则会覆盖夜莺中已有的用户信息，比如手机号、邮箱等。通常这里就是配置为 true 即可 CoverAttributes = true # 从 OAuth2 中获取用户数据时，返回的 JSON 格式数据是否为数组，根据你们的 OAuth2 服务器的返回格式进行配置 # 如果是数组，夜莺会取第一个元素作为用户信息 UserinfoIsArray = false # OAuth2 用户信息的前缀，通常是 'data'，即返回的 JSON 数据中会有一个 'data' 字段，里面是用户信息 UserinfoPrefix = 'data' # Scope 是 OAuth2 协议中的一个概念，表示请求获取的用户信息字段列表，通常就是下面的这些字段 Scopes = ['profile', 'email', 'phone'] # 用户在 OAuth2 中信息字段和夜莺中的用户信息字段不是 100% 一一对应的 # 所以在下面配置：夜莺的各个字段对应 OAuth2 中的哪些字段 # Username、Nickname、Phone、Email 就是夜莺中的用户信息字段 # 后面的 sub、nickname、phone_number、email 就是 OAuth2 中的用户字段名 # 请根据您的 OAuth2 服务器的用户信息字段进行调整 [Attributes] Username = 'sub' Nickname = 'nickname' Phone = 'phone_number' Email = 'email'  对接 Authing 演示 # 使用 Authing 作为 OAuth2 的 SSO 服务器进行演示。首先，要在 Authing 上启用 OAuth2。配置样例如下：\n然后在夜莺中配置 OAuth2 的相关信息：\nEnable = true DisplayName = 'OAuth2' RedirectURL = 'http://192.168.127.151:17000/callback/oauth' SsoAddr = 'https://n9e.authing.cn/oauth/auth' SsoLogoutAddr = 'https://n9e.authing.cn/oauth/session/end' TokenAddr = 'https://n9e.authing.cn/oauth/token' UserInfoAddr = 'https://n9e.authing.cn/oauth/me' TranTokenMethod = 'header' ClientId = '65befb5b452d4854f9731b9b' ClientSecret = '0af4...' CoverAttributes = true DefaultRoles = ['Standard'] UserinfoIsArray = false UserinfoPrefix = '' Scopes = ['profile', 'username', 'email', 'phone'] [Attributes] Username = 'username' Nickname = 'nickname' Phone = 'phone' Email = 'email'  上面的 192.168.127.151:17000 是我这个测试环境的夜莺地址，您需要替换为自己的夜莺地址。\n配置 CAS # 夜莺监控（Nightingale）也支持 CAS 协议的单点登录。相比 OIDC，坑更多，慎用。\n配置项说明 # # 是否开启 CAS 单点登录，夜莺可以同时开启多个 SSO 方式 Enable = false # 登录页面会展示 SSO 登录地址的超链接，DisplayName 用于配置超链接的文本内容 DisplayName = 'CAS' # CAS 登录验证通过后，需要跳转到夜莺，下面是配置夜莺用于 CAS 的回调地址 # 您需要把 n9e.com 替换为您的夜莺地址，/callback/cas 是固定的路径 RedirectURL = 'http://n9e.com/callback/cas' # CAS SSO 服务器根地址，换成您的 CAS 服务器地址 SsoAddr = 'https://cas.example.com/cas' # CAS SSO 服务器的登出地址，用户在夜莺中点击登出时会跳转到这个地址，即可完成夜莺和 SSO 的同步登出 SsoLogoutAddr = 'https://cas.example.com/cas/session/end' # LoginPath 这个配置项，是为了兼容不同的 CAS 版本，因为不同的 CAS 版本登录地址可能不同 # 如果您配置了 LoginPath，则夜莺会在 SsoAddr 的基础上拼接 LoginPath 作为登录地址 # 如果您没有配置 LoginPath，夜莺的逻辑是： # 1. 如果发现 SsoAddr 中包含 p3 关键字，就设置 LoginPath = '/login' # 2. 如果没有包含 p3 关键字，就设置 LoginPath = '/cas/login' LoginPath = '' # 用户通过 SSO 登录夜莺，夜莺发现用户在夜莺的用户表中不存在时，会自动创建一个用户 # 创建用户的时候，需要给这个用户一个角色，下面是配置默认角色的列表 DefaultRoles = ['Standard'] # 用户通过 SSO 登录夜莺时，夜莺会向 SSO 服务器请求用户信息，并将用户信息写入夜莺的用户表中 # 如果 CoverAttributes = true 则会覆盖夜莺中已有的用户信息，比如手机号、邮箱等。通常这里就是配置为 true 即可 CoverAttributes = true # 用户在 CAS 中信息字段和夜莺中的用户信息字段不是 100% 一一对应的 # 所以在下面配置：夜莺的各个字段对应 CAS 中的哪些字段 # Username、Nickname、Phone、Email 就是夜莺中的用户信息字段 # 后面的 sub、nickname、phone_number、email 就是 CAS 中的用户字段名 # 请根据您的 CAS 服务器的用户信息字段进行调整 [Attributes] Username = 'sub' Nickname = 'nickname' Phone = 'phone_number' Email = 'email'  对接 Authing 演示 # 使用 Authing 作为 CAS 的 SSO 服务器进行演示。首先，要在 Authing 上启用 CAS。配置样例如下：\n然后在夜莺中配置 CAS 的相关信息：\nEnable = true DisplayName = 'CAS' RedirectURL = 'http://192.168.127.151:17000/callback/cas' SsoAddr = 'https://n9e.authing.cn/cas-idp/65befb5b452d4854f9731b9b' SsoLogoutAddr = 'https://n9e.authing.cn/cas-idp/65befb5b452d4854f9731b9b/logout' LoginPath = '/login' CoverAttributes = true DefaultRoles = ['Standard'] [Attributes] Username = 'username' Nickname = 'nickname' Phone = 'phone_number' Email = 'email'  上面的 192.168.127.151:17000 是我这个测试环境的夜莺地址，您需要替换为自己的夜莺地址。\n配置 LDAP # 夜莺监控（Nightingale）也支持 LDAP 协议的认证登录。LDAP 是一种轻量级目录访问协议，通常用于企业内部的用户认证和授权。前面讲到的 SSO 机制（OIDC、OAuth2、CAS）都没法把用户信息周期性全量同步到夜莺中，而 LDAP 则可以做到这一点。\nLDAP 在页面上也没有单独的登录超链接入口，用户在输入用户名和密码登录夜莺时，夜莺首先去 DB 中查询用户信息，如果没有找到，则自动检查 LDAP 是否启用，如果启用了，就直接使用 LDAP 进行认证登录。\n配置项说明 # # 是否开启 LDAP 单点登录，夜莺可以同时开启多个 SSO 方式 Enable = false # LDAP 服务器地址和端口、TLS、StartTLS 等配置 # 请根据您自己的环境进行配置 Host = 'ldap.example.org' Port = 389 TLS = false StartTLS = true # LDAP 服务器的根 DN，可以 Google、GPT 获取更多信息 BaseDn = 'dc=example,dc=org' # 管理员信息，这个账号需要具备查询所有用户信息的权限 BindUser = 'cn=manager,dc=example,dc=org' BindPass = '*******' # 是否同步 LDAP 中的创建用户至夜莺 SyncAddUsers = false # 是否同步 LDAP 中的删除用户操作至夜莺 SyncDelUsers = false # 同步频率，单位：秒 SyncInterval = 86400 # 用户登录时，检查用户是否存在于 LDAp 中的筛选条件 # openldap 和 AD 通常有不同的筛选格式 # openldap 的格式可能为： (\u0026amp;(uid=%s)) # AD 的格式可能为 (\u0026amp;(sAMAccountName=%s)) # 您需要根据您的 LDAP 服务器类型进行调整 AuthFilter = '(\u0026amp;(uid=%s))' # 查询 LDAP 中全量用户的筛选条件 # 根据您的 LDAP 服务器类型进行调整 UserFilter = '(\u0026amp;(uid=*))' # 用户通过 LDAP 登录夜莺，夜莺发现用户在夜莺的用户表中不存在时，会自动创建一个用户 # 创建用户的时候，需要给这个用户一个角色，下面是配置默认角色的列表 DefaultRoles = ['Standard'] # 用户通过 LDAP 登录夜莺时，夜莺会向 LDAP 服务器请求用户信息，并将用户信息写入夜莺的用户表中 # 如果 CoverAttributes = true 则会覆盖夜莺中已有的用户信息，比如手机号、邮箱等。通常这里就是配置为 true 即可 CoverAttributes = true # 用户在 LDAP 中信息字段和夜莺中的用户信息字段不是 100% 一一对应的 # 所以在下面配置：夜莺的各个字段对应 LDAP 中的哪些字段 # Username、Nickname、Phone、Email 就是夜莺中的用户信息字段 # 后面的 uid、cn、mobile、mail 就是 LDAP 中的用户字段名 # 请根据您的 LDAP 服务器的用户信息字段进行调整 [Attributes] Username = 'uid' Nickname = 'cn' Phone = 'mobile' Email = 'mail'  上面的配置信息如果您看完注释还是不清楚如何配置，可以咨询贵司的 LDAP 管理员，他大概率是比较清楚的。\n","description":"夜莺监控（Nightingale）支持单点登录（SSO）功能，可以通过 SSO 方式登录夜莺监控。SSO 支持多种协议，如 OAuth2、OIDC 等。","title":"单点登录（SSO）"},{"RelPermalink":"/zh/docs/usecase/api/","contents":"本文介绍如何使用 API 调用夜莺监控（Nightingale）的接口，主要是两类接口，一类是页面操作类，就是使用 API 模仿用户在页面上的操作，另一类是数据推送类，比如自己的程序采集了监控数据，想要推送给夜莺。\n页面操作类 # 页面操作类的 API 主要是模拟用户在页面上的操作，比如创建告警规则、修改机器标签、修改机器备注、调整机器归属的业务组等。所有用户在页面上的操作，都可以使用 API 完成，您可以通过这些接口来实现自动化操作。\n显然，要调用 API 需要有两个前提：\n 搞定认证 了解有哪些接口，各个接口有哪些参数  搞定认证 # 这里直接讲解 v8.0.0-beta.5 以上版本的认证方式，即个人中心 token 方式，这是最简单的方式。\n1. 修改配置文件 # 修改夜莺的配置文件 etc/config.toml，确保配置了 HTTP.TokenAuth，并且设置了 Enable = true，如下所示：\n... [HTTP.RSA] OpenRSA = false [HTTP.TokenAuth] Enable = true [DB] ...  2. 获取 Token # 登录夜莺监控，进入右上角头像，进入个人信息页面，点击 “Token 管理” 那个 Tab，然后点击“创建 Token”，随便起个名字，就可以得到一个 Token。\n3. 使用 Token # 在调用 API 的时候，需要在 HTTP 请求的 Header 中添加 X-User-Token 字段，值为你刚才创建的 Token。用 cURL 命令调用 API 的示例：\ncurl -s -X GET \u0026quot;http://\u0026lt;NIGHTINGALE_HOST\u0026gt;\u0026lt;API_URL_PATH\u0026gt;\u0026quot; \\ -H \u0026quot;X-User-Token: \u0026lt;YOUR_TOKEN\u0026gt;\u0026quot; \\ -H \u0026quot;Content-Type: application/json\u0026quot;  我们测试一下获取个人信息的接口：\ncurl -s -H \u0026quot;X-User-Token: e6897d32-c237-4d27-a0fc-786345b682ea\u0026quot; -H \u0026quot;Content-Type: application/json\u0026quot; 'http://10.99.1.106:8003/api/n9e/self/profile' | python3 -m json.tool { \u0026quot;dat\u0026quot;: { \u0026quot;id\u0026quot;: 1, \u0026quot;username\u0026quot;: \u0026quot;root\u0026quot;, \u0026quot;nickname\u0026quot;: \u0026quot;Root\u0026quot;, \u0026quot;phone\u0026quot;: \u0026quot;\u0026quot;, \u0026quot;email\u0026quot;: \u0026quot;qinxiaohui@flashcat.cloud\u0026quot;, \u0026quot;portrait\u0026quot;: \u0026quot;/image/avatar1.png\u0026quot;, \u0026quot;roles\u0026quot;: [ \u0026quot;Admin\u0026quot; ], \u0026quot;contacts\u0026quot;: { \u0026quot;wecomid\u0026quot;: \u0026quot;qinxiaohui\u0026quot; }, \u0026quot;maintainer\u0026quot;: 0, \u0026quot;create_at\u0026quot;: 1733229739, \u0026quot;create_by\u0026quot;: \u0026quot;system\u0026quot;, \u0026quot;update_at\u0026quot;: 1749811268, \u0026quot;update_by\u0026quot;: \u0026quot;root\u0026quot;, \u0026quot;belong\u0026quot;: \u0026quot;\u0026quot;, \u0026quot;admin\u0026quot;: true, \u0026quot;user_groups\u0026quot;: null, \u0026quot;busi_groups\u0026quot;: null, \u0026quot;last_active_time\u0026quot;: 1749811088 }, \u0026quot;err\u0026quot;: \u0026quot;\u0026quot; }  如上，正常返回了内容，表示成功。如果你要写程序调用 API，需要校验：\n 夜莺返回的 HTTP 状态码是否为 200，如果状态码不是 200，表示请求失败，此时可以把 Response Body 打印出来，查看具体的错误信息。 如果状态码是 200，Response Body 肯定是 JSON，此时还要校验 JSON 数据中 err 字段是否为空，如果不为空就是有问题的。  了解有哪些接口 # 直接使用 Chrome 打开夜莺的页面，按 F12 打开开发者工具，切换到 Network 标签页，然后在页面上操作，比如创建一个告警规则，或者修改机器标签等。你会看到 Network 中有很多 API 请求，这些就是夜莺的 API 接口。比如：\n Headers 下面可以看到 Request Method 和 URL Response 下面可以看到返回的内容  上面的接口没有任何 Query string 参数，如果有 Query string 参数，通常会在 URL 中显示。另外，如果是 POST 请求，就需要研究 Request Body 的格式了，届时会出现一个 Payload 的 Tab，在 Payload 下面可以看到 Request Body 的内容格式。\n这种方式比接口文档要好多了，接口文档经常忘记更新，而且不同版本的差异经常忘记说明，而通过查看 Chrome 的这种方式，那信息绝对是 100% 准确的，有哪些接口，有哪些参数，一目了然，每个运维、后端研发都应该懂得这种方式。\n数据推送类 # 自己的程序暴露监控数据，通常有两个手段，一个是埋入 Prometheus SDK，暴露 /metrics 接口，然后用 Prometheus 或 Categraf 来抓取（称为 PULL 模式），另一个是直接调用夜莺的 API 接口，推送监控数据（称为 PUSH 模式），夜莺支持多种数据接收的接口，包括 OpenTSDB、Open-Falcon、PrometheusRemoteWrite、Datadog 等协议。\n推送样例 # 以 OpenTSDB 协议为例，夜莺接口路径是 /opentsdb/put，HTTP Method 是 POST，Request Body 里放置你要上报的监控数据，格式样例如下：\n[ { \u0026quot;metric\u0026quot;: \u0026quot;cpu_usage_idle\u0026quot;, \u0026quot;timestamp\u0026quot;: 1637732157, \u0026quot;tags\u0026quot;: { \u0026quot;cpu\u0026quot;: \u0026quot;cpu-total\u0026quot;, \u0026quot;ident\u0026quot;: \u0026quot;c3-ceph01.bj\u0026quot; }, \u0026quot;value\u0026quot;: 30.5 }, { \u0026quot;metric\u0026quot;: \u0026quot;cpu_usage_util\u0026quot;, \u0026quot;timestamp\u0026quot;: 1637732157, \u0026quot;tags\u0026quot;: { \u0026quot;cpu\u0026quot;: \u0026quot;cpu-total\u0026quot;, \u0026quot;ident\u0026quot;: \u0026quot;c3-ceph01.bj\u0026quot; }, \u0026quot;value\u0026quot;: 69.5 } ]  显然，JSON 最外层是个数组，如果只上报一条监控数据，也可以不要外面的中括号，直接把对象结构上报：\n{ \u0026quot;metric\u0026quot;: \u0026quot;cpu_usage_idle\u0026quot;, \u0026quot;timestamp\u0026quot;: 1637732157, \u0026quot;tags\u0026quot;: { \u0026quot;cpu\u0026quot;: \u0026quot;cpu-total\u0026quot;, \u0026quot;ident\u0026quot;: \u0026quot;c3-ceph01.bj\u0026quot; }, \u0026quot;value\u0026quot;: 30.5 }  服务端会看第一个字符是否是 [，来判断上报的是数组，还是单个对象，自动做相应的 Decode。如果觉得上报的内容太过占用带宽，也可以在你的程序里对 Request Body 做 gzip 压缩，同时在 HTTP Header 里带上 Content-Encoding: gzip 的 Header。\n各个字段的含义可以 Google 一下或者询问 GPT，关键字是 “OpenTSDB 数据格式里各个字段的含义”。这里我稍作说明：\n metric: 监控指标的名称，通常是一个英文单词，多个单词用下划线连接，比如 cpu_usage_idle timestamp: 时间戳，单位是秒，表示监控数据的采集时间 tags: 标签，通常是一个 map 结构，key 是标签名，value 是标签值，用于描述指标的各类维度信息或元信息 value: 监控数据的值，通常是一个数字，表示指标的数值   🟢 注意 ident 这个标签，ident 是 identity 的缩写，表示设备的唯一标识，如果标签中有 ident 标签，n9e 就认为这个监控数据是来自某个机器的，会自动获取 ident 的 value，注册到夜莺的机器列表里。\n 其他常用的接口路径：\n /openfalcon/push: Open-Falcon 数据接收接口 /prometheus/v1/write: Prometheus Remote Write 数据接收接口  如何认证 # 如果你的夜莺暴露在公网，那所有人都可以推监控数据给你，这显然是不安全的。所以我们建议：\n 不要把夜莺暴露在公网 如果实在要暴露在公网，要用 HTTPS 协议，同时开启 Basic Auth 认证  如何开启 Basic Auth 认证呢？在 etc/config.toml 中配置：\n[HTTP.APIForAgent] Enable = true [HTTP.APIForAgent.BasicAuth] user001 = \u0026quot;Pa55word01\u0026quot; user002 = \u0026quot;Pa55word02\u0026quot;  你自己的程序调用夜莺的接口上报监控数据，此时你的程序就相当于一个 agent 的角色，所以就是跟 HTTP.APIForAgent 这块的配置相关。\n HTTP.APIForAgent 下面的 Enable 首先要设置为 true，才会启用相关接口，否则你调用那些上报数据的接口都会报 404 Not Found 错误。 HTTP.APIForAgent.BasicAuth 下面的配置是用户名和密码，格式是 username = \u0026quot;password\u0026quot;，你可以设置多个用户，这些用户的认证方式是 Basic Auth。如果 HTTP.APIForAgent.BasicAuth 下面一个用户也没有配置，那么就表示不需要认证，任何人都可以推送数据。   🔴 注意：跟 HTTP.APIForAgent 紧挨着的还有一个 HTTP.APIForService 配置段，用于提供一些接口给 n9e-edge 使用，即夜莺的边缘机房部署模式，如果你没有用到 n9e-edge，一定要把 HTTP.APIForService 给 Disable 掉，即 HTTP.APIForService 下面的 Enable 设置为 false，避免安全风险。\n ","description":"本文介绍使用 API 调用夜莺监控 Nightingale 的接口，主要是两类接口，一类是页面操作类，另一类是数据推送类","title":"API"},{"RelPermalink":"/zh/docs/faq/global-callback/","contents":"后面计划在 V9 版本，下掉全局回调，如果你当前还在使用全局回调功能，需要尽快迁移到新的使用方式。那么，使用什么方式来替代全局回调呢？\n答案是：订阅规则（ 👈 点击查看使用说明）。\n订阅规则的菜单入口是：告警-规则管理-订阅规则TAB。下面是创建订阅规则的界面：\n我们可以创建一个订阅规则，然后订阅所有的告警事件，即不要加过滤条件，直接选中所有级别，这样任何告警事件都会匹配这个订阅规则，注意：\n 上图是老版本，数据源类型还是必须要选的，所以准确来讲，上例的订阅规则其实不是针对所有告警事件，而是针对 Prometheus 类型的数据源的所有告警事件。 后面的版本会做优化，数据源类型会做成非必填项，即可以订阅所有数据源类型的告警事件。  然后，选择一个通知规则，这样一来，所有的告警事件都可以走这个通知规则了。和之前的全局回调相比，有两个典型好处：\n 订阅规则这里，可以做一些过滤，比如只订阅某个数据源类型的告警事件，或者只订阅某个级别的告警事件。 所有告警事件走一个统一的通知规则，通知规则里可以有事件处理器 Pipeline，可以使用不同的通知媒介，不同的通知媒介还可以有细粒度的过滤配置，整体上比全局回调更灵活。  ","description":"新版本的夜莺下掉了全局回调的功能，但是有些场景需要全局回调，本文介绍了如何使用订阅规则来替代全局回调。","title":"全局回调下线，那全局场景怎么处理？"},{"RelPermalink":"/zh/docs/faq/cpu-alerting/","contents":"CPU 负载高，到底应不应该告警？\n 不告警吧，出了问题怕被怼，嫌你告警缺失 告警吧，好像全是噪音，工程师都自动忽略了  尴尬\u0026hellip;\n成年人的世界没有非黑即白，如果要严肃的论述，就要加很多限定词，为了避免歧义拉齐认知，我先补充一点前置知识（原则）。\n前置知识（原则） # 告警应该有不同的紧迫级别，有些公司甚至会规定 6 个级别（估计自己的工程师都捋不清楚\u0026hellip;），通常建议 3 个级别足够了：\n Critical：已经影响业务，立马需要处理。通常使用打扰性很强的多个告警通知媒介一起发告警消息，比如电话+短信+IM+邮件。比如电商业务订单量下跌严重，就是紧急告警。 Warning：不用立马处理，可以自动建立工单，慢慢处理。但也必须要处理，如果不处理，可能会酿成大故障。通常也要发告警，只不过选用的通知媒介没有那么强的打扰性。比如重要机器的磁盘使用率已经 95%，可能再有 24 小时就要写满了；或域名证书再有 3 天就要过期了之类的。 Info：仅生成告警事件，不用发告警通知，相当于是从海量指标里提取了一些稍微重要的信息。如果有故障发生，这些信息是作为故障排查的线索依据。比如某个 Pod 被驱逐漂移了；或者某个用户尝试登录系统的失败次数太多。  整体来看，可以分成两个大类：\n 要处理的：Critical、Warning 不用处理的：Info  其中，Info 不关键，可配可不配，完全可以等到后面你的监控、故障定位体系做得很精细化的时候再说。我们重点关注前面两个级别：Critical 和 Warning，这俩级别有个相同点，就是都！要！处！理！英文世界里通常称之为 actionable（感觉很精确）。\n所以，CPU 负载高，到底要不要配置告警？\nCPU 告警的制定逻辑 #  如果 CPU 告警产生之后，你们有后续处理动作，那就应该配置，即便这个动作是登录机器瞅一眼，出两句跟进结论，也算动作 如果没有后续动作就无需配置，比如看到了这个告警，习惯了，直接忽略了，这就不算动作，这个告警就不应该配置；或者，也可以配置，但是作为 Info 级别，仅生成告警事件，不做告警通知  其实，不仅仅是 CPU 告警，所有的告警规则配置，都是这个逻辑，所有的告警规则，都应该是 actionable 的。所以，理论上，每个告警规则都应该对应一个 SOP（处理预案），Prometheus 和夜莺的告警规则里都有个 Annotations 字段，典型的应该放到 Annotations 中的字段就是 SOP URL 和 Dashboard URL。\n很多人看到这里，觉得，那这个工作量大了，每个告警规则都要整理 SOP（不同的公司 SOP 通常不同，一些中间件、数据库的部分 SOP 可能相同），之前就仅仅是从网上找了一些告警规则导入即可，以为就完事了，没成想还有这些活要干！\n其实，相比搭建一套监控系统，这才是更有价值的事情啊！\n","description":"服务器的 CPU 负载高，到底应不应该告警？这个问题困扰了很多运维监控的从业人员，本文尝试给出一些建议。","title":"CPU 负载高，到底应不应该告警？"},{"RelPermalink":"/zh/docs/faq/biz-team-subscribe-infra-alarms/","contents":"有朋友问：我是业务应用的 DEV 或 SRE，我的应用依赖了底层服务和基础设施，比如依赖基础网络、Kubernetes、MySQL、收银台服务，那这些基础服务如果出问题，我应该收告警吗？夜莺里有个订阅规则，是不是就是为此设计的？\n本文讲讲笔者的个人理解，仅供参考。\n首先，请大家看一下上一篇文章《CPU负载高，到底应不应该告警？》，其中提到一个点：只有 actionable 的告警规则才有意义！\n所以，要看你们的情况：\n1，如果你的服务是单机房部署，这些基础设施和服务出问题你无能为力，只能被动等待恢复，即你没有 SOP，那收这些告警意义不大。\n此时推荐的做法是：做一个可视化页面，把你依赖的基础设施和服务的关键 SLI 放上去，你能通过查看 UI 趋势图，了解到各个基础设施和服务的健康状况即可。Facebook 有个内部产品叫 SLICK，就是类似的逻辑，我们创业做的 Flashcat 里有个功能叫“灭火图”，也有类似的效果。这算是一个惯常做法。\n2，如果你有 SOP，比如可以切流，那么去订阅这类告警是有意义的。\n但是，很多底层服务的关键指标你也未必看得懂，此时最好有个规范。比如，每个底层服务的负责人，在配置告警规则时，如果觉得那个告警规则很重要，对应的告警会影响上层服务，那就给那个规则打上一个特殊标签，比如 advertise=mysql 表示所有 MySQL 相关的需要周知的告警，比如 advertise=k8s 表示所有 Kubernetes 相关的需要周知的告警，之后上层应用的 DEV、SRE 就可以订阅这类标签，知悉相关的告警。\n另外\nMySQL、收银台这类服务，相比去订阅它们的 SLI 告警，更好的方式是在上层应用里自行埋点，主要是采集一下请求数、失败数、延迟就可以了。\n因为从 MySQL 的视角来看，其 SLI 指标是面向整个实例的，而如果在上层应用埋点，其指标就可以细化到与这个服务相关，甚至与这个服务的特定业务场景相关，做得更精细化。\n","description":"我是业务应用的 DEV 或 SRE，我的应用依赖了底层服务和基础设施，比如依赖基础网络、Kubernetes、MySQL、收银台服务，那这些基础服务如果出问题，我应该收告警吗？夜莺里有个订阅规则，是不是就是为此设计的？","title":"底层的告警，上层业务应该收吗？"},{"RelPermalink":"/zh/docs/faq/how-to-import-prometheus-rules/","contents":"Prometheus 生态有很多人分享了告警规则，比如这个项目：\n https://github.com/samber/awesome-prometheus-alerts/tree/master/dist/rules  每个目录下都是 yaml 格式的告警规则，比如 host-and-hardware 目录下就是常见的 node-exporter 的告警规则。想要把这些规则直接导入夜莺？请参考如下操作。\n版本说明 # 请使用夜莺 v8.2.0 以上的版本。\n导入步骤 #   如上截图。在告警规则页面选择导入，即可导入 Prometheus 格式的告警规则。注意那个 yaml 格式的规则内容，一开始是 groups，包含多个 group，每个 group 有 name 和 rules，rules 也是一个数组，里面是具体的告警规则。夜莺处理的时候会忽略 group 的 name，直接将 rules 中的内容导入。\n导入完成之后，通常需要关联通知规则，才能做告警通知。方法是：批量选中告警规则，然后点击右上角的更多操作，批量更新告警规则：\n  在批量更新的弹层里，字段选择为：通知规则，然后选择对应的通知规则，点击确定即可，截图如下：\n  ","description":"如何将 Prometheus 告警规则导入到夜莺？","title":"如何导入 Prometheus 告警规则？"}]