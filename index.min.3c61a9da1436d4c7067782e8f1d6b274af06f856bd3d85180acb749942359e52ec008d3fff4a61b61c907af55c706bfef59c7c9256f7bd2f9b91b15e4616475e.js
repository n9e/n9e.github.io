var suggestions=document.getElementById("suggestions"),search=document.getElementById("search");search!==null&&document.addEventListener("keydown",inputFocus);function inputFocus(e){e.ctrlKey&&e.key==="/"&&(e.preventDefault(),search.focus()),e.key==="Escape"&&(search.blur(),suggestions.classList.add("d-none"))}document.addEventListener("click",function(e){var t=suggestions.contains(e.target);t||suggestions.classList.add("d-none")}),document.addEventListener("keydown",suggestionFocus);function suggestionFocus(n){const s=suggestions.classList.contains("d-none");if(s)return;const e=[...suggestions.querySelectorAll("a")];if(e.length===0)return;const t=e.indexOf(document.activeElement);if(n.key==="ArrowUp"){n.preventDefault();const s=t>0?t-1:0;e[s].focus()}else if(n.key==="ArrowDown"){n.preventDefault();const s=t+1<e.length?t+1:t;e[s].focus()}}(function(){var e=new FlexSearch.Document({tokenize:"forward",cache:100,document:{id:"id",store:["href","title","description"],index:["title","description","content"]}});e.add({id:0,href:"/docs/prologue/introduction/",title:"夜莺介绍",description:"夜莺（ Nightingale ）是一款国产开源、云原生监控系统",content:"项目代码 #  后端：💡 https://github.com/ccfos/nightingale 前端：💡 https://github.com/n9e/fe-v5  前后端都是开源的，如果觉得不错，欢迎 star 一下，给我们持续坚持的动力！有任何问题，也欢迎提交 issue，当然，如果能直接 PR 就更好了，开源软件，就是需要大家一起参与才能有蓬勃的生命力。\n产品介绍 # Nightingale 可以接收各种采集器上报的监控数据，转存到时序库（可以支持Prometheus、M3DB、VictoriaMetrics、Thanos等），并提供告警规则、屏蔽规则、订阅规则的配置能力，提供监控数据的查看能力，提供告警自愈机制（告警触发之后自动回调某个webhook地址或者执行某个脚本），提供历史告警事件的存储管理、分组查看的能力。\n系统截图 # 系统架构 # 夜莺 v5 的设计非常简单，核心是 server 和 webapi 两个模块，webapi 无状态，放到中心端，承接前端请求，将用户配置写入数据库；server 是告警引擎和数据转发模块，一般随着时序库走，一个时序库就对应一套 server，每套 server 可以只用一个实例，也可以多个实例组成集群，server 可以接收 Categraf、Telegraf、Grafana-Agent、Datadog-Agent、Falcon-Plugins 上报的数据，写入后端时序库，周期性从数据库同步告警规则，然后查询时序库做告警判断。每套 server 依赖一个 redis。\n产品对比 # Zabbix # Zabbix 是一款老牌的监控系统，对机器和网络设备的监控覆盖很全，比如支持 AIX 系统，常见的开源监控都是支持 Linux、Windows，AIX 较少能够支持，Zabbix 用户群体广泛，国内很多公司基于 Zabbix 做商业化服务，不过 Zabbix 使用数据库做存储，容量有限，今年推出的 TimescaleDB 对容量有较大提升，大家可以尝试下；其次 Zabbix 整个产品设计是面向静态资产的，在云原生场景下显得力不从心。\nOpen-Falcon # 因为开发 Open-Falcon 和 Nightingale 的是一拨人，所以很多社区伙伴会比较好奇，为何要新做一个监控开源软件。核心点是 Open-Falcon 和 Nightingale 的差异点实在是太大了，Nightingale 并非是 Open-Falcon 设计逻辑的一个延续，就看做两个不同的软件就好。\nOpen-Falcon 是 14 年开发的，当时是想解决 Zabbix 的一些容量问题，可以看做是物理机时代的产物，整个设计偏向运维视角，虽然数据结构上已经开始设计了标签，但是查询语法还是比较简单，无法应对比较复杂的场景。\nNightingale 直接支持 PromQL，支持 Prometheus、M3DB、VictoriaMetrics 多种时序库，支持 Categraf、Telegraf、Datadog-Agent、Grafana-Agent 做监控数据采集，支持 Grafana 看图，整个设计更加云原生。\nPrometheus # Nightingale 可以简单看做是 Prometheus 的一个企业级版本，把 Prometheus 当做 Nightingale 的一个内部组件（时序库），当然，也不是必须的，时序库除了 Prometheus，还可以使用 VictoriaMetrics、M3DB 等，各种 Exporter 采集器也可以继续使用。\nNightingale 可以接入多个 Prometheus，可以允许用户在页面上配置告警规则、屏蔽规则、订阅规则，在页面上查看告警事件、做告警事件聚合统计，配置告警自愈机制，管理监控对象，配置监控大盘等，就把 Nightingale 看做是 Prometheus 的一个 WEBUI 也是可以的，不过实际上，它远远不止是一个 WEBUI，用一下就会深有感触。\n加入社区 # 公众号有加入交流群的方式、答疑方式，也会定期分享夜莺知识、云原生监控知识，欢迎关注。\n商业服务 # 一款开源软件要想长期发展，需要产权所有方、核心开发人员、社区用户等多方实现共赢，否则伴随着核心人员离职，项目很可能就会停止更新甚至夭折，夜莺的产权所有方是中国计算机学会开源发展委员会，是一个非盈利机构，核心开发人员隶属于北京快猫星云科技有限公司，快猫的产品就是基于开源夜莺构建的，所以形成了良性循环。欢迎有支付能力的公司能够支持一下快猫团队，采购商业版本的产品或开源技术支持服务，多方共赢 🤝🤝\n"}),e.add({id:1,href:"/docs/prologue/share/",title:"社区分享",description:"夜莺监控社区分享",content:"本节罗列社区用户的分享文章，欢迎大家把自己的心得文章链接放到这里，让整个社区受益，相互交流：\n Telegraf Windows版本的安装，保姆级教程 - by SL Telegraf Linux版本的安装，保姆级教程 - by SL 弃用Prometheus，搭建单机版本的VictoriaMetrics - by SL 一键部署夜莺到Kubernetes - by 陶柒 使用Telegraf做夜莺5.0的数据采集，样例包含Linux基本信息采集、MySQL、Redis的采集 - by 柴今栋@艾派 telegraf常用中间件采集 修改notify.py为夜莺增加短信通知能力 - by 柴今栋@艾派 使用notify.py接入阿里云语音通知 - by 果 Oracle的简单监控实现 - by 柴今栋@艾派 RocketMQ简单监控的实现 - by 柴今栋@艾派 手把手教你接入钉钉告警 一文说透MySQL监控，使用Prometheus生态的Exporter Vsphere-monitor数据上报夜莺V5监控 使用pg作为数据库替换MySQL Telegraf 配置文件，告警规则，看图大盘分享 - 映客-郑富强 telegraf采集Nacos - 郭什么磊°  "}),e.add({id:2,href:"/docs/install/compose/",title:"Docker Compose",description:"使用Docker compose一键启动夜莺，快速尝试",content:"使用Docker Compose一键启动夜莺，快速尝试。更多Docker Compose相关知识请参考Docker官网\n$ git clone https://gitlink.org.cn/ccfos/nightingale.git $ cd nightingale/docker $ docker compose up -d Creating network \u0026quot;docker_nightingale\u0026quot; with driver \u0026quot;bridge\u0026quot; Creating mysql ... done Creating redis ... done Creating prometheus ... done Creating ibex ... done Creating agentd ... done Creating nwebapi ... done Creating nserver ... done Creating telegraf ... done $ docker compose ps Name Command State Ports ---------------------------------------------------------------------------------------------------------------------------- agentd /app/ibex agentd Up 10090/tcp, 20090/tcp ibex /app/ibex server Up 0.0.0.0:10090-\u0026gt;10090/tcp, 0.0.0.0:20090-\u0026gt;20090/tcp mysql docker-entrypoint.sh mysqld Up 0.0.0.0:3306-\u0026gt;3306/tcp, 33060/tcp nserver /app/n9e server Up 18000/tcp, 0.0.0.0:19000-\u0026gt;19000/tcp nwebapi /app/n9e webapi Up 0.0.0.0:18000-\u0026gt;18000/tcp, 19000/tcp prometheus /bin/prometheus --config.f ... Up 0.0.0.0:9090-\u0026gt;9090/tcp redis docker-entrypoint.sh redis ... Up 0.0.0.0:6379-\u0026gt;6379/tcp telegraf /entrypoint.sh telegraf Up 0.0.0.0:8092-\u0026gt;8092/udp, 0.0.0.0:8094-\u0026gt;8094/tcp, 0.0.0.0:8125-\u0026gt;8125/udp  💡  启动成功之后，建议把 initsql 目录下的内容挪走，这样下次重启的时候，DB 就不会重新初始化了。否则下次启动 mysql 还是会自动执行 initsql 下面的 sql 文件导致 DB 重新初始化，页面上创建的规则、大盘等都会丢失。Docker Compose 这种部署方式，只是用于简单测试，不推荐在生产环境使用，当然了，如果您是 Docker Compose 专家，另当别论   服务启动之后，浏览器访问nwebapi的端口，即18000，默认用户是root，密码是root.2020\n"}),e.add({id:3,href:"/docs/install/helm/",title:"Helm",description:"夜莺（Nightingale）Helm chart",content:"Helm chart 由快猫团队维护，地址：https://github.com/flashcatcloud/n9e-helm 夜莺系统的默认用户是root，密码是root.2020\n"}),e.add({id:4,href:"/docs/install/server/",title:"服务端组件部署",description:"夜莺（Nightingale）服务端相关模块的安装",content:"首先我们来看下面的架构图，夜莺的服务端有两个模块：n9e-webapi 和 n9e-server，n9e-webapi 用于提供 API 给前端 JavaScript 使用，n9e-server 的职责是告警引擎和数据转发器。依赖的组件有 MySQL、Redis、时序库，时序库我们这里使用 Prometheus。\n组件安装 # mysql、redis、prometheus，这三个组件都是开源软件，请大家自行安装，其中 prometheus 在启动的时候要注意开启 --enable-feature=remote-write-receiver ，如果之前贵司已经有 Prometheus 了，也可以直接使用，无需再次部署。这里也提供一个小脚本来安装这3个组件，大家可以参考：\n# install prometheus mkdir -p /opt/prometheus wget https://s3-gz01.didistatic.com/n9e-pub/prome/prometheus-2.28.0.linux-amd64.tar.gz -O prometheus-2.28.0.linux-amd64.tar.gz tar xf prometheus-2.28.0.linux-amd64.tar.gz cp -far prometheus-2.28.0.linux-amd64/* /opt/prometheus/ # service cat \u0026lt;\u0026lt;EOF \u0026gt;/etc/systemd/system/prometheus.service [Unit] Description=\u0026quot;prometheus\u0026quot; Documentation=https://prometheus.io/ After=network.target [Service] Type=simple ExecStart=/opt/prometheus/prometheus --config.file=/opt/prometheus/prometheus.yml --storage.tsdb.path=/opt/prometheus/data --web.enable-lifecycle --enable-feature=remote-write-receiver --query.lookback-delta=2m Restart=on-failure SuccessExitStatus=0 LimitNOFILE=65536 StandardOutput=syslog StandardError=syslog SyslogIdentifier=prometheus [Install] WantedBy=multi-user.target EOF systemctl daemon-reload systemctl enable prometheus systemctl restart prometheus systemctl status prometheus # install mysql yum -y install mariadb* systemctl enable mariadb systemctl restart mariadb mysql -e \u0026quot;SET PASSWORD FOR 'root'@'localhost' = PASSWORD('1234');\u0026quot; # install redis yum install -y redis systemctl enable redis systemctl restart redis  上例中mysql的root密码设置为了1234，建议维持这个不变，后续就省去了修改配置文件的麻烦。\n安装夜莺 # mkdir -p /opt/n9e \u0026amp;\u0026amp; cd /opt/n9e # 去 https://github.com/didi/nightingale/releases 找最新版本的包，文档里的包地址可能已经不是最新的了 tarball=n9e-5.8.0.tar.gz urlpath=https://github.com/didi/nightingale/releases/download/v5.8.0/${tarball} wget $urlpath || exit 1 tar zxvf ${tarball} mysql -uroot -p1234 \u0026lt; docker/initsql/a-n9e.sql nohup ./n9e server \u0026amp;\u0026gt; server.log \u0026amp; nohup ./n9e webapi \u0026amp;\u0026gt; webapi.log \u0026amp; # check logs # check port  如果启动成功，server 默认会监听在 19000 端口，webapi 会监听在 18000 端口，且日志没有报错。上面使用 nohup 简单演示，生产环境建议用 systemd 托管，相关 service 文件可以在 etc/service 目录下，供参考，nohup和systemd的使用教程\n配置文件etc/server.conf和etc/webapi.conf中都含有 mysql 的连接地址配置，检查一下用户名和密码，prometheus 如果使用上面的脚本安装，默认会监听本机 9090 端口，server.conf 和 webapi.conf 中的 prometheus 相关地址都不用修改就是对的，如果使用贵司之前已有的 Prometheus，就要检查这俩配置文件中的时序库的配置了，把 127.0.0.1:9090 改成你的 Prometheus。\n好了，浏览器访问 webapi 的端口（默认是18000）就可以体验相关功能了，默认用户是root，密码是root.2020。如果安装过程出现问题，可以参考公众号的视频教程。\n夜莺服务端部署好了，默认情况下时序库中只有少量 Prometheus 自身的数据，大家可以简单测试。接下来要考虑监控数据采集的问题，如果是 Prometheus 重度用户，可以继续使用各类 Exporter 来采集，只要数据进了时序库了，夜莺就能够消费（判断告警、展示图表等）了。如果是新用户，我们建议使用 Categraf （Gitlink | Github ）来采集，当然，也可以使用 Telegraf、Grafana-agent、Datadog-agent，这些监控采集器都可以和夜莺无缝集成。\n部署集群 # 如果担心容量问题，或高可用问题，可以部署夜莺集群，除了夜莺的两个组件，还有依赖的 MySQL、Redis、时序库，都需要部署集群版。\nMySQL # MySQL 全局就部署一个主从集群就可以了，n9e-webapi、n9e-server都要连到 MySQL 的主库。建议使用公有云提供的 RDS 服务。\nRedis # 夜莺 5.8.0（含）之前的版本，都只支持 standalone 的 Redis，为了高可用，建议使用公有云提供的 Redis 服务。从 5.9.0 开始，夜莺依赖的 Redis 支持 cluster 版本和 sentinel 版本。为了简单起见，全局就使用一套 Redis 即可。如果 n9e-webapi 和 n9e-server 根据地域做了拆分，物理距离较远，比如一个在国内，一个在美东，此时 Redis 就建议拆开，n9e-webapi 依赖一套 Redis，n9e-server 依赖另一套 Redis，如果 n9e-server 有多套，也可以为每套 n9e-server 部署单独的 Redis。\n时序库 # 时序库的高可用，有不同的方案，我们建议使用 VictoriaMetrics 或 Thanos，VictoriaMetrics 如何部署集群版本，后面的章节会有介绍，当然大家也可以查看 VictoriaMetrics 的官方文档，Thanos 的话请大家自行查看 Thanos 的官方文档。\nn9e-webapi # 高可用就是部署多个实例即可，各个n9e-webapi的实例的配置完全相同。前面架设 nginx 或 lvs，某个 n9e-webapi 挂掉了，会被 nginx、lvs 自动摘掉，用户无感\nn9e-server # 首先，n9e-server 是随着时序库走的，贵司有几套时序库，就要部署几套 n9e-server，每套 n9e-server 要取个名字，在 server.conf 中有个 ClusterName 的配置来标识 n9e-server 集群的名字，每套 n9e-server 可以只有一个实例，可以有多个实例组成集群，一套 n9e-server 集群内的多个实例，其 ClusterName 要保持一致。不同的 n9e-server 集群，ClusterName 要不同。\n如果有多套时序库，其连接信息都要配置到 n9e-webapi 的配置文件 webapi.conf 中，即配置多个 [[Clusters]] ，每个 Cluster 有个 Name 的配置，要和 server.conf 中的 ClusterName 保持一致。\n"}),e.add({id:5,href:"/docs/install/victoria/",title:"VictoriaMetrics",description:"使用 VictoriaMetrics 作为夜莺 Nightingale 的时序存储库",content:"简介 # VictoriaMetrics 架构简单，可靠性高，在性能，成本，可扩展性方面表现出色，社区活跃，且和 Prometheus 生态绑定紧密。如果单机版本的 Prometheus 无法在容量上满足贵司的需求，可以使用 VictoriaMetrics 作为时序数据库。\nVictoriaMetrics 提供单机版和集群版。如果您的每秒写入数据点数小于100万（这个数量是个什么概念呢，如果只是做机器设备的监控，每个机器差不多采集200个指标，采集频率是10秒的话每台机器每秒采集20个指标左右，100万/20=5万台机器），VictoriaMetrics 官方默认推荐您使用单机版，单机版可以通过增加服务器的CPU核心数，增加内存，增加IOPS来获得线性的性能提升。且单机版易于配置和运维。\n集群架构 # vmstorage、vminsert、vmselect 三者组合构成 VictoriaMetrics 的集群功能，三者都可以通过启动多个实例来分担承载流量，通过要在 vminsert 和 vmselect 前面架设负载均衡。\nvmstorage 是数据存储模块\n 其数据保存在-storageDataPath指定的目录中，默认为./vmstorage-data/，vmstorage 是有状态模块，删除 storage node 会丢失约 1/N的历史数据（N 为集群中 vmstorage node 的节点数量）。增加 storage node，则需要同步修改 vminsert 和 vmselect 的启动参数，将新加入的storage node节点地址通过命令行参数 -storageNode传入给vminsert和vmselect vmstorage 启动后，会监听三个端口，分别是 -httpListenAddr :8482、-vminsertAddr :8400、-vmselectAddr :8401。端口8400负责接收来自 vminsert 的写入请求，端口8401负责接收来自 vmselect 的数据查询请求，端口8482则是 vmstorage 自身提供的 http api 接口  vminsert 接收来自客户端的数据写入请求，并负责转发到选定的vmstorage\n vminsert 接收到数据写入请求后，按照 jump consistent hash 算法，将数据转发到选定的某个vmstorage node 上。vminsert 本身是无状态模块，可以增加或者删除一个或多个实例，而不会造成数据的损失。vminsert 模块通过启动时的参数 -storageNode xxx,yyy,zzz 来感知到整个 vmstorage 集群的完整 node 地址列表 vminsert 启动后，会监听一个端口-httpListenAddr :8480。该端口实现了 prometheus remote_write协议，因此可以接收和解析通过 remote_write 协议写入的数据。不过要注意，VictoriaMetrics 集群版本具有多租户功能，因此租户ID会以如下形式出现在 API URL 中: http://vminsert:8480/insert/\u0026lt;account_id\u0026gt;/prometheus/api/v1/write 更多 URL Format 可以参考 VictoriaMetrics官网  vmselect 接收来自客户端的数据查询请求，并负责转发到所有的 vmstorage 查询结果，最后将结果 merge 后返回\n vmselect 启动后，会监听一个端口-httpListenAddr :8481。该端口实现了 prometheus query相关的接口。不过要注意，VictoriaMetrics 集群版本具有多租户功能，因此租户ID会以如下形式出现在 API URL 中: http://vminsert:8481/select/\u0026lt;account_id\u0026gt;/prometheus/api/v1/query。 更多 URL Format 可以参考 VictoriaMetrics官网  安装部署 # 1、 去 vm release 下载编译好的二进制版本，比如我们选择下载 v1.69.0 amd64。\n2、 解压缩后得到：\n$ ls -l vm*-prod -rwxr-xr-x 1 work work 10946416 Nov 8 22:03 vminsert-prod* -rwxr-xr-x 1 work work 13000624 Nov 8 22:03 vmselect-prod* -rwxr-xr-x 1 work work 11476736 Nov 8 22:03 vmstorage-prod*  3、 启动三个 vmstorage 实例（可以用下面的脚本快速生成不同实例的启动命令）\n#!/bin/bash for i in `seq 0 2`; do if [ $i -eq 0 ]; then i=\u0026quot;\u0026quot; fi pp=$i httpListenAddr=${pp}8482 vminsertAddr=${pp}8400 vmselectAddr=${pp}8401 storageDataPath=./${pp}vmstorage-data prog=\u0026quot;nohup ./vmstorage-prod -loggerTimezone Asia/Shanghai \\ -storageDataPath $storageDataPath \\ -httpListenAddr :$httpListenAddr \\ -vminsertAddr :$vminsertAddr \\ -vmselectAddr :$vmselectAddr \\ \u0026amp;\u0026gt; ${pp}vmstor.log \u0026amp;\u0026quot; echo $prog (exec \u0026quot;$prog\u0026quot;) done  也可以输入以下命令行启动三个实例：\nnohup ./vmstorage-prod -loggerTimezone Asia/Shanghai -storageDataPath ./vmstorage-data -httpListenAddr :8482 -vminsertAddr :8400 -vmselectAddr :8401 \u0026amp;\u0026gt; vmstor.log \u0026amp; nohup ./vmstorage-prod -loggerTimezone Asia/Shanghai -storageDataPath ./1vmstorage-data -httpListenAddr :18482 -vminsertAddr :18400 -vmselectAddr :18401 \u0026amp;\u0026gt; 1vmstor.log \u0026amp; nohup ./vmstorage-prod -loggerTimezone Asia/Shanghai -storageDataPath ./2vmstorage-data -httpListenAddr :28482 -vminsertAddr :28400 -vmselectAddr :28401 \u0026amp;\u0026gt; 2vmstor.log \u0026amp;  4、 启动一个 vminsert 实例：\nnohup ./vminsert-prod -httpListenAddr :8480 -storageNode=127.0.0.1:8400,127.0.0.1:18400,127.0.0.1:28400 \u0026amp;\u0026gt;vminsert.log \u0026amp;  5、 启动一个 vmselect 实例：\nnohup ./vmselect-prod -httpListenAddr :8481 -storageNode=127.0.0.1:8401,127.0.0.1:18401,127.0.0.1:28401 \u0026amp;\u0026gt;vmselect.log \u0026amp;  6、 查看 vmstorage，vminsert，vmselect 的 /metrics 接口:\ncurl http://127.0.0.1:8482/metrics curl http://127.0.0.1:18482/metrics curl http://127.0.0.1:28482/metrics curl http://127.0.0.1:8481/metrics curl http://127.0.0.1:8480/metrics  7、 n9e-server 通过 remote write 协议写入时序库，VictoriaMetrics 作为时序库的一个选择，其 remote write 接口地址为：http://127.0.0.1:8480/insert/0/prometheus/api/v1/write 把这个地址配置到 server.conf 当中，配置完了重启 n9e-server\n# Reader部分修改Url [Reader] Url = \u0026quot;http://172.21.0.8:8481/select/0/prometheus\u0026quot; # Writers部分修改Url [[Writers]] Url = \u0026quot;http://172.21.0.8:8480/insert/0/prometheus/api/v1/write\u0026quot;  8、 修改 n9e-webapi 的配置文件 ./etc/webapi.conf 如下：\n[[Clusters]] # Prometheus cluster name Name = \u0026quot;Default\u0026quot; # Prometheus APIs base url Prom = \u0026quot;http://127.0.0.1:8481/select/0/prometheus\u0026quot;  然后，重启 n9e-webapi，这样夜莺就可以查询到 VictoriaMetrics 集群的数据了。\n如果您使用的是 VictoriaMetrics 单机版，端口是 8428，故而 Nightingale 的配置文件需要做如下调整：\n# server.conf # Reader部分修改为： [Reader] Url = \u0026quot;http://127.0.0.1:8428\u0026quot; # Writers部分修改为： [[Writers]] Url = \u0026quot;http://127.0.0.1:8428/api/v1/write\u0026quot;  # webapi.conf # Clusters部分修改为： [[Clusters]] Name = \u0026quot;Default\u0026quot; Prom = \u0026quot;http://127.0.0.1:8428\u0026quot;  FAQ # VictoriaMetrics 单机版本如何保障数据的可靠性？\nvm 针对磁盘IO有针对性的优化，单机版可以考虑将数据的可靠性保障交给 EBS 等云盘来保证。\nVictoriaMetrics 如何评估容量？\n参考vm的官方文档。\nVictoriaMetrics 集群版本增加或者删除 vmstorage node 的时候，数据如何再平衡？\nvm 不支持扩缩容节点时，对数据进行自动的再平衡。\nVictoriaMetrics 的数据大小如何查看？\n可以通过 vmstorage 实例暴露的 /metrics 接口来获取到相应的统计数据，譬如：\n$ curl http://127.0.0.1:8482/metrics |grep -i data_size vm_data_size_bytes{type=\u0026quot;indexdb\u0026quot;} 609291 vm_data_size_bytes{type=\u0026quot;storage/big\u0026quot;} 0 vm_data_size_bytes{type=\u0026quot;storage/small\u0026quot;} 8749893  vminsert 在将数据写入多个 vmstorage node的时候，是按照什么规则将数据写入到不同的 node 上的？\n采用 jump consistent hash 对数据进行分片，写入到相应的 storage node 上。\nvmselect 在接到查询请求的时候，如何定位到请求的数据是在哪个 storage node上的？\nvmselect 并不知道每个 metrics 对应的数据分布的 storage node，vmselect 会对所有的 storage node 发起查询请求，最后进行数据合并，并返回。\nVictoriaMetrics 和 M3db 的对比和选择？\nm3db 架构设计上更高级，实现难度高，m3db 在时序数据功能之后，重点解决了自动扩缩容，数据自动平衡等运维难题。但是因此也更复杂，可靠性也更难保证。VictoriaMetrics 架构设计上更倾向于简单可靠，重点优化了单机版的性能，强调垂直扩展，同时和 prometheus 生态做到兼容，甚至于在很多的点上做到了加强。但是 VictoriaMetrics 对于时序数据 downsample，节点的自动扩缩容，数据自动再平衡等高级功能和分布式能力，是有缺失的。\n相关资料 #  使用 Docker Compose 快速部署 VictoriaMetrics 使用 Helm Chart 快速在 Kubernetes中部署 VictoriaMetrics 使用 VictoriaMetrics Operator 在 Kubernetes中部署 VictoriaMetrics  "}),e.add({id:6,href:"/docs/install/ibex/",title:"Ibex",description:"夜莺 Nightingale 的告警自愈模块的安装",content:"Ibex 是告警自愈功能依赖的模块，提供一个批量执行命令的通道，可以做到在告警的时候自动去目标机器执行脚本，如果大家没有此需求，无需阅读本节内容。\n概述 # 所谓的告警自愈，典型手段是在告警触发时自动回调某个 webhook 地址，在这个 webhook 里写告警自愈的逻辑，夜莺默认支持这种方式。另外，夜莺还可以更进一步，配合 ibex 这个模块，在告警触发的时候，自动去告警的机器执行某个脚本，这种机制可以大幅简化构建运维自愈链路的工作量，毕竟，不是所有的运维人员都擅长写 http server，但所有的运维人员，都擅长写脚本。这种方式是典型的物理机时代的产物，希望各位朋友用不到这个工具（说明贵司的IT技术已经走得非常靠前了）。\n架构 # ibex 包括 server 和 agentd 两个模块，agentd 周期性调用 server 的 rpc 接口，询问有哪些任务要执行，如果有分配给自己的任务，就从 server 拿到任务脚本信息，在本地 fork 一个进程运行，然后将结果上报给服务端。为了简化部署，server 和 agentd 融合成了一个二进制，就是 ibex，通过传入不同的参数来启动不同的角色。ibex 架构图如下：\n项目地址 #  Repo：https://github.com/flashcatcloud/ibex Linux-amd64 有编译好的二进制，在这里  安装启动 # 下载安装包之后，解压缩，在 etc 下可以找到服务端和客户端的配置文件，在 sql 目录下可以找到初始化 sql 脚本。\n初始化 sql # mysql \u0026lt; sql/ibex.sql  启动 server # server 的配置文件是 etc/server.conf，注意修改里边的 mysql 连接地址，配置正确的 mysql 用户名和密码。然后就可以直接启动了：\nnohup ./ibex server \u0026amp;\u0026gt; server.log \u0026amp;  ibex 没有 web 页面，只提供 api 接口，鉴权方式是 http basic auth，basic auth 的用户名和密码默认都是 ibex，在 etc/server.conf 中可以找到，如果ibex 部署在互联网，一定要修改默认用户名和密码，当然，因为 Nightingale 要调用 ibex，所以 Nightingale 的 server.conf 和 webapi.conf 中也配置了 ibex 的 basic auth 账号信息，要改就要一起改啦。\n启动agentd # 客户端的配置非常非常简单，agentd.conf 内容如下：\n# debug, release RunMode = \u0026quot;release\u0026quot; # task meta storage dir MetaDir = \u0026quot;./meta\u0026quot; [Heartbeat] # unit: ms Interval = 1000 # rpc servers Servers = [\u0026quot;10.2.3.4:20090\u0026quot;] # $ip or $hostname or specified string Host = \u0026quot;telegraf01\u0026quot;  重点关注 Heartbeat 这个部分，Interval 是心跳频率，默认是 1000 毫秒，如果机器量比较小，比如小于 1000 台，维持 1000 毫秒没问题，如果机器量比较大，可以适当调大这个频率，比如 2000 或者 3000，可以减轻服务端的压力。Servers 是个数组，配置的是 ibex-server 的地址，ibex-server 可以启动多个，多个地址都配置到这里即可，Host 这个字段，是本机的唯一标识，有三种配置方式，如果配置为 $ip，系统会自动探测本机的 IP，如果是 $hostname，系统会自动探测本机的 hostname，如果是其他字符串，那就直接把该字符串作为本机的唯一标识。每个机器上都要部署 ibex-agentd，不同的机器要保证 Host 字段获取的内容不能重复。\n要想做到告警的机器自动执行脚本，需要保证告警消息中的 ident 表示机器标识，且和 ibex-agentd 中的 Host 配置对应上。\n下面是启动 ibex-agentd 的命令：\nnohup ./ibex agentd \u0026amp;\u0026gt; agentd.log \u0026amp;  另外，细心的读者应该会发现 ibex 的压缩包里的 etc 目录下有个 service 目录，里边准备好了两个 service 样例文件，便于大家使用 systemd 来管理 ibex 进程，生产环境，建议使用 systemd 来管理。nohup和systemd的知识\n"}),e.add({id:7,href:"/docs/agent/categraf/",title:"Categraf",description:"Categraf是一款all-in-one的采集器，是夜莺主推的一款监控客户端",content:"Categraf 是一款 all-in-one 的采集器，由 快猫团队 开源，代码托管在两个地方：\n gitlink: https://www.gitlink.org.cn/flashcat/categraf github: https://github.com/flashcatcloud/categraf  Categraf 不但可以采集 OS、MySQL、Redis、Oracle 等常见的监控对象，也准备提供日志采集能力和 trace 接收能力，这是夜莺主推的采集器，相关信息请查阅项目 README\nCategraf 采集到数据之后，通过 remote write 协议推给远端存储，Nightingale 恰恰提供了 remote write 协议的数据接收接口，所以二者可以整合在一起，重点是配置 Categraf 的 conf/config.toml 中的 writer 部分，其中 url 部分配置为 n9e-server 的 remote write 接口：\n[writer_opt] # default: 2000 batch = 2000 # channel(as queue) size chan_size = 10000 [[writers]] url = \u0026quot;http://N9E-SERVER:19000/prometheus/v1/write\u0026quot; # Basic auth username basic_auth_user = \u0026quot;\u0026quot; # Basic auth password basic_auth_pass = \u0026quot;\u0026quot; # timeout settings, unit: ms timeout = 5000 dial_timeout = 2500 max_idle_conns_per_host = 100  "}),e.add({id:8,href:"/docs/agent/telegraf/",title:"Telegraf",description:"Telegraf 接入夜莺 Nightingale",content:"Telegraf 是 InfluxData 公司开源的一款采集器，内置非常多的采集插件，不过 Telegraf 是面向 InfluxDB 生态的，采集的监控数据推给 InfluxDB 非常合适，推给 Prometheus、Victoriametrics、Thanos 这些时序库，可能会带来问题。主要是两点：\n 有些数据是 string 类型的，Prometheus、VM、M3、Thanos 等都不支持 string 类型的数据 有些采集器设计的标签是非稳态的设计，比如经常会看到 result=success 和 result=failed 的标签，需要手工配置采集器 drop 掉，但是对于新手确实有些难度  另外一个问题是，Telegraf 采集的数据存到 Prometheus 中，这种做法在业界实践的比较少，导致 Grafana 大盘很少，需要我们付出较大精力手工制作大盘。不过，如果，你是资深监控玩家，Telegraf 上面这些问题都不是问题。下面是笔者之前调研 Telegraf 的几篇笔记，供大家参考：\n Telegraf监控客户端调研笔记（1）-介绍、安装、初步测试 Telegraf监控客户端调研笔记（2）-CPU、MEM、DISK、IO相关指标采集 Telegraf监控客户端调研笔记（3）-kernel、system、processes相关指标采集 Telegraf监控客户端调研笔记（4）-exec、net、netstat相关指标采集 Telegraf监控客户端调研笔记（5）-本地端口监控\u0026amp;远程TCP探测 Telegraf监控客户端调研笔记（6）-PING监控、进程监控  Telegraf 是如何与 Nightingale 整合的呢？Telegraf 有不同的 output plugin，可以把采集的数据推给 OpenTSDB、推给 Datadog，Nightingale 实现了 OpenTSDB 和 Datadog 这两种消息接收接口，所以，可以通过任一 output plugin 和 Nightingale 对接。下面提供一个简单的 Telegraf 配置供大家参考，使用 OpenTSDB 的 output plugin 和 Nightingale 对接，即 [[outputs.opentsdb]] 配置段，host 部分配置为 n9e-server 的地址：\n#!/bin/sh version=1.20.4 tarball=telegraf-${version}_linux_amd64.tar.gz wget https://dl.influxdata.com/telegraf/releases/$tarball tar xzvf $tarball mkdir -p /opt/telegraf cp -far telegraf-${version}/usr/bin/telegraf /opt/telegraf cat \u0026lt;\u0026lt;EOF \u0026gt; /opt/telegraf/telegraf.conf [global_tags] [agent] interval = \u0026quot;10s\u0026quot; round_interval = true metric_batch_size = 1000 metric_buffer_limit = 10000 collection_jitter = \u0026quot;0s\u0026quot; flush_interval = \u0026quot;10s\u0026quot; flush_jitter = \u0026quot;0s\u0026quot; precision = \u0026quot;\u0026quot; hostname = \u0026quot;\u0026quot; omit_hostname = false [[outputs.opentsdb]] host = \u0026quot;http://127.0.0.1\u0026quot; port = 19000 http_batch_size = 50 http_path = \u0026quot;/opentsdb/put\u0026quot; debug = false separator = \u0026quot;_\u0026quot; [[inputs.cpu]] percpu = true totalcpu = true collect_cpu_time = false report_active = true [[inputs.disk]] ignore_fs = [\u0026quot;tmpfs\u0026quot;, \u0026quot;devtmpfs\u0026quot;, \u0026quot;devfs\u0026quot;, \u0026quot;iso9660\u0026quot;, \u0026quot;overlay\u0026quot;, \u0026quot;aufs\u0026quot;, \u0026quot;squashfs\u0026quot;] [[inputs.diskio]] [[inputs.kernel]] [[inputs.mem]] [[inputs.processes]] [[inputs.system]] fielddrop = [\u0026quot;uptime_format\u0026quot;] [[inputs.net]] ignore_protocol_stats = true EOF cat \u0026lt;\u0026lt;EOF \u0026gt; /etc/systemd/system/telegraf.service [Unit] Description=\u0026quot;telegraf\u0026quot; After=network.target [Service] Type=simple ExecStart=/opt/telegraf/telegraf --config telegraf.conf WorkingDirectory=/opt/telegraf SuccessExitStatus=0 LimitNOFILE=65535 StandardOutput=syslog StandardError=syslog SyslogIdentifier=telegraf KillMode=process KillSignal=SIGQUIT TimeoutStopSec=5 Restart=always [Install] WantedBy=multi-user.target EOF systemctl daemon-reload systemctl enable telegraf systemctl restart telegraf systemctl status telegraf  "}),e.add({id:9,href:"/docs/agent/datadog-agent/",title:"Datadog-Agent",description:"Datadog-Agent 接入夜莺 Nightingale",content:"Datadog 是专门提供监控和分析服务的 SaaS 服务商，市值几百亿，成立了10多年了，他们做的客户端采集器，理论上应该是比较完备的，夜莺实现了几个 Datadog 特定的接口，可以接收Datadog-Agent 推送上来的数据，即：我们可以拿 Datadog-Agent 作为客户端采集器采集监控数据，然后上报给夜莺。\n1、注册datadog的账号 # https://www.datadoghq.com/\n2、选择套餐 # https://app.datadoghq.com/billing/plan 可以选择免费的套餐\n3、拿到agent安装命令 # https://app.datadoghq.com/account/settings#agent 选择对应的OS，比如CentOS7，可能是类似这么个命令：\nDD_AGENT_MAJOR_VERSION=7 DD_API_KEY=xxx DD_SITE=\u0026quot;datadoghq.com\u0026quot; bash -c \u0026quot;$(curl -L https://s3.amazonaws.com/dd-agent/scripts/install_script.sh)\u0026quot;  DD_API_KEY 是一串字符串，不同的账号有自己的 API_KEY，拿着这个命令去 shell 下（使用root账号应该会省事一些）跑一下安装\n4、修改配置文件 # 修改 Datadog-Agent 的配置文件，把推送监控数据的地址，改成 n9e-server 的地址，配置文件地址在：/etc/datadog-agent/datadog.yaml 修改 dd_url 这个配置项，比如我的环境：\ndd_url: http://10.206.0.16:19000/datadog  5、重启datadog-agent # systemctl restart datadog-agent  "}),e.add({id:10,href:"/docs/agent/grafana-agent/",title:"Grafana-Agent",description:"Grafana-Agent 接入夜莺 Nightingale",content:"Grafana-agent 是 Grafana 开源的一款 Agent，专门用于和自己的 Cloud 做数据采集集成，通过 remote write 协议推数据给后端，和 Categraf 的数据推送方式一样，所以，也是可以作为 Nightingale 的采集器的。Grafana-Agent 的具体使用请查阅 Grafana 官方文档，下面给出 v0.23.0 版本的 Grafana-Agent 的简要安装方式，如果各位看官使用了其他版本的 Grafana-Agent，下面的教程可能就不适用了，毕竟，Grafana-Agent 也在快速迭代，请大家注意。\n1. 下载二进制 # 以 64 位 Linux 举例：\ncurl -SOL \u0026quot;https://github.com/grafana/agent/releases/download/v0.23.0/agent-linux-amd64.zip\u0026quot; gunzip ./agent-linux-amd64.zip chmod a+x \u0026quot;agent-linux-amd64\u0026quot;  2. 生成配置 # cat \u0026lt;\u0026lt;EOF \u0026gt; ./agent-cfg.yaml server: log_level: info http_listen_port: 12345 metrics: global: scrape_interval: 15s scrape_timeout: 10s remote_write: - url: https://N9E-SERVER:19000/prometheus/v1/write basic_auth: username: \u0026quot;\u0026quot; password: \u0026quot;\u0026quot; integrations: agent: enabled: true node_exporter: enabled: true include_exporter_metrics: true EOF  上面的 url 部分，就是 n9e-server 的 remote write 数据接收接口，仔细看就会发现，和 Categraf 章节用的 url 是一样的。\n3. 启动 grafana-agent # nohup ./agent-linux-amd64 \\ -config.file ./agent-cfg.yaml \\ -metrics.wal-directory ./data \\ \u0026amp;\u0026gt; grafana-agent.log \u0026amp;  上面的配置内置启用了 node_exporter，Grafana-Agent 内置了很多 exporter，省的到处去找 exporter 了，感兴趣的话大家可以查阅 Grafana-Agent 的文档仔细研究下。\n"}),e.add({id:11,href:"/docs/agent/falcon-plugin/",title:"Falcon-Plugin",description:"Falcon-Plugin 接入夜莺 Nightingale",content:"Nightingale 实现了 Open-Falcon 的 HTTP 数据接收接口，所以，Open-Falcon 社区很多采集插件也是可以直接使用的。但是 Falcon-Agent 不行，因为 Falcon-Agent 推送监控数据给服务端，走的是 RPC 接口。\n如果你发现某个 Falcon-Plugin 是用 CRON 的方式驱动的，推送数据走的是 Falcon-Agent 的 HTTP 接口，那这个插件就可以推数据给夜莺。举个例子，比如 mymon 其配置文件采用 ini 格式，下面是样例：\n[default] basedir = . # 工作目录 log_dir = ./fixtures # 日志目录，默认日志文件为myMon.log,旧版本有log_file项，如果同时设置了，会优先采用log_file ignore_file = ./falconignore # 配置忽略的metric项 snapshot_dir = ./snapshot # 保存快照(process, innodb status)的目录 snapshot_day = 10 # 保存快照的时间(日) log_level = 5 # 日志级别[RFC5424] # 0 LevelEmergency # 1 LevelAlert # 2 LevelCritical # 3 LevelError # 4 LevelWarning # 5 LevelNotice # 6 LevelInformational # 7 LevelDebug falcon_client=http://127.0.0.1:1988/v1/push # falcon agent连接地址 [mysql] user=root # 数据库用户名 password=1tIsB1g3rt # 您的数据库密码 host=127.0.0.1 # 数据库连接地址 port=3306 # 数据库端口  注意 falcon_client 配置项，配置的是 Falcon-Agent 的数据接收接口，可以把这个配置改成夜莺 n9e-server 的地址： http://N9E-SERVER:19000/openfalcon/push 。\nOpen-Falcon 的监控数据中有一个 endpoint 字段，夜莺会把 endpoint 字段当做监控对象唯一标识来对待，自动解析之后入库，就可以在对象列表中看到了。当然，如果没有 endpoint 字段也没关系，使用 metric 和 tags 也是可以唯一标识一个 Series 的。\n"}),e.add({id:12,href:"/docs/usage/video/",title:"入门教程",description:"夜莺（ Nightingale ）入门视频教程",content:"页面上的功能挨个描述的话篇幅太长了，录制了一套小视频教程供大家参考，不过这套视频教程比较浅显，基于5.0的版本介绍的，相对较老，夜莺一直在快速迭代，增加了很多新特性，有很多特性没有在视频教程中体现，请大家见谅，后面会再录制一套更详尽的，基于新版本的讲解视频。\n 01-使用Docker Compose一行命令安装夜莺v5 02-快速在生产环境部署启动单机版夜莺v5 03-讲解夜莺v5人员组织相关功能 04-讲解夜莺v5监控看图相关功能 05-讲解夜莺v5告警规则的使用 06-讲解夜莺v5告警屏蔽规则的使用 07-讲解夜莺告警订阅规则的使用 08-讲解夜莺v5活跃告警和历史告警 09-讲解夜莺v5告警自愈脚本的使用 10-讲解夜莺监控对象的管理功能 11-夜莺v5如何接入多个时序存储 12-讲解夜莺v5配置文件  除了这些视频教程，使用手册这一章，还会提供更多小节来介绍一些大家常问的问题，比如如何监控交换机，如何监控应用等。从总体问题比例来看，夜莺服务端问题相对较少，大家摸索一下，很快可以掌握，疑问比较多的，是对各种目标的监控，比如如何监控 MySQL，如何监控 Redis 等，针对这部分问题，大家应该去查看采集器的文档，比如 Telegraf 每个采集器下面都有 README介绍， 通过这些 README，理论上就可以知道如何使用各个采集器。Categraf 的采集器目录 在这里， 未来我们也会把所有采集器补充完整的 README，以及告警规则和监控大盘JSON，大家导入直接就可以使用，当然，路漫漫其修远兮，一步一步来吧。\n"}),e.add({id:13,href:"/docs/usage/snmp/",title:"SNMP",description:"夜莺（ Nightingale ）通过 SNMP 监控网络设备",content:"监控网络设备，主要是通过 SNMP 协议，Categraf、Telegraf、Datadog-Agent、snmp_exporter 都提供了这个能力。\nCategraf # Categraf 提供了一个网络设备的采集插件：switch_legacy，在 conf/input.switch_legacy 下可以看到配置文件，最核心就是配置交换机的 IP 以及认证信息，switch_legacy 当前只支持 v2 协议，所以认证信息就是 community 字段。其他配置都一目了然，这里就不赘述了。\n这个插件是把之前 Open-Falcon 社区的 swcollector 直接拿过来了，感谢 冯骐 大佬持续在维护这个开源项目。\nTelegraf # Telegraf 内置支持 SNMP 的采集，本节给一个入门例子，让大家快速上手，更多具体知识可以参考这里。在 telegraf.conf 中搜索 inputs.snmp，即可找到对应的配置，例子如下：\n[[inputs.snmp]] agents = [\u0026quot;udp://172.25.79.194:161\u0026quot;] timeout = \u0026quot;5s\u0026quot; version = 3 agent_host_tag = \u0026quot;ident\u0026quot; retries = 1 sec_name = \u0026quot;managev3user\u0026quot; auth_protocol = \u0026quot;SHA\u0026quot; auth_password = \u0026quot;example.Demo.c0m\u0026quot; [[inputs.snmp.field]] oid = \u0026quot;RFC1213-MIB::sysUpTime.0\u0026quot; name = \u0026quot;uptime\u0026quot; [[inputs.snmp.field]] oid = \u0026quot;RFC1213-MIB::sysName.0\u0026quot; name = \u0026quot;source\u0026quot; is_tag = true [[inputs.snmp.table]] oid = \u0026quot;IF-MIB::ifTable\u0026quot; name = \u0026quot;interface\u0026quot; inherit_tags = [\u0026quot;source\u0026quot;] [[inputs.snmp.table.field]] oid = \u0026quot;IF-MIB::ifDescr\u0026quot; name = \u0026quot;ifDescr\u0026quot; is_tag = true  上面非常关键的部分是：agent_host_tag = \u0026quot;ident\u0026quot;，因为夜莺对 ident 这个标签会特殊对待处理，把携有这个标签的数据当做隶属某个监控对象的数据，机器和网络设备都是典型的期望作为监控对象来管理的，所以 SNMP 的采集中，我们把网络设备的 IP 放到 ident 这个标签里带上去。\n另外这个采集规则是 v3 的校验方法，不同的公司可能配置的校验方式不同，请各位参照 telegraf.conf 中那些 SNMP 相关的注释仔细核对，如果是 v2 会简单很多，把上例中的如下部分：\nversion = 3 sec_name = \u0026quot;managev3user\u0026quot; auth_protocol = \u0026quot;SHA\u0026quot; auth_password = \u0026quot;example.Demo.c0m\u0026quot;  换成：\nversion = 2 community = \u0026quot;public\u0026quot;  即可，当然了，community 要改成你们自己的，这里写的 “public” 只是举个例子。\ninputs.snmp.field 相关的那些配置，可以采集到各个网口的监控指标，更多的使用方式请参考官网\n另外，snmp的采集，建议大家部署单独的 Telegraf 来做，因为和机器、中间件等的采集频率可能不同，比如边缘交换机，我们 5min 采集一次就够了，如果按照默认的配置可是 10s 采集一次，实在是太频繁了，可能会给一些老式交换机造成比较大的压力，采集频率在 telegraf.conf 的最上面 [agent] 部分，边缘交换机建议配置为：\n[agent] interval = \u0026quot;300s\u0026quot; flush_interval = \u0026quot;300s\u0026quot;  核心交换机可以配置的频繁一些，比如 60s 或者 120s，请各位网络工程师朋友自行斟酌。\n"}),e.add({id:14,href:"/docs/usage/apm/",title:"应用监控",description:"夜莺（ Nightingale ）通过 Prometheus SDK 监控应用程序",content:"写在前面 # 应用监控实际要比 OS、中间件的监控更为关键，因为某个 OS 层面的指标异常，比如 CPU 飙高了，未必会影响终端用户的体验，但是应用层面的监控指标出问题，通常就会影响客户的感受、甚至影响客户的付费。\n针对应用监控，Google提出了 4 个黄金指标，分别是：流量、延迟、错误、饱和度，其中前面 3 个指标都可以通过内嵌 SDK 的方式埋点采集，本节重点介绍这种方式。当然了，内嵌 SDK 有较强的代码侵入性，如果业务研发难以配合，也可以采用解析日志的方案，这个超出了夜莺（夜莺是指标监控系统）的范畴，大家如果感兴趣，可以了解一下快猫的商业化产品\n埋点工具 # 最常见的通用埋点工具有两个，一个是 statsd，一个是 prometheus SDK，当然，各个语言也会有自己的更方便的方式，比如 Java 生态使用 micrometer 较多，如果是 SpringBoot 的程序，则使用 actuator 会更便捷，actuator 底层就是使用 micrometer。\n夜莺自身监控 # 我们就以夜莺自身的代码举例，讲解如何内嵌埋点工具，这里选择 prometheus SDK 作为埋点方案。\n夜莺核心模块有两个，Webapi 主要是提供 HTTP 接口给 JavaScript 调用，Server 主要是负责接收监控数据，处理告警规则，这两个模块都引入了 Prometheus 的 Go 的SDK，用此方式做 App Performance 监控，本节以夜莺的代码为例，讲解如何使用 Prometheus 的 SDK。\nWebapi # Webapi 模块主要统计两个内容，一个是请求的数量统计，一个是请求的延迟统计，统计时，要用不同的 Label 做维度区分，后面就可以通过不同的维度做多种多样的统计分析，对于 HTTP 请求，规划 4 个核心 Label，分别是：service、code、path、method。service 标识服务名称，要求全局唯一，便于和其他服务名称区分开，比如 Webapi 模块，就定义为 n9e-webapi，code 是 HTTP 返回的状态码，200 就表示成功数量，其他 code 就是失败的，后面我们可以据此统计成功率，method 是 HTTP 方法，GET、POST、PUT、DELETE 等，比如新增用户和获取用户列表可能都是 /api/n9e/users，从路径上无法区分，只能再加上 method 才能区分开。\npath 着重说一下，表示请求路径，比如上面提到的/api/n9e/users，但是，在 restful 实践中，url 中经常会有参数，比如获取编号为1的用户的信息，接口是/api/n9e/user/1，获取编号为2的用户信息，接口是/api/n9e/user/2，如果这俩带有用户编号的 url 都作为 Label，会造成时序库索引爆炸，而且从业务方使用角度来看，我们也不关注编号为1的用户获取请求还是编号为2的用户获取请求，而是关注整体的GET /api/n9e/user/:id这个接口的监控数据。所以我们在设置 Label 的时候，要把path设置为/api/n9e/user/:id，而不是那具体的带有用户编号的 url 路径。夜莺用的 gin 框架，gin 框架有个 FullPath 方法就是获取这个信息的，比较方便。\n首先，我们在 Webapi 下面创建一个 stat package，放置相关统计变量：\npackage stat import ( \u0026quot;time\u0026quot; \u0026quot;github.com/prometheus/client_golang/prometheus\u0026quot; ) const Service = \u0026quot;n9e-webapi\u0026quot; var ( labels = []string{\u0026quot;service\u0026quot;, \u0026quot;code\u0026quot;, \u0026quot;path\u0026quot;, \u0026quot;method\u0026quot;} uptime = prometheus.NewCounterVec( prometheus.CounterOpts{ Name: \u0026quot;uptime\u0026quot;, Help: \u0026quot;HTTP service uptime.\u0026quot;, }, []string{\u0026quot;service\u0026quot;}, ) RequestCounter = prometheus.NewCounterVec( prometheus.CounterOpts{ Name: \u0026quot;http_request_count_total\u0026quot;, Help: \u0026quot;Total number of HTTP requests made.\u0026quot;, }, labels, ) RequestDuration = prometheus.NewHistogramVec( prometheus.HistogramOpts{ Buckets: []float64{.01, .1, 1, 10}, Name: \u0026quot;http_request_duration_seconds\u0026quot;, Help: \u0026quot;HTTP request latencies in seconds.\u0026quot;, }, labels, ) ) func Init() { // Register the summary and the histogram with Prometheus's default registry. prometheus.MustRegister( uptime, RequestCounter, RequestDuration, ) go recordUptime() } // recordUptime increases service uptime per second. func recordUptime() { for range time.Tick(time.Second) { uptime.WithLabelValues(Service).Inc() } }  uptime 变量是顺手为之，统计进程启动了多久时间，不用太关注，RequestCounter 和 RequestDuration，分别统计请求流量和请求延迟。Init 方法是在 Webapi 模块进程初始化的时候调用，所以进程一起，就会自动注册好。\n然后我们写一个 middleware，在请求进来的时候拦截一下，省的每个请求都要去统计，middleware 方法的代码如下：\nimport ( ... promstat \u0026quot;github.com/didi/nightingale/v5/src/webapi/stat\u0026quot; ) func stat() gin.HandlerFunc { return func(c *gin.Context) { start := time.Now() c.Next() code := fmt.Sprintf(\u0026quot;%d\u0026quot;, c.Writer.Status()) method := c.Request.Method labels := []string{promstat.Service, code, c.FullPath(), method} promstat.RequestCounter.WithLabelValues(labels...).Inc() promstat.RequestDuration.WithLabelValues(labels...).Observe(float64(time.Since(start).Seconds())) } }  有了这个 middleware 之后，new 出 gin 的 engine 的时候，就立马 Use 一下，代码如下：\n... r := gin.New() r.Use(stat()) ...  最后，监控数据要通过/metrics接口暴露出去，我们要暴露这个请求端点，代码如下：\nimport ( ... \u0026quot;github.com/prometheus/client_golang/prometheus/promhttp\u0026quot; ) func configRoute(r *gin.Engine, version string) { ... r.GET(\u0026quot;/metrics\u0026quot;, gin.WrapH(promhttp.Handler())) }  如上，每个 Webapi 的接口的流量和成功率都可以监控到了。如果你也部署了夜莺，请求 Webapi 的端口（默认是18000）的 /metrics 接口看看吧。\n💡  如果服务部署多个实例，甚至多个 region，多个环境，上面的 4 个 Label 就不够用了，因为只有这 4 个 Label 不足以唯一标识一个具体的实例，此时需要 env、region、instance 这种 Label，这些 Label不 需要在代码里埋点，在采集的时候一般可以附加额外的标签，通过附加标签的方式来处理即可   Server # Server 模块的监控，和 Webapi 模块的监控差异较大，因为关注点不同，Webapi 关注的是 HTTP 接口的请求量和延迟，而 Server 模块关注的是接收了多少监控指标，内部事件队列的长度，从数据库同步告警规则花费多久，同步了多少条数据等，所以，我们也需要在 Server 的 package 下创建一个 stat 包，stat 包下放置 stat.go，内容如下：\npackage stat import ( \u0026quot;github.com/prometheus/client_golang/prometheus\u0026quot; ) const ( namespace = \u0026quot;n9e\u0026quot; subsystem = \u0026quot;server\u0026quot; ) var ( // 各个周期性任务的执行耗时 GaugeCronDuration = prometheus.NewGaugeVec(prometheus.GaugeOpts{ Namespace: namespace, Subsystem: subsystem, Name: \u0026quot;cron_duration\u0026quot;, Help: \u0026quot;Cron method use duration, unit: ms.\u0026quot;, }, []string{\u0026quot;cluster\u0026quot;, \u0026quot;name\u0026quot;}) // 从数据库同步数据的时候，同步的条数 GaugeSyncNumber = prometheus.NewGaugeVec(prometheus.GaugeOpts{ Namespace: namespace, Subsystem: subsystem, Name: \u0026quot;cron_sync_number\u0026quot;, Help: \u0026quot;Cron sync number.\u0026quot;, }, []string{\u0026quot;cluster\u0026quot;, \u0026quot;name\u0026quot;}) // 从各个接收接口接收到的监控数据总量 CounterSampleTotal = prometheus.NewCounterVec(prometheus.CounterOpts{ Namespace: namespace, Subsystem: subsystem, Name: \u0026quot;samples_received_total\u0026quot;, Help: \u0026quot;Total number samples received.\u0026quot;, }, []string{\u0026quot;cluster\u0026quot;, \u0026quot;channel\u0026quot;}) // 产生的告警总量 CounterAlertsTotal = prometheus.NewCounterVec(prometheus.CounterOpts{ Namespace: namespace, Subsystem: subsystem, Name: \u0026quot;alerts_total\u0026quot;, Help: \u0026quot;Total number alert events.\u0026quot;, }, []string{\u0026quot;cluster\u0026quot;}) // 内存中的告警事件队列的长度 GaugeAlertQueueSize = prometheus.NewGaugeVec(prometheus.GaugeOpts{ Namespace: namespace, Subsystem: subsystem, Name: \u0026quot;alert_queue_size\u0026quot;, Help: \u0026quot;The size of alert queue.\u0026quot;, }, []string{\u0026quot;cluster\u0026quot;}) ) func Init() { // Register the summary and the histogram with Prometheus's default registry. prometheus.MustRegister( GaugeCronDuration, GaugeSyncNumber, CounterSampleTotal, CounterAlertsTotal, GaugeAlertQueueSize, ) }  定义一个监控指标，除了 name 之外，还可以设置 namespace、subsystem，最终通过 /metrics 接口暴露的时候，可以发现：监控指标的最终名字，就是$namespace_$subsystem_$name，三者拼接在一起。Webapi 模块的监控代码中我们看到了 counter 类型和 histogram 类型的处理，这次我们拿 GaugeAlertQueueSize 举例，这是个 GAUGE 类型的统计数据，起一个 goroutine 周期性获取队列长度，然后 Set 到 GaugeAlertQueueSize 中：\npackage engine import ( \u0026quot;context\u0026quot; \u0026quot;time\u0026quot; \u0026quot;github.com/didi/nightingale/v5/src/server/config\u0026quot; promstat \u0026quot;github.com/didi/nightingale/v5/src/server/stat\u0026quot; ) func Start(ctx context.Context) error { ... go reportQueueSize() return nil } func reportQueueSize() { for { time.Sleep(time.Second) promstat.GaugeAlertQueueSize.WithLabelValues(config.C.ClusterName).Set(float64(EventQueue.Len())) } }  另外，Init 方法要在 Server 模块初始化的时候调用，Server 的 router.go 中要暴露 /metrics 端点路径，这些就不再详述了，大家可以扒拉一下夜莺的代码看一下。\n数据抓取 # 应用自身的监控数据已经通过 /metrics 接口暴露了，后续采集规则可以在 prometheus.yml 中配置，prometheus.yml 中有个 section 叫：scrape_configs 可以配置抓取目标，这是 Prometheus 范畴的知识了，大家可以参考Prometheus官网。\n或者，大家也可以使用 Categraf 的 prometheus 插件抓取 /metrics 数据，就是把 url 配置进去即可，比较容易。\n参考资料 #  https://prometheus.io/docs/instrumenting/clientlibs/ https://github.com/prometheus/client_golang/tree/master/examples  "}),e.add({id:15,href:"/docs/usage/mtail/",title:"日志监控",description:"夜莺（ Nightingale ）通过 mtail 监控日志",content:"前言 # 说到日志监控，大家第一反应的可能是ELK的方案，或者Loki的方案，这两个方案都是把日志采集了发到中心，在中心存储、查看、分析，不过这个方案相对比较重量级一些，如果我们的需求只是从日志中提取一些metrics数据，比如统计一些日志中出现的Error次数之类的，则有一个更简单的方案。\n这里给大家介绍一个Google出品的小工具，mtail，mtail就是流式读取日志，通过正则表达式匹配的方式从日志中提取metrics指标，这种方式可以利用目标机器的算力，不过如果量太大，可能会影响目标机器上的业务程序，另外一个好处是无侵入性，不需要业务埋点，如果业务程序是第三方供应商提供的，我们改不了其代码，mtail此时就非常合适了。当然了，如果业务程序是我们公司的人自己写的，那还是建议用埋点的方式采集指标，mtail只是作为一个补充吧。\nmtail简介 # mtail的使用方案，参考如下两个文档（下载的话参考Releases页面）：\n Deploying Programming Guide  我们拿mtail的启动命令来举例其用法：\nmtail --progs /etc/mtail --logs /var/log/syslog --logs /var/log/ntp/peerstats  通过 --progs 参数指定一个目录，这个目录里放置一堆的*.mtail文件，每个mtail文件就是描述的正则提取规则，通过 --logs 参数来指定要监控的日志目录，可以写通配符，--logs 可以写多次，上例中只是指定了 --progs 和 --logs ，没有其他参数，mtail启动之后会自动监听一个端口3903，在3903的/metrics接口暴露符合Prometheus协议的监控数据，Prometheus 或者 Categraf 或者 Telegraf 等就可以从 /metrics 接口提取监控数据。\n这样看起来，原理就很清晰了，mtail 启动之后，根据 --logs 找到相关日志文件，seek 到文件末尾，开始流式读取，每读到一行，就根据 --progs 指定的那些规则文件做匹配，看是否符合某些正则，从中提取时序数据，然后通过3903的/metrics暴露采集到的监控指标。当然，除了Prometheus这种/metrics方式暴露，mtail 还支持把监控数据直接推给 graphite 或者 statsd，具体可以参考：这里\nmtail样例 # 这里我用mtail监控一下n9e-server的日志，从中提取一下各个告警规则触发的 notify 的数量，这个日志举例：\n2021-12-27 10:00:30.537582 INFO engine/logger.go:19 event(cbb8d4be5efd07983c296aaa4dec5737 triggered) notify: rule_id=9 [__name__=net_response_result_code author=qin ident=10-255-0-34 port=4567 protocol=tcp server=localhost]2@1640570430  很明显，日志中有这么个关键字：notify: rule_id=9，可以用正则来匹配，统计出现的行数，ruleid 也可以从中提取到，这样，我们可以把 ruleid 作为标签上报，于是乎，我们就可以写出这样的 mtail 规则了：\n[root@10-255-0-34 nightingale]# cat /etc/mtail/n9e-server.mtail counter mtail_alert_rule_notify_total by ruleid /notify: rule_id=(?P\u0026lt;ruleid\u0026gt;\\d+)/ { mtail_alert_rule_notify_total[$ruleid]++ }  然后启动也比较简单，我这里就用 nohup 简单来做：\nnohup mtail -logtostderr --progs /etc/mtail --logs server.log \u0026amp;\u0026gt; stdout.log \u0026amp;  mtail 没有指定绝对路径，是因为我把 mtail 的二进制直接放在了 /usr/bin 下面了，mtail 默认会监听在 3903，所以我们可以用如下命令验证：\ncurl -s localhost:3903/metrics # output: # HELP mtail_alert_rule_notify_total defined at n9e-server.mtail:1:9-37 # TYPE mtail_alert_rule_notify_total counter mtail_alert_rule_notify_total{prog=\u0026quot;n9e-server.mtail\u0026quot;,ruleid=\u0026quot;9\u0026quot;} 6  上面的输出只是挑选了部分内容，没有全部贴出，这就表示正常采集到了，如果 n9e 的 server.log 中当前没有打印 notify 相关的日志，那请求/metrics接口是没法得到上面的输出的，可以手工配置一条必然会触发的规则，待日志里有相关输出的时候再次请求 /metrics 接口，应该就有了。\n最后我们在 Categraf （或者 Telegraf） 中配置一下抓取规则，抓取本机的 http://localhost:3903/metrics 即可，然后重启 Categraf，等一会就可以在页面查到相关指标了。\n另外，mtail 的配置文件如果发生变化，是需要重启 mtail 才能生效的，或者发一个 SIGHUP 信号给 mtail，mtail 收到信号就会重新加载配置。\nmtail更多样例 # mtail 的 github repo 中有一个 examples，里边有挺多例子，大家可以参考。我在这里再给大家举一个简单例子，比如我们要统计 /var/log/messages 文件中的 Out of memory 关键字，mtail 规则应该怎么写呢？其实比上面举例的 mtail_alert_rule_notify_total 还要更简单：\ncounter mtail_oom_total /Out of memory/ { mtail_oom_total++ }  关于时间戳 # 最后说一下时间戳的问题，日志中每一行一般都是有个时间戳的，夜莺v4版本在页面上配置采集规则的时候，就是要选择时间戳的，但是 mtail，上面的例子中没有处理时间戳，为啥？其实 mtail 也可以支持从日志中提取时间戳，如果没有配置的话，就用系统当前时间，个人认为，用系统当前时间就可以了，从日志中提取时间稍微还有点麻烦，当然，系统当前时间和日志中的时间可能稍微有差别，但是不会差很多的，可以接受，examples 中的 mtail 样例，也基本都没有给出时间戳的提取。\n"}),e.add({id:16,href:"/docs/api/read/",title:"数据读取",description:"读取夜莺Nightingale的监控数据",content:"夜莺把接收到的监控数据都直接写入了后端时序数据库，所以，读取监控数据，无需经由夜莺的接口，直接读取后端的时序库的接口就可以了。即：如果使用了 Prometheus，就通过 Prometheus 的接口读取监控数据，如果用了 VictoriaMetrics，就通过 VictoriaMetrics 的接口读取监控数据。\n比如 Prometheus，就是那些/api/v1/query /api/v1/query_range之类的接口。相关接口文档请参考：Prometheus官网\n"}),e.add({id:17,href:"/docs/api/push/",title:"数据推送",description:"如何把自定义监控数据推送给夜莺Nightingale",content:"在 采集器 章节可以看出，夜莺支持多种数据接收的接口（由 n9e-server 实现，推送数据就是推给 n9e-server 的 19000 端口），包括 OpenTSDB、Open-Falcon、RemoteWrite、Datadog 等协议。这节我们以 OpenTSDB 的数据接收接口举例。\nOpenTSDB 的数据接收接口的 Url Path 是 /opentsdb/put ，POST 方法，监控数据做成 JSON 放到 HTTP Request Body 中，举例：\n[ { \u0026quot;metric\u0026quot;: \u0026quot;cpu_usage_idle\u0026quot;, \u0026quot;timestamp\u0026quot;: 1637732157, \u0026quot;tags\u0026quot;: { \u0026quot;cpu\u0026quot;: \u0026quot;cpu-total\u0026quot;, \u0026quot;ident\u0026quot;: \u0026quot;c3-ceph01.bj\u0026quot; }, \u0026quot;value\u0026quot;: 30.5 }, { \u0026quot;metric\u0026quot;: \u0026quot;cpu_usage_util\u0026quot;, \u0026quot;timestamp\u0026quot;: 1637732157, \u0026quot;tags\u0026quot;: { \u0026quot;cpu\u0026quot;: \u0026quot;cpu-total\u0026quot;, \u0026quot;ident\u0026quot;: \u0026quot;c3-ceph01.bj\u0026quot; }, \u0026quot;value\u0026quot;: 69.5 } ]  显然，JSON 最外层是个数组，如果只上报一条监控数据，也可以不要外面的中括号，直接把对象结构上报：\n{ \u0026quot;metric\u0026quot;: \u0026quot;cpu_usage_idle\u0026quot;, \u0026quot;timestamp\u0026quot;: 1637732157, \u0026quot;tags\u0026quot;: { \u0026quot;cpu\u0026quot;: \u0026quot;cpu-total\u0026quot;, \u0026quot;ident\u0026quot;: \u0026quot;c3-ceph01.bj\u0026quot; }, \u0026quot;value\u0026quot;: 30.5 }  服务端会看第一个字符是否是[，来判断上报的是数组，还是单个对象，自动做相应的 Decode。如果觉得上报的内容太过占用带宽，也可以做 gzip 压缩，此时上报的数据，要带有Content-Encoding: gzip的 Header。\n💡  注意 ident 这个标签，ident 是 identity 的缩写，表示设备的唯一标识，如果标签中有 ident 标签，n9e-server 就认为这个监控数据是来自某个机器的，会自动获取 ident 的 value，注册到监控对象的列表里   "}),e.add({id:18,href:"/docs/api/webapi/",title:"Webapi接口",description:"调用夜莺Nightingale的Webapi接口",content:"简介 # n9e-webapi 模块提供了两类接口，一个是 /api/n9e 打头的，给前端调用，另一类是 /v1/n9e 打头的，给第三方系统调用。如果想以个人身份模仿WEB操作，也是调用 /api/n9e 相关接口。\n以个人身份模仿WEB操作 # 这种方式，页面上 JavaScript 可以调用的所有接口，你都可以用程序调用，打开 chrome 的开发者工具，扒拉这些接口，还是非常容易的。当然，要先登录，登录调用 webapi 模块的 /api/n9e/auth/login 接口，系统使用 jwt 认证，如果登录成功，会返回 access_token 和 refresh_token，每次调用的时候都要把 access_token 放到 Header 里，access_token 差不多15分钟过期，之后可以重新调用登录接口换 token，也可以调用 /api/n9e/auth/refresh 接口用 refresh_token 换一个新的 access_token，当然，也会顺道返回一个新的 refresh_token，举例：\n# 调用登录接口拿到access_token和refresh_token记录下来，后面调用其他接口的时候会用到 [root@10-255-0-34 ~]# curl -X POST 'http://localhost:18000/api/n9e/auth/login' -d '{\u0026quot;username\u0026quot;: \u0026quot;root\u0026quot;, \u0026quot;password\u0026quot;: \u0026quot;root.2020\u0026quot;}' {\u0026quot;dat\u0026quot;:{\u0026quot;access_token\u0026quot;:\u0026quot;eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhY2Nlc3NfdXVpZCI6ImIxNTcyMjgwLWZlNzAtNDhjZi1hNDQ3LWVlMjVhZmYwMjRhZCIsImF1dGhvcml6ZWQiOnRydWUsImV4cCI6MTYzNzgyMzA1OSwidXNlcl9pZGVudGl0eSI6IjEtcm9vdCJ9.nJ56Pc7qS5Ik_UaVmlNWu_QlABaBc4pZ_WkU45u2wWk\u0026quot;,\u0026quot;refresh_token\u0026quot;:\u0026quot;eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJleHAiOjE2MzgzMzc4NTksInJlZnJlc2hfdXVpZCI6ImIxNTcyMjgwLWZlNzAtNDhjZi1hNDQ3LWVlMjVhZmYwMjRhZCsrMS1yb290IiwidXNlcl9pZGVudGl0eSI6IjEtcm9vdCJ9.JKsbfTYBCOOfR_oPsf496N9ml9yXbP7BHb4E8Yfnzbo\u0026quot;,\u0026quot;user\u0026quot;:{\u0026quot;id\u0026quot;:1,\u0026quot;username\u0026quot;:\u0026quot;root\u0026quot;,\u0026quot;nickname\u0026quot;:\u0026quot;超管\u0026quot;,\u0026quot;phone\u0026quot;:\u0026quot;\u0026quot;,\u0026quot;email\u0026quot;:\u0026quot;\u0026quot;,\u0026quot;portrait\u0026quot;:\u0026quot;\u0026quot;,\u0026quot;roles\u0026quot;:[\u0026quot;Admin\u0026quot;],\u0026quot;contacts\u0026quot;:{},\u0026quot;create_at\u0026quot;:1637545881,\u0026quot;create_by\u0026quot;:\u0026quot;system\u0026quot;,\u0026quot;update_at\u0026quot;:1637546351,\u0026quot;update_by\u0026quot;:\u0026quot;root\u0026quot;,\u0026quot;admin\u0026quot;:true}},\u0026quot;err\u0026quot;:\u0026quot;\u0026quot;} # access_token放到Authorization这个Header里，Bearer的验证方式 [root@10-255-0-34 ~]# curl -H \u0026quot;Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhY2Nlc3NfdXVpZCI6ImIxNTcyMjgwLWZlNzAtNDhjZi1hNDQ3LWVlMjVhZmYwMjRhZCIsImF1dGhvcml6ZWQiOnRydWUsImV4cCI6MTYzNzgyMzA1OSwidXNlcl9pZGVudGl0eSI6IjEtcm9vdCJ9.nJ56Pc7qS5Ik_UaVmlNWu_QlABaBc4pZ_WkU45u2wWk\u0026quot; 'http://localhost:18000/api/n9e/self/profile' {\u0026quot;dat\u0026quot;:{\u0026quot;id\u0026quot;:1,\u0026quot;username\u0026quot;:\u0026quot;root\u0026quot;,\u0026quot;nickname\u0026quot;:\u0026quot;超管\u0026quot;,\u0026quot;phone\u0026quot;:\u0026quot;\u0026quot;,\u0026quot;email\u0026quot;:\u0026quot;\u0026quot;,\u0026quot;portrait\u0026quot;:\u0026quot;\u0026quot;,\u0026quot;roles\u0026quot;:[\u0026quot;Admin\u0026quot;],\u0026quot;contacts\u0026quot;:{},\u0026quot;create_at\u0026quot;:1637545881,\u0026quot;create_by\u0026quot;:\u0026quot;system\u0026quot;,\u0026quot;update_at\u0026quot;:1637546351,\u0026quot;update_by\u0026quot;:\u0026quot;root\u0026quot;,\u0026quot;admin\u0026quot;:true},\u0026quot;err\u0026quot;:\u0026quot;\u0026quot;} # 如果token过期了，后端会返回异常HTTP状态码，此时要调用refresh接口换取新的token [root@10-255-0-34 ~]# curl -X POST 'http://localhost:18000/api/n9e/auth/refresh' -d '{\u0026quot;refresh_token\u0026quot;: \u0026quot;eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJleHAiOjE2MzgzMzc4NTksInJlZnJlc2hfdXVpZCI6ImIxNTcyMjgwLWZlNzAtNDhjZi1hNDQ3LWVlMjVhZmYwMjRhZCsrMS1yb290IiwidXNlcl9pZGVudGl0eSI6IjEtcm9vdCJ9.JKsbfTYBCOOfR_oPsf496N9ml9yXbP7BHb4E8Yfnzbo\u0026quot;}' {\u0026quot;dat\u0026quot;:{\u0026quot;access_token\u0026quot;:\u0026quot;eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhY2Nlc3NfdXVpZCI6IjAxMzkzYzkxLTk5MWItNGE0Yi04ODk2LTJhZGRjMDUwYjcxMCIsImF1dGhvcml6ZWQiOnRydWUsImV4cCI6MTYzNzgyMzMxOCwidXNlcl9pZGVudGl0eSI6IjEtcm9vdCJ9.2BeWyYfcnRi3qw69zecaaeFnPFUNAGsiPIZBBnd5lug\u0026quot;,\u0026quot;refresh_token\u0026quot;:\u0026quot;eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJleHAiOjE2MzgzMzgxMTgsInJlZnJlc2hfdXVpZCI6IjAxMzkzYzkxLTk5MWItNGE0Yi04ODk2LTJhZGRjMDUwYjcxMCsrMS1yb290IiwidXNlcl9pZGVudGl0eSI6IjEtcm9vdCJ9.zFZaRYcJI6G5maSgDVF-jZzxQ3Tb5dybIqufJhBy034\u0026quot;},\u0026quot;err\u0026quot;:\u0026quot;\u0026quot;}  第三方系统调用夜莺 # 比如第三方系统想获取夜莺中的所有未恢复告警，或者获取夜莺中的全量用户列表，这些需求，建议走 /v1/n9e 打头的接口，这些接口走 BasicAuth 认证，BasicAuth 的用户名和密码在 webapi.conf 中可以找到，就是 BasicAuth 那个 section 的配置。当前这个阶段，/v1/n9e 前缀的接口还比较少，不过代码框架已经搭起来了，代码在 src/webapi/router/router.go 文件中，如果贵司要封装夜莺的接口，可能要在这个路由分组下加一些路由配置了，欢迎大家 PR。\n"}),e.add({id:19,href:"/docs/api/",title:"API",description:"夜莺 Nightingale API 手册",content:""}),e.add({id:20,href:"/docs/usage/",title:"使用手册",description:"夜莺 Nightingale 使用手册",content:""}),e.add({id:21,href:"/docs/agent/",title:"采集器",description:"监控数据采集器，Categraf、Telegraf、Grafana-Agent、Datadog-Agent等",content:""}),e.add({id:22,href:"/docs/install/",title:"安装部署",description:"夜莺安装部署",content:""}),e.add({id:23,href:"/docs/prologue/",title:"简介",description:"夜莺介绍",content:""}),e.add({id:24,href:"/docs/",title:"Nightingale",description:"Nightingale is a cloud native monitoring system",content:""}),search.addEventListener("input",t,!0);function t(){const s=5;var n=this.value,o=e.search(n,{limit:s,enrich:!0});const t=new Map;for(const e of o.flatMap(e=>e.result)){if(t.has(e.doc.href))continue;t.set(e.doc.href,e.doc)}if(suggestions.innerHTML="",suggestions.classList.remove("d-none"),t.size===0&&n){const e=document.createElement("div");e.innerHTML=`No results for "<strong>${n}</strong>"`,e.classList.add("suggestion__no-results"),suggestions.appendChild(e);return}for(const[r,a]of t){const n=document.createElement("div");suggestions.appendChild(n);const e=document.createElement("a");e.href=r,n.appendChild(e);const o=document.createElement("span");o.textContent=a.title,o.classList.add("suggestion__title"),e.appendChild(o);const i=document.createElement("span");if(i.textContent=a.description,i.classList.add("suggestion__description"),e.appendChild(i),suggestions.appendChild(n),suggestions.childElementCount==s)break}}})()