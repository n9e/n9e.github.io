var suggestions=document.getElementById("suggestions"),search=document.getElementById("search");search!==null&&document.addEventListener("keydown",inputFocus);function inputFocus(e){e.ctrlKey&&e.key==="/"&&(e.preventDefault(),search.focus()),e.key==="Escape"&&(search.blur(),suggestions.classList.add("d-none"))}document.addEventListener("click",function(e){var t=suggestions.contains(e.target);t||suggestions.classList.add("d-none")}),document.addEventListener("keydown",suggestionFocus);function suggestionFocus(n){const s=suggestions.classList.contains("d-none");if(s)return;const e=[...suggestions.querySelectorAll("a")];if(e.length===0)return;const t=e.indexOf(document.activeElement);if(n.key==="ArrowUp"){n.preventDefault();const s=t>0?t-1:0;e[s].focus()}else if(n.key==="ArrowDown"){n.preventDefault();const s=t+1<e.length?t+1:t;e[s].focus()}}(function(){var e=new FlexSearch.Document({tokenize:"forward",cache:100,document:{id:"id",store:["href","title","description"],index:["title","description","content"]}});e.add({id:0,href:"/docs/prologue/introduction/",title:"夜莺介绍",description:"夜莺（ Nightingale ）是一款国产开源、云原生监控系统",content:"项目代码 #  后端：💡 https://github.com/ccfos/nightingale 前端：💡 https://github.com/n9e/fe-v5  欢迎大家在Github上关注夜莺项目，及时获取项目更新动态，有任何问题，也欢迎提交 Issue，以及提交 PR，开源社区，需要大家一起参与才能有蓬勃的生命力。\n产品介绍 # 💡下载夜莺功能介绍材料（可用于你在团队内部分享/推广夜莺监控），点击以下链接下载：\n PDF版本  Nightingale 可以接收各种采集器上报的监控数据，转存到时序库（可以支持Prometheus、M3DB、VictoriaMetrics、Thanos等），并提供告警规则、屏蔽规则、订阅规则的配置能力，提供监控数据的查看能力，提供告警自愈机制（告警触发之后自动回调某个webhook地址或者执行某个脚本），提供历史告警事件的存储管理、分组查看的能力。\n系统截图 # 系统架构 # 夜莺 v5 的设计非常简单，核心是 server 和 webapi 两个模块，webapi 无状态，放到中心端，承接前端请求，将用户配置写入数据库；server 是告警引擎和数据转发模块，一般随着时序库走，一个时序库就对应一套 server，每套 server 可以只用一个实例，也可以多个实例组成集群，server 可以接收 Categraf、Telegraf、Grafana-Agent、Datadog-Agent、Falcon-Plugins 上报的数据，写入后端时序库，周期性从数据库同步告警规则，然后查询时序库做告警判断。每套 server 依赖一个 redis。\n产品对比 # Zabbix # Zabbix 是一款老牌的监控系统，对机器和网络设备的监控覆盖很全，比如支持 AIX 系统，常见的开源监控都是支持 Linux、Windows，AIX 较少能够支持，Zabbix 用户群体广泛，国内很多公司基于 Zabbix 做商业化服务，不过 Zabbix 使用数据库做存储，容量有限，今年推出的 TimescaleDB 对容量有较大提升，大家可以尝试下；其次 Zabbix 整个产品设计是面向静态资产的，在云原生场景下显得力不从心。\nOpen-Falcon # 因为开发 Open-Falcon 和 Nightingale 的是一拨人，所以很多社区伙伴会比较好奇，为何要新做一个监控开源软件。核心点是 Open-Falcon 和 Nightingale 的差异点实在是太大了，Nightingale 并非是 Open-Falcon 设计逻辑的一个延续，就看做两个不同的软件就好。\nOpen-Falcon 是 14 年开发的，当时是想解决 Zabbix 的一些容量问题，可以看做是物理机时代的产物，整个设计偏向运维视角，虽然数据结构上已经开始设计了标签，但是查询语法还是比较简单，无法应对比较复杂的场景。\nNightingale 直接支持 PromQL，支持 Prometheus、M3DB、VictoriaMetrics 多种时序库，支持 Categraf、Telegraf、Datadog-Agent、Grafana-Agent 做监控数据采集，支持 Grafana 看图，整个设计更加云原生。\nPrometheus # Nightingale 可以简单看做是 Prometheus 的一个企业级版本，把 Prometheus 当做 Nightingale 的一个内部组件（时序库），当然，也不是必须的，时序库除了 Prometheus，还可以使用 VictoriaMetrics、M3DB 等，各种 Exporter 采集器也可以继续使用。\nNightingale 可以接入多个 Prometheus，可以允许用户在页面上配置告警规则、屏蔽规则、订阅规则，在页面上查看告警事件、做告警事件聚合统计，配置告警自愈机制，管理监控对象，配置监控大盘等，就把 Nightingale 看做是 Prometheus 的一个 WEBUI 也是可以的，不过实际上，它远远不止是一个 WEBUI，用一下就会深有感触。\n加入社区 # 公众号有加入交流群的方式、答疑方式，也会定期分享夜莺知识、云原生监控知识，欢迎关注。\n"}),e.add({id:1,href:"/docs/appendix/grafana-agent/",title:"Grafana-agent",description:"使用Grafana-agent采集数据",content:""}),e.add({id:2,href:"/docs/appendix/",title:"附录",description:"参考资料",content:""}),e.add({id:3,href:"/docs/install/first/",title:"开始之前",description:"安装夜莺之前必读的内容",content:"各种环境的选型建议：\n 快速体验测试，使用 Docker compose 方式 公司大规模使用了 Kubernetes，可以选中 Helm 方式 最稳定的部署方式，还是二进制 小规模使用，比如 1000 台机器以下，用 Prometheus 做存储即可，超过 1000 台机器，选择 VictoriaMetrics 可能更合适  后面章节会讲解各种方式如何部署，也可参考下面的两篇文章，里边有视频演示：\n 【连载】说透运维监控系统-2.1安装夜莺监控系统 【连载】说透运维监控系统-2.2监控系统典型架构以及夜莺分布式部署方案  "}),e.add({id:4,href:"/docs/install/compose/",title:"Docker Compose",description:"使用Docker compose一键启动夜莺，快速尝试",content:"使用Docker Compose一键启动夜莺，快速尝试。更多Docker Compose相关知识请参考Docker官网 操作演示\n$ git clone https://gitlink.org.cn/ccfos/nightingale.git $ cd nightingale/docker # docker compose V2版本执行 docker compose up -d (https://docs.docker.com/compose/#compose-v2-and-the-new-docker-compose-command) $ docker-compose up -d Creating network \u0026quot;docker_nightingale\u0026quot; with driver \u0026quot;bridge\u0026quot; Creating mysql ... done Creating redis ... done Creating prometheus ... done Creating ibex ... done Creating agentd ... done Creating nwebapi ... done Creating nserver ... done Creating telegraf ... done # docker compose V2版本执行 docker compose ps (https://docs.docker.com/compose/#compose-v2-and-the-new-docker-compose-command) $ docker-compose ps Name Command State Ports ---------------------------------------------------------------------------------------------------------------------------- agentd /app/ibex agentd Up 10090/tcp, 20090/tcp ibex /app/ibex server Up 0.0.0.0:10090-\u0026gt;10090/tcp, 0.0.0.0:20090-\u0026gt;20090/tcp mysql docker-entrypoint.sh mysqld Up 0.0.0.0:3306-\u0026gt;3306/tcp, 33060/tcp nserver /app/n9e server Up 18000/tcp, 0.0.0.0:19000-\u0026gt;19000/tcp nwebapi /app/n9e webapi Up 0.0.0.0:18000-\u0026gt;18000/tcp, 19000/tcp prometheus /bin/prometheus --config.f ... Up 0.0.0.0:9090-\u0026gt;9090/tcp redis docker-entrypoint.sh redis ... Up 0.0.0.0:6379-\u0026gt;6379/tcp telegraf /entrypoint.sh telegraf Up 0.0.0.0:8092-\u0026gt;8092/udp, 0.0.0.0:8094-\u0026gt;8094/tcp, 0.0.0.0:8125-\u0026gt;8125/udp  💡  启动成功之后，建议把 initsql 目录下的内容挪走，这样下次重启的时候，DB 就不会重新初始化了。否则下次启动 mysql 还是会自动执行 initsql 下面的 sql 文件导致 DB 重新初始化，页面上创建的规则、大盘等都会丢失。Docker Compose 这种部署方式，只是用于简单测试，不推荐在生产环境使用，当然了，如果您是 Docker Compose 专家，另当别论   服务启动之后，浏览器访问nwebapi的端口，即18000，默认用户是root，密码是root.2020\n"}),e.add({id:5,href:"/docs/install/helm/",title:"Helm",description:"夜莺（Nightingale）Helm chart",content:"Helm chart 由快猫团队维护，地址：https://github.com/flashcatcloud/n9e-helm 夜莺系统的默认用户是root，密码是root.2020\n"}),e.add({id:6,href:"/docs/install/server/",title:"服务端组件部署",description:"夜莺（Nightingale）服务端相关模块的安装",content:"首先我们来看下面的架构图，夜莺的服务端有两个模块：n9e-webapi 和 n9e-server，n9e-webapi 用于提供 API 给前端 JavaScript 使用，n9e-server 的职责是告警引擎和数据转发器。依赖的组件有 MySQL、Redis、时序库，时序库我们这里使用 Prometheus。\n组件安装 # mysql、redis、prometheus，这三个组件都是开源软件，请大家自行安装，其中 prometheus 在启动的时候要注意开启 --enable-feature=remote-write-receiver ，如果之前贵司已经有 Prometheus 了，也可以直接使用，无需再次部署。这里也提供一个小脚本来安装这3个组件，大家可以参考：\n# install prometheus mkdir -p /opt/prometheus wget https://s3-gz01.didistatic.com/n9e-pub/prome/prometheus-2.28.0.linux-amd64.tar.gz -O prometheus-2.28.0.linux-amd64.tar.gz tar xf prometheus-2.28.0.linux-amd64.tar.gz cp -far prometheus-2.28.0.linux-amd64/* /opt/prometheus/ # service cat \u0026lt;\u0026lt;EOF \u0026gt;/etc/systemd/system/prometheus.service [Unit] Description=\u0026quot;prometheus\u0026quot; Documentation=https://prometheus.io/ After=network.target [Service] Type=simple ExecStart=/opt/prometheus/prometheus --config.file=/opt/prometheus/prometheus.yml --storage.tsdb.path=/opt/prometheus/data --web.enable-lifecycle --enable-feature=remote-write-receiver --query.lookback-delta=2m Restart=on-failure SuccessExitStatus=0 LimitNOFILE=65536 StandardOutput=syslog StandardError=syslog SyslogIdentifier=prometheus [Install] WantedBy=multi-user.target EOF systemctl daemon-reload systemctl enable prometheus systemctl restart prometheus systemctl status prometheus # install mysql yum -y install mariadb* systemctl enable mariadb systemctl restart mariadb mysql -e \u0026quot;SET PASSWORD FOR 'root'@'localhost' = PASSWORD('1234');\u0026quot; # install redis yum install -y redis systemctl enable redis systemctl restart redis  上例中mysql的root密码设置为了1234，建议维持这个不变，后续就省去了修改配置文件的麻烦。\n安装夜莺 # mkdir -p /opt/n9e \u0026amp;\u0026amp; cd /opt/n9e # 去 https://github.com/didi/nightingale/releases 找最新版本的包，文档里的包地址可能已经不是最新的了 tarball=n9e-5.8.0.tar.gz urlpath=https://github.com/didi/nightingale/releases/download/v5.8.0/${tarball} wget $urlpath || exit 1 tar zxvf ${tarball} mysql -uroot -p1234 \u0026lt; docker/initsql/a-n9e.sql nohup ./n9e server \u0026amp;\u0026gt; server.log \u0026amp; nohup ./n9e webapi \u0026amp;\u0026gt; webapi.log \u0026amp; # check logs # check port  如果启动成功，server 默认会监听在 19000 端口，webapi 会监听在 18000 端口，且日志没有报错。上面使用 nohup 简单演示，生产环境建议用 systemd 托管，相关 service 文件可以在 etc/service 目录下，供参考，nohup和systemd的使用教程\n配置文件etc/server.conf和etc/webapi.conf中都含有 mysql 的连接地址配置，检查一下用户名和密码，prometheus 如果使用上面的脚本安装，默认会监听本机 9090 端口，server.conf 和 webapi.conf 中的 prometheus 相关地址都不用修改就是对的，如果使用贵司之前已有的 Prometheus，就要检查这俩配置文件中的时序库的配置了，把 127.0.0.1:9090 改成你的 Prometheus。\n好了，浏览器访问 webapi 的端口（默认是18000）就可以体验相关功能了，默认用户是root，密码是root.2020。如果安装过程出现问题，可以参考公众号的视频教程。\n夜莺服务端部署好了，默认情况下时序库中只有少量 Prometheus 自身的数据，大家可以简单测试。接下来要考虑监控数据采集的问题，如果是 Prometheus 重度用户，可以继续使用各类 Exporter 来采集，只要数据进了时序库了，夜莺就能够消费（判断告警、展示图表等）了。如果是新用户，我们建议使用 Categraf （Gitlink | Github ）来采集，当然，也可以使用 Telegraf、Grafana-agent、Datadog-agent，这些监控采集器都可以和夜莺无缝集成。\n部署集群 # 如果担心容量问题，或高可用问题，可以部署夜莺集群，除了夜莺的两个组件，还有依赖的 MySQL、Redis、时序库，都需要部署集群版。\nMySQL # MySQL 全局就部署一个主从集群就可以了，n9e-webapi、n9e-server都要连到 MySQL 的主库。建议使用公有云提供的 RDS 服务。\nRedis # 夜莺 5.8.0（含）之前的版本，都只支持 standalone 的 Redis，为了高可用，建议使用公有云提供的 Redis 服务。从 5.9.0 开始，夜莺依赖的 Redis 支持 cluster 版本和 sentinel 版本。为了简单起见，全局就使用一套 Redis 即可。如果 n9e-webapi 和 n9e-server 根据地域做了拆分，物理距离较远，比如一个在国内，一个在美东，此时 Redis 就建议拆开，n9e-webapi 依赖一套 Redis，n9e-server 依赖另一套 Redis，如果 n9e-server 有多套，也可以为每套 n9e-server 部署单独的 Redis。\n时序库 # 时序库的高可用，有不同的方案，我们建议使用 VictoriaMetrics 或 Thanos，VictoriaMetrics 如何部署集群版本，后面的章节会有介绍，当然大家也可以查看 VictoriaMetrics 的官方文档，Thanos 的话请大家自行查看 Thanos 的官方文档。\nn9e-webapi # 高可用就是部署多个实例即可，各个n9e-webapi的实例的配置完全相同。前面架设 nginx 或 lvs，某个 n9e-webapi 挂掉了，会被 nginx、lvs 自动摘掉，用户无感\nn9e-server # 首先，n9e-server 是随着时序库走的，贵司有几套时序库，就要部署几套 n9e-server，每套 n9e-server 要取个名字，在 server.conf 中有个 ClusterName 的配置来标识 n9e-server 集群的名字，每套 n9e-server 可以只有一个实例，可以有多个实例组成集群，一套 n9e-server 集群内的多个实例，其 ClusterName 要保持一致。不同的 n9e-server 集群，ClusterName 要不同。\n如果有多套时序库，其连接信息都要配置到 n9e-webapi 的配置文件 webapi.conf 中，即配置多个 [[Clusters]] ，每个 Cluster 有个 Name 的配置，要和 server.conf 中的 ClusterName 保持一致。请注意，你使用的采集器，例如telegraf，需要上报到相应n9e server所在的ip:19000;否则，上报上去的数据将无法区分集群。\n"}),e.add({id:7,href:"/docs/install/victoria/",title:"VictoriaMetrics",description:"使用 VictoriaMetrics 作为夜莺 Nightingale 的时序存储库",content:"简介 # VictoriaMetrics 架构简单，可靠性高，在性能，成本，可扩展性方面表现出色，社区活跃，且和 Prometheus 生态绑定紧密。如果单机版本的 Prometheus 无法在容量上满足贵司的需求，可以使用 VictoriaMetrics 作为时序数据库。\nVictoriaMetrics 提供单机版和集群版。如果您的每秒写入数据点数小于100万（这个数量是个什么概念呢，如果只是做机器设备的监控，每个机器差不多采集200个指标，采集频率是10秒的话每台机器每秒采集20个指标左右，100万/20=5万台机器），VictoriaMetrics 官方默认推荐您使用单机版，单机版可以通过增加服务器的CPU核心数，增加内存，增加IOPS来获得线性的性能提升。且单机版易于配置和运维。\n集群架构 # vmstorage、vminsert、vmselect 三者组合构成 VictoriaMetrics 的集群功能，三者都可以通过启动多个实例来分担承载流量，通过要在 vminsert 和 vmselect 前面架设负载均衡。\nvmstorage 是数据存储模块\n 其数据保存在-storageDataPath指定的目录中，默认为./vmstorage-data/，vmstorage 是有状态模块，删除 storage node 会丢失约 1/N的历史数据（N 为集群中 vmstorage node 的节点数量）。增加 storage node，则需要同步修改 vminsert 和 vmselect 的启动参数，将新加入的storage node节点地址通过命令行参数 -storageNode传入给vminsert和vmselect vmstorage 启动后，会监听三个端口，分别是 -httpListenAddr :8482、-vminsertAddr :8400、-vmselectAddr :8401。端口8400负责接收来自 vminsert 的写入请求，端口8401负责接收来自 vmselect 的数据查询请求，端口8482则是 vmstorage 自身提供的 http api 接口  vminsert 接收来自客户端的数据写入请求，并负责转发到选定的vmstorage\n vminsert 接收到数据写入请求后，按照 jump consistent hash 算法，将数据转发到选定的某个vmstorage node 上。vminsert 本身是无状态模块，可以增加或者删除一个或多个实例，而不会造成数据的损失。vminsert 模块通过启动时的参数 -storageNode xxx,yyy,zzz 来感知到整个 vmstorage 集群的完整 node 地址列表 vminsert 启动后，会监听一个端口-httpListenAddr :8480。该端口实现了 prometheus remote_write协议，因此可以接收和解析通过 remote_write 协议写入的数据。不过要注意，VictoriaMetrics 集群版本具有多租户功能，因此租户ID会以如下形式出现在 API URL 中: http://vminsert:8480/insert/\u0026lt;account_id\u0026gt;/prometheus/api/v1/write 更多 URL Format 可以参考 VictoriaMetrics官网  vmselect 接收来自客户端的数据查询请求，并负责转发到所有的 vmstorage 查询结果，最后将结果 merge 后返回\n vmselect 启动后，会监听一个端口-httpListenAddr :8481。该端口实现了 prometheus query相关的接口。不过要注意，VictoriaMetrics 集群版本具有多租户功能，因此租户ID会以如下形式出现在 API URL 中: http://vminsert:8481/select/\u0026lt;account_id\u0026gt;/prometheus/api/v1/query。 更多 URL Format 可以参考 VictoriaMetrics官网  安装部署 # 1、 去 vm release 下载编译好的二进制版本，比如我们选择下载 v1.69.0 amd64。\n2、 解压缩后得到：\n$ ls -l vm*-prod -rwxr-xr-x 1 work work 10946416 Nov 8 22:03 vminsert-prod* -rwxr-xr-x 1 work work 13000624 Nov 8 22:03 vmselect-prod* -rwxr-xr-x 1 work work 11476736 Nov 8 22:03 vmstorage-prod*  3、 启动三个 vmstorage 实例（可以用下面的脚本快速生成不同实例的启动命令）\n#!/bin/bash for i in `seq 0 2`; do if [ $i -eq 0 ]; then i=\u0026quot;\u0026quot; fi pp=$i httpListenAddr=${pp}8482 vminsertAddr=${pp}8400 vmselectAddr=${pp}8401 storageDataPath=./${pp}vmstorage-data prog=\u0026quot;nohup ./vmstorage-prod -loggerTimezone Asia/Shanghai \\ -storageDataPath $storageDataPath \\ -httpListenAddr :$httpListenAddr \\ -vminsertAddr :$vminsertAddr \\ -vmselectAddr :$vmselectAddr \\ \u0026amp;\u0026gt; ${pp}vmstor.log \u0026amp;\u0026quot; echo $prog (exec \u0026quot;$prog\u0026quot;) done  也可以输入以下命令行启动三个实例：\nnohup ./vmstorage-prod -loggerTimezone Asia/Shanghai -storageDataPath ./vmstorage-data -httpListenAddr :8482 -vminsertAddr :8400 -vmselectAddr :8401 \u0026amp;\u0026gt; vmstor.log \u0026amp; nohup ./vmstorage-prod -loggerTimezone Asia/Shanghai -storageDataPath ./1vmstorage-data -httpListenAddr :18482 -vminsertAddr :18400 -vmselectAddr :18401 \u0026amp;\u0026gt; 1vmstor.log \u0026amp; nohup ./vmstorage-prod -loggerTimezone Asia/Shanghai -storageDataPath ./2vmstorage-data -httpListenAddr :28482 -vminsertAddr :28400 -vmselectAddr :28401 \u0026amp;\u0026gt; 2vmstor.log \u0026amp;  4、 启动一个 vminsert 实例：\nnohup ./vminsert-prod -httpListenAddr :8480 -storageNode=127.0.0.1:8400,127.0.0.1:18400,127.0.0.1:28400 \u0026amp;\u0026gt;vminsert.log \u0026amp;  5、 启动一个 vmselect 实例：\nnohup ./vmselect-prod -httpListenAddr :8481 -storageNode=127.0.0.1:8401,127.0.0.1:18401,127.0.0.1:28401 \u0026amp;\u0026gt;vmselect.log \u0026amp;  6、 查看 vmstorage，vminsert，vmselect 的 /metrics 接口:\ncurl http://127.0.0.1:8482/metrics curl http://127.0.0.1:18482/metrics curl http://127.0.0.1:28482/metrics curl http://127.0.0.1:8481/metrics curl http://127.0.0.1:8480/metrics  7、 n9e-server 通过 remote write 协议写入时序库，VictoriaMetrics 作为时序库的一个选择，其 remote write 接口地址为：http://127.0.0.1:8480/insert/0/prometheus/api/v1/write 把这个地址配置到 server.conf 当中，配置完了重启 n9e-server\n# Reader部分修改Url [Reader] Url = \u0026quot;http://172.21.0.8:8481/select/0/prometheus\u0026quot; # Writers部分修改Url [[Writers]] Url = \u0026quot;http://172.21.0.8:8480/insert/0/prometheus/api/v1/write\u0026quot;  8、 修改 n9e-webapi 的配置文件 ./etc/webapi.conf 如下：\n[[Clusters]] # Prometheus cluster name Name = \u0026quot;Default\u0026quot; # Prometheus APIs base url Prom = \u0026quot;http://127.0.0.1:8481/select/0/prometheus\u0026quot;  然后，重启 n9e-webapi，这样夜莺就可以查询到 VictoriaMetrics 集群的数据了。\n如果您使用的是 VictoriaMetrics 单机版，端口是 8428，故而 Nightingale 的配置文件需要做如下调整：\n# server.conf # Reader部分修改为： [Reader] Url = \u0026quot;http://127.0.0.1:8428\u0026quot; # Writers部分修改为： [[Writers]] Url = \u0026quot;http://127.0.0.1:8428/api/v1/write\u0026quot;  # webapi.conf # Clusters部分修改为： [[Clusters]] Name = \u0026quot;Default\u0026quot; Prom = \u0026quot;http://127.0.0.1:8428\u0026quot;  FAQ # VictoriaMetrics 单机版本如何保障数据的可靠性？\nvm 针对磁盘IO有针对性的优化，单机版可以考虑将数据的可靠性保障交给 EBS 等云盘来保证。\nVictoriaMetrics 如何评估容量？\n参考vm的官方文档。\nVictoriaMetrics 集群版本增加或者删除 vmstorage node 的时候，数据如何再平衡？\nvm 不支持扩缩容节点时，对数据进行自动的再平衡。\nVictoriaMetrics 的数据大小如何查看？\n可以通过 vmstorage 实例暴露的 /metrics 接口来获取到相应的统计数据，譬如：\n$ curl http://127.0.0.1:8482/metrics |grep -i data_size vm_data_size_bytes{type=\u0026quot;indexdb\u0026quot;} 609291 vm_data_size_bytes{type=\u0026quot;storage/big\u0026quot;} 0 vm_data_size_bytes{type=\u0026quot;storage/small\u0026quot;} 8749893  vminsert 在将数据写入多个 vmstorage node的时候，是按照什么规则将数据写入到不同的 node 上的？\n采用 jump consistent hash 对数据进行分片，写入到相应的 storage node 上。\nvmselect 在接到查询请求的时候，如何定位到请求的数据是在哪个 storage node上的？\nvmselect 并不知道每个 metrics 对应的数据分布的 storage node，vmselect 会对所有的 storage node 发起查询请求，最后进行数据合并，并返回。\nVictoriaMetrics 和 M3db 的对比和选择？\nm3db 架构设计上更高级，实现难度高，m3db 在时序数据功能之后，重点解决了自动扩缩容，数据自动平衡等运维难题。但是因此也更复杂，可靠性也更难保证。VictoriaMetrics 架构设计上更倾向于简单可靠，重点优化了单机版的性能，强调垂直扩展，同时和 prometheus 生态做到兼容，甚至于在很多的点上做到了加强。但是 VictoriaMetrics 对于时序数据 downsample，节点的自动扩缩容，数据自动再平衡等高级功能和分布式能力，是有缺失的。\n相关资料 #  使用 Docker Compose 快速部署 VictoriaMetrics 使用 Helm Chart 快速在 Kubernetes中部署 VictoriaMetrics 使用 VictoriaMetrics Operator 在 Kubernetes中部署 VictoriaMetrics  "}),e.add({id:8,href:"/docs/install/ibex/",title:"Ibex",description:"夜莺 Nightingale 的告警自愈模块的安装",content:"Ibex 是告警自愈功能依赖的模块，提供一个批量执行命令的通道，可以做到在告警的时候自动去目标机器执行脚本，如果大家没有此需求，无需阅读本节内容。\n概述 # 所谓的告警自愈，典型手段是在告警触发时自动回调某个 webhook 地址，在这个 webhook 里写告警自愈的逻辑，夜莺默认支持这种方式。另外，夜莺还可以更进一步，配合 ibex 这个模块，在告警触发的时候，自动去告警的机器执行某个脚本，这种机制可以大幅简化构建运维自愈链路的工作量，毕竟，不是所有的运维人员都擅长写 http server，但所有的运维人员，都擅长写脚本。这种方式是典型的物理机时代的产物，希望各位朋友用不到这个工具（说明贵司的IT技术已经走得非常靠前了）。\n架构 # ibex 包括 server 和 agentd 两个模块，agentd 周期性调用 server 的 rpc 接口，询问有哪些任务要执行，如果有分配给自己的任务，就从 server 拿到任务脚本信息，在本地 fork 一个进程运行，然后将结果上报给服务端。为了简化部署，server 和 agentd 融合成了一个二进制，就是 ibex，通过传入不同的参数来启动不同的角色。ibex 架构图如下：\n项目地址 #  Repo：https://github.com/flashcatcloud/ibex Linux-amd64 有编译好的二进制，在这里  安装启动 # 下载安装包之后，解压缩，在 etc 下可以找到服务端和客户端的配置文件，在 sql 目录下可以找到初始化 sql 脚本。\n初始化 sql # mysql \u0026lt; sql/ibex.sql  启动 server # server 的配置文件是 etc/server.conf，注意修改里边的 mysql 连接地址，配置正确的 mysql 用户名和密码。然后就可以直接启动了：\nnohup ./ibex server \u0026amp;\u0026gt; server.log \u0026amp;  ibex 没有 web 页面，只提供 api 接口，鉴权方式是 http basic auth，basic auth 的用户名和密码默认都是 ibex，在 etc/server.conf 中可以找到，如果ibex 部署在互联网，一定要修改默认用户名和密码，当然，因为 Nightingale 要调用 ibex，所以 Nightingale 的 server.conf 和 webapi.conf 中也配置了 ibex 的 basic auth 账号信息，要改就要一起改啦。\n启动agentd # 客户端的配置非常非常简单，agentd.conf 内容如下：\n# debug, release RunMode = \u0026quot;release\u0026quot; # task meta storage dir MetaDir = \u0026quot;./meta\u0026quot; [Heartbeat] # unit: ms Interval = 1000 # rpc servers Servers = [\u0026quot;10.2.3.4:20090\u0026quot;] # $ip or $hostname or specified string Host = \u0026quot;telegraf01\u0026quot;  重点关注 Heartbeat 这个部分，Interval 是心跳频率，默认是 1000 毫秒，如果机器量比较小，比如小于 1000 台，维持 1000 毫秒没问题，如果机器量比较大，可以适当调大这个频率，比如 2000 或者 3000，可以减轻服务端的压力。Servers 是个数组，配置的是 ibex-server 的地址，ibex-server 可以启动多个，多个地址都配置到这里即可，Host 这个字段，是本机的唯一标识，有三种配置方式，如果配置为 $ip，系统会自动探测本机的 IP，如果是 $hostname，系统会自动探测本机的 hostname，如果是其他字符串，那就直接把该字符串作为本机的唯一标识。每个机器上都要部署 ibex-agentd，不同的机器要保证 Host 字段获取的内容不能重复。\n要想做到告警的机器自动执行脚本，需要保证告警消息中的 ident 表示机器标识，且和 ibex-agentd 中的 Host 配置对应上。\n下面是启动 ibex-agentd 的命令：\nnohup ./ibex agentd \u0026amp;\u0026gt; agentd.log \u0026amp;  另外，细心的读者应该会发现 ibex 的压缩包里的 etc 目录下有个 service 目录，里边准备好了两个 service 样例文件，便于大家使用 systemd 来管理 ibex 进程，生产环境，建议使用 systemd 来管理。nohup和systemd的知识\n"}),e.add({id:9,href:"/docs/agent/categraf/",title:"Categraf",description:"Categraf是一款all-in-one的采集器，是夜莺主推的一款监控客户端",content:"基本介绍 # Categraf 是一款 all-in-one 的采集器，由 快猫团队 开源，代码托管在：\n github: https://github.com/flashcatcloud/categraf  Categraf 不但可以采集 OS、MySQL、Redis、Oracle 等常见的监控对象，也准备提供日志采集能力和 trace 接收能力，这是夜莺主推的采集器，相关信息请查阅项目 README\nCategraf 采集到数据之后，通过 remote write 协议推给远端存储，Nightingale 恰恰提供了 remote write 协议的数据接收接口，所以二者可以整合在一起，重点是配置 Categraf 的 conf/config.toml 中的 writer 部分，其中 url 部分配置为 n9e-server 的 remote write 接口：\n[writer_opt] # default: 2000 batch = 2000 # channel(as queue) size chan_size = 10000 [[writers]] url = \u0026quot;http://N9E-SERVER:19000/prometheus/v1/write\u0026quot; # Basic auth username basic_auth_user = \u0026quot;\u0026quot; # Basic auth password basic_auth_pass = \u0026quot;\u0026quot; # timeout settings, unit: ms timeout = 5000 dial_timeout = 2500 max_idle_conns_per_host = 100  采集插件 # Categraf 每个采集器，都有一个配置目录，在 conf 下面，以 input. 打头，如果某个插件不想启用，就把插件配置目录改个名字，别让它是 input. 打头即可，比如 docker 不想采集，可以 mv input.docker bak.input.docker 就可以了。当然了，也并不是说只要有 input.xx 目录，就会采集对应的内容，比如 MySQL 监控插件，如果想采集其数据，至少要在 conf/input.mysql/mysql.toml 中配置要采集的数据库实例的连接地址。\n每个采集插件的配置文件，都给了很详尽的注释，阅读这些注释，基本就了解如何去配置各个插件了。另外，有些采集插件还会同步提供夜莺监控大盘JSON和告警规则JSON，大家可以直接导入使用，在代码的 inputs 目录，机器的监控大盘比较特殊，放到了 system 目录，没有分散在 cpu、mem、disk 等目录。\n很多采集插件的配置文件中，都有 [[instances]] 配置段，这个 [[]] 在 toml 配置中表示数组，即 instances 配置段可以配置多份，比如 oracle 的配置文件：\n# collect interval, unit: second interval = 15 [[instances]] address = \u0026quot;10.1.2.3:1521/orcl\u0026quot; username = \u0026quot;monitor\u0026quot; password = \u0026quot;123456\u0026quot; is_sys_dba = false is_sys_oper = false disable_connection_pool = false max_open_connections = 5 # interval = global.interval * interval_times interval_times = 1 labels = { region=\u0026quot;cloud\u0026quot; } [[instances]] address = \u0026quot;192.168.10.10:1521/orcl\u0026quot; username = \u0026quot;monitor\u0026quot; password = \u0026quot;123456\u0026quot; is_sys_dba = false is_sys_oper = false disable_connection_pool = false max_open_connections = 5 labels = { region=\u0026quot;local\u0026quot; }  address 可以指定连接地址，如果想监控多个 oracle 实例，一个 address 显然不行了，就要把 instances 部分拷贝多份，即可做到监控多个 oracle 实例的效果。\n当然，更多信息请查阅Categraf README，README 中有 FAQ 和 QuickStart 的链接，可以帮助大家快速入门。另外，大家也可以参考我的公众号文章《讲解Categraf采集器》里边有3个视频教程介绍Categraf，公众号也欢迎大家关注，会持续更新监控相关的文章。\n"}),e.add({id:10,href:"/docs/usage/share/",title:"藏经阁",description:"夜莺监控藏经阁，相关分享资料，网友分享资料",content:"本节罗列社区用户的分享文章，欢迎大家把自己的心得文章链接放到这里，让整个社区受益，相互交流：\n专栏 # 龙渊秦五专栏连载：《说透运维监控系统》 #  1.1 监控系统概述 1.2 业界方案概述 2.1 安装夜莺监控系统 2.2 监控系统典型架构以及夜莺分布式部署方案 3.1 夜莺页面功能介绍 4.1 监控数据采集必知必会 4.2 讲解Categraf采集器 4.3 手把手教你编写Categraf采集插件  云原生监控连载：《说透Kubernetes云原生监控》 #  1. Kubernetes 云原生监控系列-概览 2. Kubernetes 云原生监控系列-环境鉴权与自动发现 3. Kubernetes 控制面组件指标梳理 4. Kubernetes Node 组件指标梳理 5. Kubernetes 组件监控实践  服务稳定性保障专栏： #  是时候该从用户视角去看待系统稳定性问题了 - by laiwei SLO新解，一种行之有效的故障处理方法 - by 华明 基于夜莺快速构建日志告警平台 - by 秦叶宁 为夜莺监控，一键开启智能告警能力 - by 秦叶宁 All-in-one的监控数据采集器 稳定性保障一号位的进击之旅 - by laiwei 云原生监控的十大趋势和特点 - laiwei 服务挂了，学费交了，掌握这6点就值了 - by 华明 服务稳定性保障的五大误解 - by 华明  FlashTalk #  [第一期 2022-06-16] 夜莺监控社区动态交流\n  夜莺近期动态-快猫-秦晓辉-20220616.pdf 夜莺智能告警介绍-快猫-秦叶宁-20220616.pdf   [第二期 2022-09-27 ~ ] 云原生监控系列专题\n  Kubernetes云原生监控-20220927.pdf Kubernetes组件监控讲解-快猫-孔飞-20221011.pdf   [第三期 2022-11-03] 运维转型探索\n  途游邹轶-运维转型探索：打造研运一体化敏捷组织  夜莺动态 #  基于夜莺快速构建日志告警平台 - 秦叶宁@快猫星云 为夜莺监控，一键开启智能告警能力 - 秦叶宁@快猫星云 让工程师用上有设计感的监控工具，夜莺5.10来了 - 夜莺开发团队 Categraf - 夜莺监控发布新轮子 - 秦晓辉@快猫星云 夜莺监控成为CCF托管开源项目 - laiwei@快猫星云 十年死磕，从一线工程师到CEO - laiwei@快猫星云  藏经阁 #  夜莺功能介绍材料（可用于你在团队内部分享/推广夜莺监控），点击下载PDF版本 Flashcat平台介绍材料（可用于你在团队内部分享/推广Flashcat平台），点击下载PDF版本 Flashcat平台一分钟视频，快速预览Flashcat平台功能特性，点击预览 Zabbix 和夜莺监控横评对比  案例研究 #  映客直播使用夜莺监控，支撑5亿时间线节省8成费用 - 映客@郑富强 夜莺监控助力盛见网络，保障联盟链稳定运行 - 池梦南@盛见网络 夜莺监控助力方正证券解决运维稳定性难题，5年铁粉用户给出满分评价 - 杨豆豆@方正证券 监控告警平台的国产化选择—Rancher 与夜莺的集成实践 - 张智博@Rancher 高科技Startup构建监控体系之路 - 若尘@贝联珠贯 主流监控工具如何选？头部在线教育公司的监控选型落地全流程分享 - 于长夫  部署 #  使用ansible部署Categraf 使用ansible部署telegraf、categraf  告警通知 #  手把手教你接入钉钉告警 修改notify.py为夜莺增加短信通知能力 - by 柴今栋@艾派 使用notify.py接入阿里云语音通知 - by 果  监控实战 #  JVM监控调研对比 - by 国泰君安期货郑绪祺 Oracle的简单监控实现 - by 柴今栋@艾派 - 备注：Categraf新版已经内置支持 RocketMQ简单监控的实现 - by 柴今栋@艾派 一文说透MySQL监控，使用Prometheus生态的Exporter Vsphere-monitor数据上报夜莺V5监控  经验杂谈 #  弃用Prometheus，搭建单机版本的VictoriaMetrics - by SL 使用pg作为数据库替换MySQL 一键部署夜莺到Kubernetes - by 陶柒 记n9e_server活跃告警 聚合规则写法 - 肖君  Telegraf #  Telegraf Windows版本的安装，保姆级教程 - by SL Telegraf Linux版本的安装，保姆级教程 - by SL telegraf常用中间件采集 Telegraf 配置文件，告警规则，看图大盘分享 - 映客-郑富强 telegraf采集Nacos - 郭什么磊° 使用Telegraf做夜莺5.0的数据采集，样例包含Linux基本信息采集、MySQL、Redis的采集 - by 柴今栋@艾派  监控大盘 # 每个 Categraf 的插件目录下，大都会有监控大盘的 json 文件，如果社区有用户自己制作的大盘希望分享出来，会罗列在这里\n vsphere-monitor的监控大盘，采集方式  "}),e.add({id:11,href:"/docs/agent/telegraf/",title:"Telegraf",description:"Telegraf 接入夜莺 Nightingale",content:"Telegraf 是 InfluxData 公司开源的一款采集器，内置非常多的采集插件，不过 Telegraf 是面向 InfluxDB 生态的，采集的监控数据推给 InfluxDB 非常合适，推给 Prometheus、Victoriametrics、Thanos 这些时序库，可能会带来问题。主要是两点：\n 有些数据是 string 类型的，Prometheus、VM、M3、Thanos 等都不支持 string 类型的数据 有些采集器设计的标签是非稳态的设计，比如经常会看到 result=success 和 result=failed 的标签，需要手工配置采集器 drop 掉，但是对于新手确实有些难度  另外一个问题是，Telegraf 采集的数据存到 Prometheus 中，这种做法在业界实践的比较少，导致 Grafana 大盘很少，需要我们付出较大精力手工制作大盘。不过，如果，你是资深监控玩家，Telegraf 上面这些问题都不是问题。下面是笔者之前调研 Telegraf 的几篇笔记，供大家参考：\n Telegraf监控客户端调研笔记（1）-介绍、安装、初步测试 Telegraf监控客户端调研笔记（2）-CPU、MEM、DISK、IO相关指标采集 Telegraf监控客户端调研笔记（3）-kernel、system、processes相关指标采集 Telegraf监控客户端调研笔记（4）-exec、net、netstat相关指标采集 Telegraf监控客户端调研笔记（5）-本地端口监控\u0026amp;远程TCP探测 Telegraf监控客户端调研笔记（6）-PING监控、进程监控  Telegraf 是如何与 Nightingale 整合的呢？Telegraf 有不同的 output plugin，可以把采集的数据推给 OpenTSDB、推给 Datadog，Nightingale 实现了 OpenTSDB 和 Datadog 这两种消息接收接口，所以，可以通过任一 output plugin 和 Nightingale 对接。下面提供一个简单的 Telegraf 配置供大家参考，使用 OpenTSDB 的 output plugin 和 Nightingale 对接，即 [[outputs.opentsdb]] 配置段，host 部分配置为 n9e-server 的地址：\n#!/bin/sh version=1.20.4 tarball=telegraf-${version}_linux_amd64.tar.gz wget https://dl.influxdata.com/telegraf/releases/$tarball tar xzvf $tarball mkdir -p /opt/telegraf cp -far telegraf-${version}/usr/bin/telegraf /opt/telegraf cat \u0026lt;\u0026lt;EOF \u0026gt; /opt/telegraf/telegraf.conf [global_tags] [agent] interval = \u0026quot;10s\u0026quot; round_interval = true metric_batch_size = 1000 metric_buffer_limit = 10000 collection_jitter = \u0026quot;0s\u0026quot; flush_interval = \u0026quot;10s\u0026quot; flush_jitter = \u0026quot;0s\u0026quot; precision = \u0026quot;\u0026quot; hostname = \u0026quot;\u0026quot; omit_hostname = false [[outputs.opentsdb]] host = \u0026quot;http://127.0.0.1\u0026quot; port = 19000 http_batch_size = 50 http_path = \u0026quot;/opentsdb/put\u0026quot; debug = false separator = \u0026quot;_\u0026quot; [[inputs.cpu]] percpu = true totalcpu = true collect_cpu_time = false report_active = true [[inputs.disk]] ignore_fs = [\u0026quot;tmpfs\u0026quot;, \u0026quot;devtmpfs\u0026quot;, \u0026quot;devfs\u0026quot;, \u0026quot;iso9660\u0026quot;, \u0026quot;overlay\u0026quot;, \u0026quot;aufs\u0026quot;, \u0026quot;squashfs\u0026quot;] [[inputs.diskio]] [[inputs.kernel]] [[inputs.mem]] [[inputs.processes]] [[inputs.system]] fielddrop = [\u0026quot;uptime_format\u0026quot;] [[inputs.net]] ignore_protocol_stats = true EOF cat \u0026lt;\u0026lt;EOF \u0026gt; /etc/systemd/system/telegraf.service [Unit] Description=\u0026quot;telegraf\u0026quot; After=network.target [Service] Type=simple ExecStart=/opt/telegraf/telegraf --config telegraf.conf WorkingDirectory=/opt/telegraf SuccessExitStatus=0 LimitNOFILE=65535 StandardOutput=syslog StandardError=syslog SyslogIdentifier=telegraf KillMode=process KillSignal=SIGQUIT TimeoutStopSec=5 Restart=always [Install] WantedBy=multi-user.target EOF systemctl daemon-reload systemctl enable telegraf systemctl restart telegraf systemctl status telegraf  "}),e.add({id:12,href:"/docs/agent/datadog-agent/",title:"Datadog-Agent",description:"Datadog-Agent 接入夜莺 Nightingale",content:"Datadog 是专门提供监控和分析服务的 SaaS 服务商，市值几百亿，成立了10多年了，他们做的客户端采集器，理论上应该是比较完备的，夜莺实现了几个 Datadog 特定的接口，可以接收Datadog-Agent 推送上来的数据，即：我们可以拿 Datadog-Agent 作为客户端采集器采集监控数据，然后上报给夜莺。\n1、注册datadog的账号 # https://www.datadoghq.com/\n2、选择套餐 # https://app.datadoghq.com/billing/plan 可以选择免费的套餐\n3、拿到agent安装命令 # https://app.datadoghq.com/account/settings#agent 选择对应的OS，比如CentOS7，可能是类似这么个命令：\nDD_AGENT_MAJOR_VERSION=7 DD_API_KEY=xxx DD_SITE=\u0026quot;datadoghq.com\u0026quot; bash -c \u0026quot;$(curl -L https://s3.amazonaws.com/dd-agent/scripts/install_script.sh)\u0026quot;  DD_API_KEY 是一串字符串，不同的账号有自己的 API_KEY，拿着这个命令去 shell 下（使用root账号应该会省事一些）跑一下安装\n4、修改配置文件 # 修改 Datadog-Agent 的配置文件，把推送监控数据的地址，改成 n9e-server 的地址，配置文件地址在：/etc/datadog-agent/datadog.yaml 修改 dd_url 这个配置项，比如我的环境：\ndd_url: http://10.206.0.16:19000/datadog  5、重启datadog-agent # systemctl restart datadog-agent  "}),e.add({id:13,href:"/docs/agent/grafana-agent/",title:"Grafana-Agent",description:"Grafana-Agent 接入夜莺 Nightingale",content:"Grafana-agent 是 Grafana 开源的一款 Agent，专门用于和自己的 Cloud 做数据采集集成，通过 remote write 协议推数据给后端，和 Categraf 的数据推送方式一样，所以，也是可以作为 Nightingale 的采集器的。Grafana-Agent 的具体使用请查阅 Grafana 官方文档，下面给出 v0.23.0 版本的 Grafana-Agent 的简要安装方式，如果各位看官使用了其他版本的 Grafana-Agent，下面的教程可能就不适用了，毕竟，Grafana-Agent 也在快速迭代，请大家注意。\n1. 下载二进制 # 以 64 位 Linux 举例：\ncurl -SOL \u0026quot;https://github.com/grafana/agent/releases/download/v0.23.0/agent-linux-amd64.zip\u0026quot; gunzip ./agent-linux-amd64.zip chmod a+x \u0026quot;agent-linux-amd64\u0026quot;  2. 生成配置 # cat \u0026lt;\u0026lt;EOF \u0026gt; ./agent-cfg.yaml server: log_level: info http_listen_port: 12345 metrics: global: scrape_interval: 15s scrape_timeout: 10s remote_write: - url: https://N9E-SERVER:19000/prometheus/v1/write basic_auth: username: \u0026quot;\u0026quot; password: \u0026quot;\u0026quot; integrations: agent: enabled: true node_exporter: enabled: true include_exporter_metrics: true EOF  上面的 url 部分，就是 n9e-server 的 remote write 数据接收接口，仔细看就会发现，和 Categraf 章节用的 url 是一样的。\n3. 启动 grafana-agent # nohup ./agent-linux-amd64 \\ -config.file ./agent-cfg.yaml \\ -metrics.wal-directory ./data \\ \u0026amp;\u0026gt; grafana-agent.log \u0026amp;  上面的配置内置启用了 node_exporter，Grafana-Agent 内置了很多 exporter，省的到处去找 exporter 了.\n4. 延伸阅读 #  阅读 grafana-agent详细使用文档 ，了解更多。  "}),e.add({id:14,href:"/docs/agent/falcon-plugin/",title:"Falcon-Plugin",description:"Falcon-Plugin 接入夜莺 Nightingale",content:"Nightingale 实现了 Open-Falcon 的 HTTP 数据接收接口，所以，Open-Falcon 社区很多采集插件也是可以直接使用的。但是 Falcon-Agent 不行，因为 Falcon-Agent 推送监控数据给服务端，走的是 RPC 接口。\n如果你发现某个 Falcon-Plugin 是用 CRON 的方式驱动的，推送数据走的是 Falcon-Agent 的 HTTP 接口，那这个插件就可以推数据给夜莺。举个例子，比如 mymon 其配置文件采用 ini 格式，下面是样例：\n[default] basedir = . # 工作目录 log_dir = ./fixtures # 日志目录，默认日志文件为myMon.log,旧版本有log_file项，如果同时设置了，会优先采用log_file ignore_file = ./falconignore # 配置忽略的metric项 snapshot_dir = ./snapshot # 保存快照(process, innodb status)的目录 snapshot_day = 10 # 保存快照的时间(日) log_level = 5 # 日志级别[RFC5424] # 0 LevelEmergency # 1 LevelAlert # 2 LevelCritical # 3 LevelError # 4 LevelWarning # 5 LevelNotice # 6 LevelInformational # 7 LevelDebug falcon_client=http://127.0.0.1:1988/v1/push # falcon agent连接地址 [mysql] user=root # 数据库用户名 password=1tIsB1g3rt # 您的数据库密码 host=127.0.0.1 # 数据库连接地址 port=3306 # 数据库端口  注意 falcon_client 配置项，配置的是 Falcon-Agent 的数据接收接口，可以把这个配置改成夜莺 n9e-server 的地址： http://N9E-SERVER:19000/openfalcon/push 。\nOpen-Falcon 的监控数据中有一个 endpoint 字段，夜莺会把 endpoint 字段当做监控对象唯一标识来对待，自动解析之后入库，就可以在对象列表中看到了。当然，如果没有 endpoint 字段也没关系，使用 metric 和 tags 也是可以唯一标识一个 Series 的。\n"}),e.add({id:15,href:"/docs/usage/video/",title:"入门教程",description:"夜莺（ Nightingale ）入门视频教程",content:" 视频讲解-夜莺页面功能介绍 视频讲解-告警自愈脚本的使用 视频讲解-监控对象的管理功能 视频讲解-如何接入多个时序存储 视频讲解-夜莺的配置文件  除了这些视频教程，使用手册这一章，还会提供更多小节来介绍一些大家常问的问题，比如如何监控交换机，如何监控应用等。从总体问题比例来看，夜莺服务端问题相对较少，大家摸索一下，很快可以掌握，疑问比较多的，是对各种目标的监控，比如如何监控 MySQL，如何监控 Redis 等，针对这部分问题，大家应该去查看采集器的文档，比如 Telegraf 每个采集器下面都有 README介绍， 通过这些 README，理论上就可以知道如何使用各个采集器。Categraf 的采集器目录 在这里， 未来我们也会把所有采集器补充完整的 README，以及告警规则和监控大盘JSON，大家导入直接就可以使用，当然，路漫漫其修远兮，一步一步来吧。\n"}),e.add({id:16,href:"/docs/usage/snmp/",title:"SNMP",description:"夜莺（ Nightingale ）通过 SNMP 监控网络设备",content:"监控网络设备，主要是通过 SNMP 协议，Categraf、Telegraf、Datadog-Agent、snmp_exporter 都提供了这个能力。\nswitch_legacy # Categraf 提供了一个网络设备的采集插件：switch_legacy，在 conf/input.switch_legacy 下可以看到配置文件，最核心就是配置交换机的 IP 以及认证信息，switch_legacy 当前只支持 v2 协议，所以认证信息就是 community 字段。其他配置都一目了然，这里就不赘述了。\n这个插件是把之前 Open-Falcon 社区的 swcollector 直接拿过来了，感谢 冯骐 大佬持续在维护这个开源项目。\nsnmp # Categraf 从 v0.2.13 版本开始把 Telegraf 的 snmp 插件集成了进来，推荐大家采用这个插件来监控网络设备。这个插件的核心逻辑是：要采集什么指标，直接配置对应的 oid 即可，而且可以把一些 oid 采集到的数据当做时序数据的标签，非常非常灵活。\n当然，弊端也有，因为 SNMP 体系里有大量的私有 oid，比如不同的设备获取 CPU、内存利用率的 oid 都不一样，这就需要为不同的型号的设备采用不同的配置，维护起来比较麻烦，需要大量的积累。这里我倡议大家把不同的设备型号的采集配置积累到 这里，每个型号一个文件夹，长期积累下来，那将是利人利己的好事。不知道如何提PR的可以联系我们。\n另外，也不用太悲观，针对网络设备而言，大部分监控数据的采集都是通用 oid 就可以搞定的，举个例子：\ninterval = 60 [[instances]] agents = [\u0026quot;udp://172.30.15.189:161\u0026quot;] interval_times = 1 timeout = \u0026quot;5s\u0026quot; version = 2 community = \u0026quot;public\u0026quot; # agent_host_tag 设置为 ident，这个交换机就会当做监控对象出现在夜莺的监控对象列表里 # 看大家的需要，我个人建议把 agent_host_tag 设置为 switch_ip agent_host_tag = \u0026quot;ident\u0026quot; retries = 1 [[instances.field]] oid = \u0026quot;RFC1213-MIB::sysUpTime.0\u0026quot; name = \u0026quot;uptime\u0026quot; [[instances.field]] oid = \u0026quot;RFC1213-MIB::sysName.0\u0026quot; name = \u0026quot;source\u0026quot; is_tag = true [[instances.table]] oid = \u0026quot;IF-MIB::ifTable\u0026quot; name = \u0026quot;interface\u0026quot; inherit_tags = [\u0026quot;source\u0026quot;] [[instances.table.field]] oid = \u0026quot;IF-MIB::ifDescr\u0026quot; name = \u0026quot;ifDescr\u0026quot; is_tag = true  上面的样例是 v2 版本的配置，如果是 v3 版本，校验方式举例：\nversion = 3 sec_name = \u0026quot;managev3user\u0026quot; auth_protocol = \u0026quot;SHA\u0026quot; auth_password = \u0026quot;example.Demo.c0m\u0026quot;  另外，snmp 的采集，建议大家部署单独的 Categraf 来做，因为不同监控对象采集频率可能不同，比如边缘交换机，我们 5min 采集一次就够了，核心交换机可以配置的频繁一些，比如 60s 或者 120s，如何调整采集频率呢？需要借助 interval 和 interval_times 等配置实现，具体可以参考《讲解Categraf采集器》中的视频教程。\n"}),e.add({id:17,href:"/docs/usage/apm/",title:"应用监控",description:"夜莺（ Nightingale ）通过 Prometheus SDK 监控应用程序",content:"写在前面 # 应用监控实际要比 OS、中间件的监控更为关键，因为某个 OS 层面的指标异常，比如 CPU 飙高了，未必会影响终端用户的体验，但是应用层面的监控指标出问题，通常就会影响客户的感受、甚至影响客户的付费。\n针对应用监控，Google提出了 4 个黄金指标，分别是：流量、延迟、错误、饱和度，其中前面 3 个指标都可以通过内嵌 SDK 的方式埋点采集，本节重点介绍这种方式。当然了，内嵌 SDK 有较强的代码侵入性，如果业务研发难以配合，也可以采用解析日志的方案，这个超出了夜莺（夜莺是指标监控系统）的范畴，大家如果感兴趣，可以了解一下快猫的商业化产品\n埋点工具 # 最常见的通用埋点工具有两个，一个是 statsd，一个是 prometheus SDK，当然，各个语言也会有自己的更方便的方式，比如 Java 生态使用 micrometer 较多，如果是 SpringBoot 的程序，则使用 actuator 会更便捷，actuator 底层就是使用 micrometer。\n夜莺自身监控 # 我们就以夜莺自身的代码举例，讲解如何内嵌埋点工具，这里选择 prometheus SDK 作为埋点方案。\n夜莺核心模块有两个，Webapi 主要是提供 HTTP 接口给 JavaScript 调用，Server 主要是负责接收监控数据，处理告警规则，这两个模块都引入了 Prometheus 的 Go 的SDK，用此方式做 App Performance 监控，本节以夜莺的代码为例，讲解如何使用 Prometheus 的 SDK。\nWebapi # Webapi 模块主要统计两个内容，一个是请求的数量统计，一个是请求的延迟统计，统计时，要用不同的 Label 做维度区分，后面就可以通过不同的维度做多种多样的统计分析，对于 HTTP 请求，规划 4 个核心 Label，分别是：service、code、path、method。service 标识服务名称，要求全局唯一，便于和其他服务名称区分开，比如 Webapi 模块，就定义为 n9e-webapi，code 是 HTTP 返回的状态码，200 就表示成功数量，其他 code 就是失败的，后面我们可以据此统计成功率，method 是 HTTP 方法，GET、POST、PUT、DELETE 等，比如新增用户和获取用户列表可能都是 /api/n9e/users，从路径上无法区分，只能再加上 method 才能区分开。\npath 着重说一下，表示请求路径，比如上面提到的/api/n9e/users，但是，在 restful 实践中，url 中经常会有参数，比如获取编号为1的用户的信息，接口是/api/n9e/user/1，获取编号为2的用户信息，接口是/api/n9e/user/2，如果这俩带有用户编号的 url 都作为 Label，会造成时序库索引爆炸，而且从业务方使用角度来看，我们也不关注编号为1的用户获取请求还是编号为2的用户获取请求，而是关注整体的GET /api/n9e/user/:id这个接口的监控数据。所以我们在设置 Label 的时候，要把path设置为/api/n9e/user/:id，而不是那具体的带有用户编号的 url 路径。夜莺用的 gin 框架，gin 框架有个 FullPath 方法就是获取这个信息的，比较方便。\n首先，我们在 Webapi 下面创建一个 stat package，放置相关统计变量：\npackage stat import ( \u0026quot;time\u0026quot; \u0026quot;github.com/prometheus/client_golang/prometheus\u0026quot; ) const Service = \u0026quot;n9e-webapi\u0026quot; var ( labels = []string{\u0026quot;service\u0026quot;, \u0026quot;code\u0026quot;, \u0026quot;path\u0026quot;, \u0026quot;method\u0026quot;} uptime = prometheus.NewCounterVec( prometheus.CounterOpts{ Name: \u0026quot;uptime\u0026quot;, Help: \u0026quot;HTTP service uptime.\u0026quot;, }, []string{\u0026quot;service\u0026quot;}, ) RequestCounter = prometheus.NewCounterVec( prometheus.CounterOpts{ Name: \u0026quot;http_request_count_total\u0026quot;, Help: \u0026quot;Total number of HTTP requests made.\u0026quot;, }, labels, ) RequestDuration = prometheus.NewHistogramVec( prometheus.HistogramOpts{ Buckets: []float64{.01, .1, 1, 10}, Name: \u0026quot;http_request_duration_seconds\u0026quot;, Help: \u0026quot;HTTP request latencies in seconds.\u0026quot;, }, labels, ) ) func Init() { // Register the summary and the histogram with Prometheus's default registry. prometheus.MustRegister( uptime, RequestCounter, RequestDuration, ) go recordUptime() } // recordUptime increases service uptime per second. func recordUptime() { for range time.Tick(time.Second) { uptime.WithLabelValues(Service).Inc() } }  uptime 变量是顺手为之，统计进程启动了多久时间，不用太关注，RequestCounter 和 RequestDuration，分别统计请求流量和请求延迟。Init 方法是在 Webapi 模块进程初始化的时候调用，所以进程一起，就会自动注册好。\n然后我们写一个 middleware，在请求进来的时候拦截一下，省的每个请求都要去统计，middleware 方法的代码如下：\nimport ( ... promstat \u0026quot;github.com/didi/nightingale/v5/src/webapi/stat\u0026quot; ) func stat() gin.HandlerFunc { return func(c *gin.Context) { start := time.Now() c.Next() code := fmt.Sprintf(\u0026quot;%d\u0026quot;, c.Writer.Status()) method := c.Request.Method labels := []string{promstat.Service, code, c.FullPath(), method} promstat.RequestCounter.WithLabelValues(labels...).Inc() promstat.RequestDuration.WithLabelValues(labels...).Observe(float64(time.Since(start).Seconds())) } }  有了这个 middleware 之后，new 出 gin 的 engine 的时候，就立马 Use 一下，代码如下：\n... r := gin.New() r.Use(stat()) ...  最后，监控数据要通过/metrics接口暴露出去，我们要暴露这个请求端点，代码如下：\nimport ( ... \u0026quot;github.com/prometheus/client_golang/prometheus/promhttp\u0026quot; ) func configRoute(r *gin.Engine, version string) { ... r.GET(\u0026quot;/metrics\u0026quot;, gin.WrapH(promhttp.Handler())) }  如上，每个 Webapi 的接口的流量和成功率都可以监控到了。如果你也部署了夜莺，请求 Webapi 的端口（默认是18000）的 /metrics 接口看看吧。\n💡  如果服务部署多个实例，甚至多个 region，多个环境，上面的 4 个 Label 就不够用了，因为只有这 4 个 Label 不足以唯一标识一个具体的实例，此时需要 env、region、instance 这种 Label，这些 Label不 需要在代码里埋点，在采集的时候一般可以附加额外的标签，通过附加标签的方式来处理即可   Server # Server 模块的监控，和 Webapi 模块的监控差异较大，因为关注点不同，Webapi 关注的是 HTTP 接口的请求量和延迟，而 Server 模块关注的是接收了多少监控指标，内部事件队列的长度，从数据库同步告警规则花费多久，同步了多少条数据等，所以，我们也需要在 Server 的 package 下创建一个 stat 包，stat 包下放置 stat.go，内容如下：\npackage stat import ( \u0026quot;github.com/prometheus/client_golang/prometheus\u0026quot; ) const ( namespace = \u0026quot;n9e\u0026quot; subsystem = \u0026quot;server\u0026quot; ) var ( // 各个周期性任务的执行耗时 GaugeCronDuration = prometheus.NewGaugeVec(prometheus.GaugeOpts{ Namespace: namespace, Subsystem: subsystem, Name: \u0026quot;cron_duration\u0026quot;, Help: \u0026quot;Cron method use duration, unit: ms.\u0026quot;, }, []string{\u0026quot;cluster\u0026quot;, \u0026quot;name\u0026quot;}) // 从数据库同步数据的时候，同步的条数 GaugeSyncNumber = prometheus.NewGaugeVec(prometheus.GaugeOpts{ Namespace: namespace, Subsystem: subsystem, Name: \u0026quot;cron_sync_number\u0026quot;, Help: \u0026quot;Cron sync number.\u0026quot;, }, []string{\u0026quot;cluster\u0026quot;, \u0026quot;name\u0026quot;}) // 从各个接收接口接收到的监控数据总量 CounterSampleTotal = prometheus.NewCounterVec(prometheus.CounterOpts{ Namespace: namespace, Subsystem: subsystem, Name: \u0026quot;samples_received_total\u0026quot;, Help: \u0026quot;Total number samples received.\u0026quot;, }, []string{\u0026quot;cluster\u0026quot;, \u0026quot;channel\u0026quot;}) // 产生的告警总量 CounterAlertsTotal = prometheus.NewCounterVec(prometheus.CounterOpts{ Namespace: namespace, Subsystem: subsystem, Name: \u0026quot;alerts_total\u0026quot;, Help: \u0026quot;Total number alert events.\u0026quot;, }, []string{\u0026quot;cluster\u0026quot;}) // 内存中的告警事件队列的长度 GaugeAlertQueueSize = prometheus.NewGaugeVec(prometheus.GaugeOpts{ Namespace: namespace, Subsystem: subsystem, Name: \u0026quot;alert_queue_size\u0026quot;, Help: \u0026quot;The size of alert queue.\u0026quot;, }, []string{\u0026quot;cluster\u0026quot;}) ) func Init() { // Register the summary and the histogram with Prometheus's default registry. prometheus.MustRegister( GaugeCronDuration, GaugeSyncNumber, CounterSampleTotal, CounterAlertsTotal, GaugeAlertQueueSize, ) }  定义一个监控指标，除了 name 之外，还可以设置 namespace、subsystem，最终通过 /metrics 接口暴露的时候，可以发现：监控指标的最终名字，就是$namespace_$subsystem_$name，三者拼接在一起。Webapi 模块的监控代码中我们看到了 counter 类型和 histogram 类型的处理，这次我们拿 GaugeAlertQueueSize 举例，这是个 GAUGE 类型的统计数据，起一个 goroutine 周期性获取队列长度，然后 Set 到 GaugeAlertQueueSize 中：\npackage engine import ( \u0026quot;context\u0026quot; \u0026quot;time\u0026quot; \u0026quot;github.com/didi/nightingale/v5/src/server/config\u0026quot; promstat \u0026quot;github.com/didi/nightingale/v5/src/server/stat\u0026quot; ) func Start(ctx context.Context) error { ... go reportQueueSize() return nil } func reportQueueSize() { for { time.Sleep(time.Second) promstat.GaugeAlertQueueSize.WithLabelValues(config.C.ClusterName).Set(float64(EventQueue.Len())) } }  另外，Init 方法要在 Server 模块初始化的时候调用，Server 的 router.go 中要暴露 /metrics 端点路径，这些就不再详述了，大家可以扒拉一下夜莺的代码看一下。\n数据抓取 # 应用自身的监控数据已经通过 /metrics 接口暴露了，后续采集规则可以在 prometheus.yml 中配置，prometheus.yml 中有个 section 叫：scrape_configs 可以配置抓取目标，这是 Prometheus 范畴的知识了，大家可以参考Prometheus官网。\n或者，大家也可以使用 Categraf 的 prometheus 插件抓取 /metrics 数据，就是把 url 配置进去即可，比较容易。\n参考资料 #  https://prometheus.io/docs/instrumenting/clientlibs/ https://github.com/prometheus/client_golang/tree/master/examples  "}),e.add({id:18,href:"/docs/usage/mtail/",title:"Mtail日志监控",description:"夜莺（ Nightingale ）通过 mtail 监控日志。Mtail日志告警。",content:"前言 # 说到日志监控，大家第一反应的可能是ELK的方案，或者Loki的方案，这两个方案都是把日志采集了发到中心，在中心存储、查看、分析，不过这个方案相对比较重量级一些，如果我们的需求只是从日志中提取一些metrics数据，比如统计一些日志中出现的Error次数之类的，则有一个更简单的方案。\n这里给大家介绍一个Google出品的小工具，mtail，mtail就是流式读取日志，通过正则表达式匹配的方式从日志中提取metrics指标，这种方式可以利用目标机器的算力，不过如果量太大，可能会影响目标机器上的业务程序，另外一个好处是无侵入性，不需要业务埋点，如果业务程序是第三方供应商提供的，我们改不了其代码，mtail此时就非常合适了。当然了，如果业务程序是我们公司的人自己写的，那还是建议用埋点的方式采集指标，mtail只是作为一个补充吧。\n更新 # 从 Categraf v0.2.17 开始，我们把 mtail 整合到了 Categraf 中，可以少部署一堆进程了，详情参考：《从应用日志中提取监控metrics》，这个文章博客的内容已经非常详细，本节文档后面的内容理论上不用看了。\nmtail简介 # mtail的使用方案，参考如下两个文档（下载的话参考Releases页面）：\n Deploying Programming Guide  我们拿mtail的启动命令来举例其用法：\nmtail --progs /etc/mtail --logs /var/log/syslog --logs /var/log/ntp/peerstats  通过 --progs 参数指定一个目录，这个目录里放置一堆的*.mtail文件，每个mtail文件就是描述的正则提取规则，通过 --logs 参数来指定要监控的日志目录，可以写通配符，--logs 可以写多次，上例中只是指定了 --progs 和 --logs ，没有其他参数，mtail启动之后会自动监听一个端口3903，在3903的/metrics接口暴露符合Prometheus协议的监控数据，Prometheus 或者 Categraf 或者 Telegraf 等就可以从 /metrics 接口提取监控数据。\n这样看起来，原理就很清晰了，mtail 启动之后，根据 --logs 找到相关日志文件，seek 到文件末尾，开始流式读取，每读到一行，就根据 --progs 指定的那些规则文件做匹配，看是否符合某些正则，从中提取时序数据，然后通过3903的/metrics暴露采集到的监控指标。当然，除了Prometheus这种/metrics方式暴露，mtail 还支持把监控数据直接推给 graphite 或者 statsd，具体可以参考：这里\nmtail样例 # 这里我用mtail监控一下n9e-server的日志，从中提取一下各个告警规则触发的 notify 的数量，这个日志举例：\n2021-12-27 10:00:30.537582 INFO engine/logger.go:19 event(cbb8d4be5efd07983c296aaa4dec5737 triggered) notify: rule_id=9 [__name__=net_response_result_code author=qin ident=10-255-0-34 port=4567 protocol=tcp server=localhost]2@1640570430  很明显，日志中有这么个关键字：notify: rule_id=9，可以用正则来匹配，统计出现的行数，ruleid 也可以从中提取到，这样，我们可以把 ruleid 作为标签上报，于是乎，我们就可以写出这样的 mtail 规则了：\n[root@10-255-0-34 nightingale]# cat /etc/mtail/n9e-server.mtail counter mtail_alert_rule_notify_total by ruleid /notify: rule_id=(?P\u0026lt;ruleid\u0026gt;\\d+)/ { mtail_alert_rule_notify_total[$ruleid]++ }  然后启动也比较简单，我这里就用 nohup 简单来做：\nnohup mtail -logtostderr --progs /etc/mtail --logs server.log \u0026amp;\u0026gt; stdout.log \u0026amp;  mtail 没有指定绝对路径，是因为我把 mtail 的二进制直接放在了 /usr/bin 下面了，mtail 默认会监听在 3903，所以我们可以用如下命令验证：\ncurl -s localhost:3903/metrics # output: # HELP mtail_alert_rule_notify_total defined at n9e-server.mtail:1:9-37 # TYPE mtail_alert_rule_notify_total counter mtail_alert_rule_notify_total{prog=\u0026quot;n9e-server.mtail\u0026quot;,ruleid=\u0026quot;9\u0026quot;} 6  上面的输出只是挑选了部分内容，没有全部贴出，这就表示正常采集到了，如果 n9e 的 server.log 中当前没有打印 notify 相关的日志，那请求/metrics接口是没法得到上面的输出的，可以手工配置一条必然会触发的规则，待日志里有相关输出的时候再次请求 /metrics 接口，应该就有了。\n最后我们在 Categraf （或者 Telegraf） 中配置一下抓取规则，抓取本机的 http://localhost:3903/metrics 即可，然后重启 Categraf，等一会就可以在页面查到相关指标了。\n另外，mtail 的配置文件如果发生变化，是需要重启 mtail 才能生效的，或者发一个 SIGHUP 信号给 mtail，mtail 收到信号就会重新加载配置。\nmtail更多样例 # mtail 的 github repo 中有一个 examples，里边有挺多例子，大家可以参考。我在这里再给大家举一个简单例子，比如我们要统计 /var/log/messages 文件中的 Out of memory 关键字，mtail 规则应该怎么写呢？其实比上面举例的 mtail_alert_rule_notify_total 还要更简单：\ncounter mtail_oom_total /Out of memory/ { mtail_oom_total++ }  关于时间戳 # 最后说一下时间戳的问题，日志中每一行一般都是有个时间戳的，夜莺v4版本在页面上配置采集规则的时候，就是要选择时间戳的，但是 mtail，上面的例子中没有处理时间戳，为啥？其实 mtail 也可以支持从日志中提取时间戳，如果没有配置的话，就用系统当前时间，个人认为，用系统当前时间就可以了，从日志中提取时间稍微还有点麻烦，当然，系统当前时间和日志中的时间可能稍微有差别，但是不会差很多的，可以接受，examples 中的 mtail 样例，也基本都没有给出时间戳的提取。\n"}),e.add({id:19,href:"/docs/usage/esalert/",title:"ES日志告警",description:"基于夜莺快速构建日志告警平台。ElasticSearch日志告警。ElastAlert升级版。",content:"在收集到日志之后，我们通常会有下面几类基于日志做告警的需求：\n 统计日志中的 ERROR 关键字出现次数，超过阈值则发出告警； 从网关日志中提取服务接口的 QPS，出现较大波动则发出告警； 从网关日志中提取服务接口的延迟，延迟太高则发出告警；  我们可以基于夜莺的的整体流程，快速构建一个日志告警平台来满足上述的需求，本文从产品设计，架构设计，代码实现三个方面，来介绍如何基于夜莺来构建日志告警平台。为了满足大家的好奇心，我们来先看一张效果图，下图是告警历史详情页的截图。\n产品设计 # 通过前文的介绍，我们的需求已经比较明确了，将应用的日志收集起来，在平台上配置告警规则，根据配置的规则触发告警通知，收到通知之后，我们在页面上可以看到和告警数据相关的日志原文，便于快速定位问题。\n夜莺监控已经支持了告警规则配置页面和告警详情查看页面，所以我们可以直接复用这两个页面。当收到告警通知，点击到告警详情页时，夜莺目前的告警详情页只有查看时序数据的能力，没有查看日志原文的能力，所以还需要增加在详情页查看日志原文的能力。所以为了支持日志告警能力，在产品层面我们需要对夜莺的两个页面（告警规则页面、告警历史详情页面）进行改造。\n告警规则配置页面：\n历史告警页面：\n架构设计 # 产品设计确定之后，我们来进行架构设计，首先看一下夜莺已有的能力\n n9e-webapi 提供各种配置管理、即时数据查询、告警历史详情查看的能力 n9e-server 提供同步规则、查询数据、产生异常点、生成告警事件、告警屏蔽、告警订阅、告警通知的能力。  如果要增加日志告警能力，我们可以发现在产生异常点之后，n9e-server 后续的一系列能力是可以复用的，所以我们可以得到下面的架构图\n从上图我们可以发现，日志告警模块只要实现下面4个功能即可\n 同步告警规则 从日志中提取 metric 数据和原文 根据规则判断数据是否异常 异常点发送给 n9e-server  搞清楚要做什么事情之后，下面我们要开始动手写代码了\n代码实现 # 本小节主要是介绍日志告警模块代码实现的思路，我们可以开发一个独立的模块，主要是实现下面四个功能。\n同步告警规则 # 我们可以通过定期查询 n9e-webapi 提供的 api 来同步告警规则，同步逻辑可以参考 n9e-server 模块 https://github.com/ccfos/nightingale/blob/main/src/server/memsto/alert_rule_cache.go 的逻辑，将从数据库查询，改成从 api 获取即可\n日志中查询 metric 数据和原文 # Elasticsearch 提供了 bucket aggregations 和 metric aggregations 的 api，通过这两个 api ，我们可以根据查询条件查到对应的 metric 数据。通过 es 的 search api，我们可以根据查询条件查到日志原文。\n根据规则判断数据是否异常 # 这个功能可以参考 n9e-server 的告警规则判断逻辑，代码在 https://github.com/ccfos/nightingale/blob/main/src/server/engine/worker.go loopFilterRules() 定期获取规则，然后生成异常点检测任务，Work() 实现了产生异常点的功能。\n异常点发送给 n9e-server # n9e-server 提供了接收异常点然后产生告警事件的接口，产生异常点之后，我们把异常点 push 给 n9e-server 的 api 即可，之后的告警事件处理流程，全部由 n9e-server 来负责。\n最终效果 # 通过夜莺日志告警插件，我们可以在夜莺平台，实现日志场景下的监控告警体系建设。\n One more thing\n 快猫星云技术团队已经实现了夜莺日志告警这个模块，如果您在使用夜莺监控，遇到了 Metric 监控覆盖不到的场景，需要对日志进行监控告警，可以点击 链接 购买试用，目前正在打折优惠，团队版首次试用费用只需 29 元， 感兴趣的可以买起来：）\n"}),e.add({id:20,href:"/docs/usage/jvm/",title:"JVM监控",description:"如何使用 Nightingale 和 Categraf 做 JVM 监控",content:"本讲介绍JVM监控相关知识。\n进程级监控 # Java类的程序，如果只是监控端口存活性，可以直接使用 Categraf 的 net_response 插件，如果只是监控进程存活性，以及进程的CPU、内存等使用率，这个和C的程序、Go的程序没有本质区别，使用 Categraf 的 procstat 插件。\nprocstat 插件的采集配置文件中，有这么一段配置：\n# gather jvm metrics only when jstat is ready # gather_more_metrics = [ # \u0026quot;threads\u0026quot;, # \u0026quot;fd\u0026quot;, # \u0026quot;io\u0026quot;, # \u0026quot;uptime\u0026quot;, # \u0026quot;cpu\u0026quot;, # \u0026quot;mem\u0026quot;, # \u0026quot;limit\u0026quot;, # \u0026quot;jvm\u0026quot; # ]  如果打开，才能采集进程的 threads、fd、io、cpu、mem等的情况，如果不打开，只能采集到进程数量。其中 gather_more_metrics 中有一项是 jvm，如果配置了 jvm 这一项，会通过 jstat 采集一些 jvm 相关的指标，前提是机器上得有 jstat 命令可以用。\n埋点方式 # 这个方式的监控，之前社区里有小伙伴分享过，链接在这里，这里就不重复讲解了\n"}),e.add({id:21,href:"/docs/usage/notify/",title:"告警通知",description:"夜莺（ Nightingale ）告警通知渠道",content:"夜莺告警通知，内置支持邮件、钉钉机器人、企微机器人、飞书机器人多种方式作为发送通道，也支持调用自定义脚本和Webhook，给用户自定义发送通道的能力。相关配置在 webapi.conf 和 server.conf 中都有涉及。这里分别讲解。\nwebapi.conf # [[NotifyChannels]] Label = \u0026quot;邮箱\u0026quot; # do not change Key Key = \u0026quot;email\u0026quot; [[NotifyChannels]] Label = \u0026quot;钉钉机器人\u0026quot; # do not change Key Key = \u0026quot;dingtalk\u0026quot; [[NotifyChannels]] Label = \u0026quot;企微机器人\u0026quot; # do not change Key Key = \u0026quot;wecom\u0026quot; [[NotifyChannels]] Label = \u0026quot;飞书机器人\u0026quot; # do not change Key Key = \u0026quot;feishu\u0026quot; [[ContactKeys]] Label = \u0026quot;Wecom Robot Token\u0026quot; # do not change Key Key = \u0026quot;wecom_robot_token\u0026quot; [[ContactKeys]] Label = \u0026quot;Dingtalk Robot Token\u0026quot; # do not change Key Key = \u0026quot;dingtalk_robot_token\u0026quot; [[ContactKeys]] Label = \u0026quot;Feishu Robot Token\u0026quot; # do not change Key Key = \u0026quot;feishu_robot_token\u0026quot;  NotifyChannels是个数组，可以写多个，告警规则配置页面，展示的通知媒介，就是读取的这个配置文件的内容。\nContactKeys也是个数组，用于控制用户的联系方式的配置，在个人中心编辑用户信息的时候，除了手机号、邮箱，还可以为用户配置多种联系方式，多种联系方式也是可以自定义的，就是通过上面的配置来控制。\n基于上面的配置，我们可以为某个告警规则指定通知媒介了，也可以为告警接收人配置手机号、邮箱、相关的机器人Token了，具体做发送的时候就不是webapi来处理了，是server模块来处理，所以下面我们再来看server的配置。\nserver.conf # [SMTP] Host = \u0026quot;smtp.163.com\u0026quot; Port = 994 User = \u0026quot;username\u0026quot; Pass = \u0026quot;password\u0026quot; From = \u0026quot;username@163.com\u0026quot; InsecureSkipVerify = true Batch = 5 [Alerting] TemplatesDir = \u0026quot;./etc/template\u0026quot; NotifyConcurrency = 10 # use builtin go code notify NotifyBuiltinChannels = [\u0026quot;email\u0026quot;, \u0026quot;dingtalk\u0026quot;, \u0026quot;wecom\u0026quot;, \u0026quot;feishu\u0026quot;] [Alerting.CallScript] # built in sending capability in go code # so, no need enable script sender Enable = false ScriptPath = \u0026quot;./etc/script/notify.py\u0026quot; [Alerting.CallPlugin] Enable = false # use a plugin via `go build -buildmode=plugin -o notify.so` PluginPath = \u0026quot;./etc/script/notify.so\u0026quot; # The first letter must be capitalized to be exported Caller = \u0026quot;N9eCaller\u0026quot; [Alerting.RedisPub] Enable = false # complete redis key: ${ChannelPrefix} + ${Cluster} ChannelPrefix = \u0026quot;/alerts/\u0026quot; [Alerting.Webhook] Enable = false Url = \u0026quot;http://a.com/n9e/callback\u0026quot; BasicAuthUser = \u0026quot;\u0026quot; BasicAuthPass = \u0026quot;\u0026quot; Timeout = \u0026quot;5s\u0026quot; Headers = [\u0026quot;Content-Type\u0026quot;, \u0026quot;application/json\u0026quot;, \u0026quot;X-From\u0026quot;, \u0026quot;N9E\u0026quot;]  server内置支持邮件发送，所以，要配置SMTP，SMTP不会配置的自行Google。Alerting相关的配置，是告警通知相关的，夜莺不但内置支持了多种通知方式，也支持了调用外部脚本、调用外部Plugin、通过Redis做Publish、全局Webhook等多种方式，把告警消息推给外部处理逻辑，增强扩展性。\n[Alerting] TemplatesDir = \u0026quot;./etc/template\u0026quot; NotifyConcurrency = 10 # use builtin go code notify NotifyBuiltinChannels = [\u0026quot;email\u0026quot;, \u0026quot;dingtalk\u0026quot;, \u0026quot;wecom\u0026quot;, \u0026quot;feishu\u0026quot;]   TemplatesDir指定模板文件的目录，这个目录下有多个模板文件，遵从Go Template语法，可以控制告警发送的消息的格式 NotifyConcurrency 表示并发度，可以维持默认，处理不过来了，有事件堆积（事件是否堆积可以查看n9e-server的这个指标：n9e_server_alert_queue_size，通过 /metrics 接口暴露的）了再调大 NotifyBuiltinChannels 是配置Go代码内置的通知媒介，默认4个通知媒介都让Go代码来做，如果某些通知媒介想做一些自定义，可以从这个数组中删除对应的通知媒介，Go代码就不处理那个通知媒介了，自定义的通知媒介可以在后面介绍的脚本里自行处理，灵活自定义  [Alerting.CallScript] # built in sending capability in go code # so, no need enable script sender Enable = false ScriptPath = \u0026quot;./etc/script/notify.py\u0026quot;  CallScript是配置告警通知脚本的，如果没有自定义的需求，Go内置的4种发送通道 [\u0026quot;email\u0026quot;, \u0026quot;dingtalk\u0026quot;, \u0026quot;wecom\u0026quot;, \u0026quot;feishu\u0026quot;] 完全可以满足需求，这个CallScript是无需关注的，所以默认Enable=false。\n如果内置的发送逻辑搞不定了，比如想支持短信、电话等通知方式，就可以启用CallScript，夜莺发现这里的Enable=true且指定了一个脚本，就会去执行这个脚本，把告警事件的内容发给这个脚本，由这个脚本做后续处理。\n告警事件是怎么发给这个脚本的呢？系统会把告警事件的内容encode成json，然后通过stdin的方式传给notify.py。notify.py的脚本里有这么几行，大家可以看一下：\ndef main(): payload = json.load(sys.stdin) with open(\u0026quot;.payload\u0026quot;, 'w') as f: f.write(json.dumps(payload, indent=4))  逻辑很简单，脚本从stdin拿到内容，json.load了一下，把payload的内容写入了.payload文件里了。很多想自行开发notify.py的朋友，都不清楚数据结构是什么样子的，其实看一下 .payload 文件的内容就知道了，一目了然。\nnotify.py的同级目录，还有一个notify.bak.py，很多逻辑可以参考这个脚本。因为夜莺刚开始的版本发送告警只能通过脚本来做，后来才内置到go代码中的，所以，notify.bak.py里备份了很多老的逻辑，大家可以参考。\n[Alerting.CallPlugin] Enable = false # use a plugin via `go build -buildmode=plugin -o notify.so` PluginPath = \u0026quot;./etc/script/notify.so\u0026quot; # The first letter must be capitalized to be exported Caller = \u0026quot;N9eCaller\u0026quot;  CallPlugin是动态链接库的方式加载外部逻辑，有个小文档可以参考：这里 非Go玩家，就不建议了解了，Go玩家，我就不用讲你也应该会了。\n[Alerting.RedisPub] Enable = false # complete redis key: ${ChannelPrefix} + ${Cluster} ChannelPrefix = \u0026quot;/alerts/\u0026quot;  这个配置如果开启，n9e-server会把生成的告警事件publish给redis，如果用户有自定义的逻辑，可以去subscribe，然后自行处理。\n[Alerting.Webhook] Enable = false Url = \u0026quot;http://a.com/n9e/callback\u0026quot; BasicAuthUser = \u0026quot;\u0026quot; BasicAuthPass = \u0026quot;\u0026quot; Timeout = \u0026quot;5s\u0026quot; Headers = [\u0026quot;Content-Type\u0026quot;, \u0026quot;application/json\u0026quot;, \u0026quot;X-From\u0026quot;, \u0026quot;N9E\u0026quot;]  这是全局Webhook，如果启用，n9e-server生成告警事件之后，就会回调这个Url，对接一些第三方系统。告警事件的内容会encode成json，放到HTTP request body中，POST给这个Url，也可以自定义Header，即Headers配置，Headers是个数组，必须是偶数个，Key1, Value1, Key2, Value2 这个写法。\n"}),e.add({id:22,href:"/docs/usage/format/",title:"告警格式",description:"夜莺（ Nightingale ）告警通知消息的内容格式",content:"告警事件的消息通知格式，是由模板控制的，模板文件在 etc/template 下：\n dingtalk.tpl 钉钉的消息模板 feishu.tpl 飞书的消息模板 wecom.tpl 企业微信的消息模板 subject.tpl 邮件标题模板 mailbody.tpl 邮件内容模板  这些模板文件都遵从 go template 语法，模板中可以引用变量，有哪些变量可以引用呢？可以参考 AlertCurEvent 结构，这个结构的各个字段都可以被引用。\n需求：如何自定义展示标签 # 告警事件中一般会有多个标签，模板文件中这个写法 {{.TagsJSON}} 可以按照数组的方式展示所有的标签。对于Kubernetes体系的监控数据，有的时候标签会非常非常多，看起来很费劲，有些朋友就会想，我是否可以自定义，只展示部分标签呢？\n答案当然是可以的。TagsJSON 是所有标签的数组形式，TagsMap是所有标签的map形式，我们可以使用TagsMap来方便的获取特定的标签值，比如我这里修改企微的模板文件，不展示所有的标签：\n**级别状态**: {{if .IsRecovered}}\u0026lt;font color=\u0026quot;info\u0026quot;\u0026gt;S{{.Severity}} Recovered\u0026lt;/font\u0026gt;{{else}}\u0026lt;font color=\u0026quot;warning\u0026quot;\u0026gt;S{{.Severity}} Triggered\u0026lt;/font\u0026gt;{{end}} **规则标题**: {{.RuleName}}{{if .RuleNote}} **规则备注**: {{.RuleNote}}{{end}} **监控指标**: {{$metric := index .TagsMap \u0026quot;__name__\u0026quot;}}{{if eq \u0026quot;disk_used_percent\u0026quot; $metric}}机器：{{index .TagsMap \u0026quot;ident\u0026quot;}} 分区：{{index .TagsMap \u0026quot;path\u0026quot;}}{{else}}{{.TagsJSON}}{{end}} {{if .IsRecovered}}**恢复时间**：{{timeformat .LastEvalTime}}{{else}}**触发时间**: {{timeformat .TriggerTime}} **触发时值**: {{.TriggerValue}}{{end}} **发送时间**: {{timestamp}}  注意上面监控指标那一行，先从TagsMap中拿到 __name__ 对应的标签值，就是 $metric，然后判断 $metric 是否是磁盘利用率，如果是就只展示ident标签的内容和path标签的内容，如果不是，就还是按照老样子，把TagsJSON全部展示出来。\n但是，这种方式每次都要修改模板文件，太麻烦了。实际上，告警规则的备注也是支持模板语法的，我们可以利用这个特性做自定义。\n使用模板语法自定义规则备注 # 这里的思路是：我们利用模板语法自定义规则备注，在规则备注里加一个特殊的前缀，在tpl文件里做判断，如果发现有这个前缀，就不展示TagsJSON，如果没有这个前缀，就还是展示TagsJSON。\n配置告警规则时，规则备注配置成如下：\n; ident={{$labels.ident}} path={{$labels.path}}  加了一个分号做前缀。然后wecom.tpl如下定义：\n**级别状态**: {{if .IsRecovered}}\u0026lt;font color=\u0026quot;info\u0026quot;\u0026gt;S{{.Severity}} Recovered\u0026lt;/font\u0026gt;{{else}}\u0026lt;font color=\u0026quot;warning\u0026quot;\u0026gt;S{{.Severity}} Triggered\u0026lt;/font\u0026gt;{{end}} **规则标题**: {{.RuleName}}{{if .RuleNote}} **规则备注**: {{.RuleNote}}{{end}}{{$iscustom := match \u0026quot;^;\u0026quot; .RuleNote}}{{if not $iscustom}} **监控指标**: {{.TagsJSON}}{{end}} {{if .IsRecovered}}**恢复时间**：{{timeformat .LastEvalTime}}{{else}}**触发时间**: {{timeformat .TriggerTime}} **触发时值**: {{.TriggerValue}}{{end}} **发送时间**: {{timestamp}}  上面逻辑是，判断RuleNote的内容，如果以分号开头（用正则匹配），表示这是特殊前缀，此时就不展示TagsJSON了，如果不是这个前缀，就展示TagsJSON。\n注意 # 以上效果的达成，需要夜莺后端版本在 5.9.6 以上。\n"}),e.add({id:23,href:"/docs/usage/aialert/",title:"智能异常检测",description:"夜莺智能异常检测。AIOps在夜莺中的实践。使用机器学习的方法做告警",content:"时序数据异常检测简介 # 对于所有的在线业务，都会随着时间产生一些数据，这些数据我们称为时序数据，在服务正常的时候，这些时序数据的变化会符合一定的模式，我们可以根据这些时序数据的变化，来判断我们服务是否出现了异常。业内目前主要有三个方式来判断时序数据是否异常：\n 第一种是有值班人员实时盯着重要的时序数据，根据经验来判断时序数据是否出现了异常 第二种是使用监控产品，给关注的时序数据配置一个静态的阈值，如果超过阈值就表示时序数据出现异常 第三种是近几年出现的新的方式，使用机器学习的能力，动态学习时序数据的规律，实时计算动态的阈值，识别是否异常。  目前业界主流的方式是使用配置静态阈值来判断，但随着业务发展，这个方式也开始出现一些问题，下面介绍下传统静态阈值告警遇到的问题。\n静态阈值可能遇到的问题 # 01.静态阈值覆盖场景有限，业务类监控数据不适用 # 业务类监控数据，使用静态阈值很多情况下不能很好的标识是否异常，比如下图的曲线，常见的业务数据都有这些特点，峰值和谷值差距很大，如果上限阈值配置是600，下降阈值配置10，那图中红圈标记的异常就会出现漏报。\n02.阈值会由于特殊日或业务发展产生变化 # 业务监控指标经常会由于 “特殊日”（节假日、营销活动日）或者业务发展影响而产生变化，传统的静态阈值或同环比策略在这种场景下，会产生多次误报，给负责稳定性的同学造成不必要的打扰，像下图的情况，紫色曲线是当天的监控数据同比1天和7天都低很多，但属于正常情况，这个在静态阈值的同环比策略下则会发出误报。\n03.传统静态阈值的设置，依赖专家经验，人力维护成本高 # 下图是静态阈值告警配置常见的流程，经过几轮调整之后，才可正常使用，而随着业务增长，仍然需要不定期调整阈值，人力维护成本高。\n智能异常检测的优势 # 智能异常检测基于机器学习算法模型实时生成动态基线，可以有效避免传统阈值方式造成的误报问题，也摆脱了对专家经验的依赖，提升了告警准确率，也提升了值班同学的幸福感：）\n下图是智能异常算法实时计算出来的动态基线，会随着业务增长动态变化\n下图总结了静态阈值和智能算法的区别：\n哪些场景适合智能异常检测？ # 智能异常检测相比静态阈值的规则，有很多优势，对于有周期性的时序数据尤其合适，以下列举了一些常见的场景：\n 网页浏览量 活跃用户数 应用下载量 购物下单量 证券交易量 打车呼叫量 \u0026hellip;\u0026hellip;  前面介绍了智能异常检测的优势和适用场景，那如何落地呢？下面介绍下夜莺的落地方案。\n夜莺的智能告警落地方案 # 如果之前使用了夜莺，再部署一个智能异常检测模块即可，可以和开源的夜莺监控无缝集成，整体架构如下图\n智能异常检测模块完成安装之后，在夜莺告警规则配置页面，会多出一个智能告警的选项，如下图所示：\n选择智能告警之后，只需填写要监控的指标，不需要填写阈值，点击保存即可，之后在告警规则列表页，智能告警的规则右侧会有一个“训练结果”的按钮\n点击“训练结果”，可以进入训练结果详情页，点击曲线详情，可以看到曲线学习出来的动态基线。如果曲线偏离到基线之外，夜莺的告警引擎会发出告警通知。\n自建还是购买？ # 从成本角度来看 # 如果你们团队已经有了算法团队+研发团队，可以让两个团队根据业界已有方案来落地实施。如果没有算法或者研发团队，招一个能把智能异常检测落地的工程师的成本至少是20W，夜莺的智能告警企业版，一年只有1W+，在这个情况下购买智能告警服务，显然是更划算的。\n从工作幸福感来看 # 如果你在运维的一线，且经常被静态阈值的误报打扰，建议推动团队尽快开启智能异常检测功能，如果团队没有这方面积累，可以购买夜莺的智能告警服务，减少日常生活中误报对自己的打扰。\n如果对夜莺的智能异常检测服务感兴趣，欢迎点击 链接 购买试用，购买之后，将您的订单号和联系方式发送邮件到 n9e@flashcat.cloud, 我们后面会联系您，目前正在打折优惠，团队版首月试用费用只需 29 元， 感兴趣的可以买起来：）\n"}),e.add({id:24,href:"/docs/api/read/",title:"数据读取",description:"读取夜莺Nightingale的监控数据",content:"夜莺把接收到的监控数据都直接写入了后端时序数据库，所以，读取监控数据，无需经由夜莺的接口，直接读取后端的时序库的接口就可以了。即：如果使用了 Prometheus，就通过 Prometheus 的接口读取监控数据，如果用了 VictoriaMetrics，就通过 VictoriaMetrics 的接口读取监控数据。\n比如 Prometheus，就是那些/api/v1/query /api/v1/query_range之类的接口。相关接口文档请参考：Prometheus官网\n"}),e.add({id:25,href:"/docs/api/push/",title:"数据推送",description:"如何把自定义监控数据推送给夜莺Nightingale",content:"在 采集器 章节可以看出，夜莺支持多种数据接收的接口（由 n9e-server 实现，推送数据就是推给 n9e-server 的 19000 端口），包括 OpenTSDB、Open-Falcon、RemoteWrite、Datadog 等协议。这节我们以 OpenTSDB 的数据接收接口举例。\nOpenTSDB 协议 # OpenTSDB 的数据接收接口的 Url Path 是 /opentsdb/put ，POST 方法，监控数据做成 JSON 放到 HTTP Request Body 中，举例：\n[ { \u0026quot;metric\u0026quot;: \u0026quot;cpu_usage_idle\u0026quot;, \u0026quot;timestamp\u0026quot;: 1637732157, \u0026quot;tags\u0026quot;: { \u0026quot;cpu\u0026quot;: \u0026quot;cpu-total\u0026quot;, \u0026quot;ident\u0026quot;: \u0026quot;c3-ceph01.bj\u0026quot; }, \u0026quot;value\u0026quot;: 30.5 }, { \u0026quot;metric\u0026quot;: \u0026quot;cpu_usage_util\u0026quot;, \u0026quot;timestamp\u0026quot;: 1637732157, \u0026quot;tags\u0026quot;: { \u0026quot;cpu\u0026quot;: \u0026quot;cpu-total\u0026quot;, \u0026quot;ident\u0026quot;: \u0026quot;c3-ceph01.bj\u0026quot; }, \u0026quot;value\u0026quot;: 69.5 } ]  显然，JSON 最外层是个数组，如果只上报一条监控数据，也可以不要外面的中括号，直接把对象结构上报：\n{ \u0026quot;metric\u0026quot;: \u0026quot;cpu_usage_idle\u0026quot;, \u0026quot;timestamp\u0026quot;: 1637732157, \u0026quot;tags\u0026quot;: { \u0026quot;cpu\u0026quot;: \u0026quot;cpu-total\u0026quot;, \u0026quot;ident\u0026quot;: \u0026quot;c3-ceph01.bj\u0026quot; }, \u0026quot;value\u0026quot;: 30.5 }  服务端会看第一个字符是否是[，来判断上报的是数组，还是单个对象，自动做相应的 Decode。如果觉得上报的内容太过占用带宽，也可以做 gzip 压缩，此时上报的数据，要带有Content-Encoding: gzip的 Header。\n💡  注意 ident 这个标签，ident 是 identity 的缩写，表示设备的唯一标识，如果标签中有 ident 标签，n9e-server 就认为这个监控数据是来自某个机器的，会自动获取 ident 的 value，注册到监控对象的列表里   RemoteWrite 协议 # 除了 OpenTSDB 协议，另一个比较常用的是 RemoteWrite 协议，Categraf、Grafana-Agent 写数据给 n9e-server 都是走的 RemoteWrite 协议，接口地址是 /prometheus/v1/write。\n推给客户端 # 除了把监控数据推给 n9e-server 之外，还可以把监控数据通过接口推给 Categraf，Categraf 再推给 n9e-server，我们也更推荐这种方式。Categraf 支持四类推送方式，代码在这里\n /api/push/opentsdb 走的是 OpenTSDB 的传输协议 /api/push/openfalcon 走的是 Open-Falcon 的传输协议 /api/push/remotewrite 走的是 Prometheus RemoteWrite 的传输协议，使用 Protobuf 编码 /api/push/pushgateway 走的是 Prometheus Pushgateway 的传输协议，文本的传输协议  这些接口都是走的HTTP协议，如果要走通，需要启用Categraf的http配置段，把http.enable设置为true，默认监听的端口是 9100\n"}),e.add({id:26,href:"/docs/api/webapi/",title:"Webapi接口",description:"调用夜莺Nightingale的Webapi接口",content:"简介 # n9e-webapi 模块提供了两类接口，一个是 /api/n9e 打头的，给前端调用，另一类是 /v1/n9e 打头的，给第三方系统调用。如果想以个人身份模仿WEB操作，也是调用 /api/n9e 相关接口。\n以个人身份模仿WEB操作 # 这种方式，页面上 JavaScript 可以调用的所有接口，你都可以用程序调用，打开 chrome 的开发者工具，扒拉这些接口，还是非常容易的。当然，要先登录，登录调用 webapi 模块的 /api/n9e/auth/login 接口，系统使用 jwt 认证，如果登录成功，会返回 access_token 和 refresh_token，每次调用的时候都要把 access_token 放到 Header 里，access_token 差不多15分钟过期，之后可以重新调用登录接口换 token，也可以调用 /api/n9e/auth/refresh 接口用 refresh_token 换一个新的 access_token，当然，也会顺道返回一个新的 refresh_token，举例：\n# 调用登录接口拿到access_token和refresh_token记录下来，后面调用其他接口的时候会用到 [root@10-255-0-34 ~]# curl -X POST 'http://localhost:18000/api/n9e/auth/login' -d '{\u0026quot;username\u0026quot;: \u0026quot;root\u0026quot;, \u0026quot;password\u0026quot;: \u0026quot;root.2020\u0026quot;}' {\u0026quot;dat\u0026quot;:{\u0026quot;access_token\u0026quot;:\u0026quot;eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhY2Nlc3NfdXVpZCI6ImIxNTcyMjgwLWZlNzAtNDhjZi1hNDQ3LWVlMjVhZmYwMjRhZCIsImF1dGhvcml6ZWQiOnRydWUsImV4cCI6MTYzNzgyMzA1OSwidXNlcl9pZGVudGl0eSI6IjEtcm9vdCJ9.nJ56Pc7qS5Ik_UaVmlNWu_QlABaBc4pZ_WkU45u2wWk\u0026quot;,\u0026quot;refresh_token\u0026quot;:\u0026quot;eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJleHAiOjE2MzgzMzc4NTksInJlZnJlc2hfdXVpZCI6ImIxNTcyMjgwLWZlNzAtNDhjZi1hNDQ3LWVlMjVhZmYwMjRhZCsrMS1yb290IiwidXNlcl9pZGVudGl0eSI6IjEtcm9vdCJ9.JKsbfTYBCOOfR_oPsf496N9ml9yXbP7BHb4E8Yfnzbo\u0026quot;,\u0026quot;user\u0026quot;:{\u0026quot;id\u0026quot;:1,\u0026quot;username\u0026quot;:\u0026quot;root\u0026quot;,\u0026quot;nickname\u0026quot;:\u0026quot;超管\u0026quot;,\u0026quot;phone\u0026quot;:\u0026quot;\u0026quot;,\u0026quot;email\u0026quot;:\u0026quot;\u0026quot;,\u0026quot;portrait\u0026quot;:\u0026quot;\u0026quot;,\u0026quot;roles\u0026quot;:[\u0026quot;Admin\u0026quot;],\u0026quot;contacts\u0026quot;:{},\u0026quot;create_at\u0026quot;:1637545881,\u0026quot;create_by\u0026quot;:\u0026quot;system\u0026quot;,\u0026quot;update_at\u0026quot;:1637546351,\u0026quot;update_by\u0026quot;:\u0026quot;root\u0026quot;,\u0026quot;admin\u0026quot;:true}},\u0026quot;err\u0026quot;:\u0026quot;\u0026quot;} # access_token放到Authorization这个Header里，Bearer的验证方式 [root@10-255-0-34 ~]# curl -H \u0026quot;Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhY2Nlc3NfdXVpZCI6ImIxNTcyMjgwLWZlNzAtNDhjZi1hNDQ3LWVlMjVhZmYwMjRhZCIsImF1dGhvcml6ZWQiOnRydWUsImV4cCI6MTYzNzgyMzA1OSwidXNlcl9pZGVudGl0eSI6IjEtcm9vdCJ9.nJ56Pc7qS5Ik_UaVmlNWu_QlABaBc4pZ_WkU45u2wWk\u0026quot; 'http://localhost:18000/api/n9e/self/profile' {\u0026quot;dat\u0026quot;:{\u0026quot;id\u0026quot;:1,\u0026quot;username\u0026quot;:\u0026quot;root\u0026quot;,\u0026quot;nickname\u0026quot;:\u0026quot;超管\u0026quot;,\u0026quot;phone\u0026quot;:\u0026quot;\u0026quot;,\u0026quot;email\u0026quot;:\u0026quot;\u0026quot;,\u0026quot;portrait\u0026quot;:\u0026quot;\u0026quot;,\u0026quot;roles\u0026quot;:[\u0026quot;Admin\u0026quot;],\u0026quot;contacts\u0026quot;:{},\u0026quot;create_at\u0026quot;:1637545881,\u0026quot;create_by\u0026quot;:\u0026quot;system\u0026quot;,\u0026quot;update_at\u0026quot;:1637546351,\u0026quot;update_by\u0026quot;:\u0026quot;root\u0026quot;,\u0026quot;admin\u0026quot;:true},\u0026quot;err\u0026quot;:\u0026quot;\u0026quot;} # 如果token过期了，后端会返回异常HTTP状态码，此时要调用refresh接口换取新的token [root@10-255-0-34 ~]# curl -X POST 'http://localhost:18000/api/n9e/auth/refresh' -d '{\u0026quot;refresh_token\u0026quot;: \u0026quot;eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJleHAiOjE2MzgzMzc4NTksInJlZnJlc2hfdXVpZCI6ImIxNTcyMjgwLWZlNzAtNDhjZi1hNDQ3LWVlMjVhZmYwMjRhZCsrMS1yb290IiwidXNlcl9pZGVudGl0eSI6IjEtcm9vdCJ9.JKsbfTYBCOOfR_oPsf496N9ml9yXbP7BHb4E8Yfnzbo\u0026quot;}' {\u0026quot;dat\u0026quot;:{\u0026quot;access_token\u0026quot;:\u0026quot;eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhY2Nlc3NfdXVpZCI6IjAxMzkzYzkxLTk5MWItNGE0Yi04ODk2LTJhZGRjMDUwYjcxMCIsImF1dGhvcml6ZWQiOnRydWUsImV4cCI6MTYzNzgyMzMxOCwidXNlcl9pZGVudGl0eSI6IjEtcm9vdCJ9.2BeWyYfcnRi3qw69zecaaeFnPFUNAGsiPIZBBnd5lug\u0026quot;,\u0026quot;refresh_token\u0026quot;:\u0026quot;eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJleHAiOjE2MzgzMzgxMTgsInJlZnJlc2hfdXVpZCI6IjAxMzkzYzkxLTk5MWItNGE0Yi04ODk2LTJhZGRjMDUwYjcxMCsrMS1yb290IiwidXNlcl9pZGVudGl0eSI6IjEtcm9vdCJ9.zFZaRYcJI6G5maSgDVF-jZzxQ3Tb5dybIqufJhBy034\u0026quot;},\u0026quot;err\u0026quot;:\u0026quot;\u0026quot;}  第三方系统调用夜莺 # 比如第三方系统想获取夜莺中的所有未恢复告警，或者获取夜莺中的全量用户列表，这些需求，建议走 /v1/n9e 打头的接口，这些接口走 BasicAuth 认证，BasicAuth 的用户名和密码在 webapi.conf 中可以找到，就是 BasicAuth 那个 section 的配置。当前这个阶段，/v1/n9e 前缀的接口还比较少，不过代码框架已经搭起来了，代码在 src/webapi/router/router.go 文件中，如果贵司要封装夜莺的接口，可能要在这个路由分组下加一些路由配置了，欢迎大家 PR。\n"}),e.add({id:27,href:"/docs/appendix/grafana-agent/grafana-agent-overview/",title:"总览",description:"Acknowledgement: Grafana Agent is a lightweight telemetry collector based on Prometheus that only performs its scraping and remote_write functions. Agent can also collect metrics, logs, and traces for storage in Grafana Cloud and Grafana Enterprise, as well as OSS deployments of Loki (logs), and Tempo (traces), Prometheus (metrics), and Cortex (metrics). Grafana Agent also contains several integrations (embedded metrics exporters) like node-exporter, a MySQL exporter, and many more.\n 如果您使用和管理着Kubernetes集群以及您的应用运行在Kubernetes之上，请参考 在K8s中使用grafana-agent。",content:" Acknowledgement: Grafana Agent is a lightweight telemetry collector based on Prometheus that only performs its scraping and remote_write functions. Agent can also collect metrics, logs, and traces for storage in Grafana Cloud and Grafana Enterprise, as well as OSS deployments of Loki (logs), and Tempo (traces), Prometheus (metrics), and Cortex (metrics). Grafana Agent also contains several integrations (embedded metrics exporters) like node-exporter, a MySQL exporter, and many more.\n 如果您使用和管理着Kubernetes集群以及您的应用运行在Kubernetes之上，请参考 在K8s中使用grafana-agent。\n在Windows环境安装和运行grafana-agent #  从Grafana github releases下载Windows安装文件； 运行安装文件后，会对grafana-agent进行配置，并注册为Windows服务； 更详细的配置文档，可以参考Windows Guide；  在Docker中运行grafana-agent # 如果您的宿主机上运行有docker服务，那么使用docker运行grafana-agent 是最快捷的方式。在命令行终端运行以下命令，即可在容器中启动grafana-agent：\n1. 生成 grafana-agent 的配置文件 # cat \u0026lt;\u0026lt;EOF \u0026gt; /tmp/grafana-agent-config.yaml server: log_level: info http_listen_port: 12345 metrics: global: scrape_interval: 15s scrape_timeout: 10s configs: - name: flashtest host_filter: false scrape_configs: - job_name: local_scrape static_configs: - targets: ['127.0.0.1:12345'] labels: cluster: 'mymac' remote_write: - url: https://n9e-server:19000/prometheus/v1/write basic_auth: username: \u0026lt;string\u0026gt; password: \u0026lt;string\u0026gt; EOF  2. 启动 grafana-agent 容器 # docker run \\ -v /tmp/agent:/etc/agent/data \\ -v /tmp/grafana-agent-config.yaml:/etc/agent/agent.yaml \\ -p 12345:12345 \\ -d \\ grafana/agent:v0.23.0 \\ --config.file=/etc/agent/agent.yaml \\ --prometheus.wal-directory=/etc/agent/data  或者您也可以从 Dockerfile 在本地 build 镜像之后再运行：\ncurl -sO https://raw.githubusercontent.com/grafana/agent/main/cmd/agent/Dockerfile docker build -t grafana/agent:v0.23.0 -f ./Dockerfile  上述步骤中，几个需要注意的点：\n remote_write 和 basic_auth ，请根据自己的实际情况填写； -p 把容器中的端口12345映射到主机，-d 把容器进程放到后台运行； -v /tmp/agent:/etc/agent/data 是把宿主机的目录 /tmp/agent 映射到容器中 /etc/agent/data，用于 grafana-agent 持久化保存其 WAL(Write Ahead Log) ； -v /tmp/grafana-agent-config.yaml:/etc/agent/agent.yaml 是把 grafana-agent 的配置文件，放置到容器指定的位置，即 /etc/agent/agent.yaml  3. 验证 grafana-agent 是否正常工作 # 您可以通过直接 curl http://localhost:12345/metrics 来验证数据的产生是否符合预期，正常情况下会显示如下：\nagent_build_info{branch=\u0026quot;HEAD\u0026quot;,goversion=\u0026quot;go1.17.6\u0026quot;,revision=\u0026quot;36b8ca75\u0026quot;,version=\u0026quot;v0.23.0\u0026quot;} 1 agent_inflight_requests{method=\u0026quot;GET\u0026quot;,route=\u0026quot;metrics\u0026quot;} 1 agent_metrics_active_configs 1 agent_metrics_active_instances 1 agent_tcp_connections{protocol=\u0026quot;grpc\u0026quot;} 0 agent_tcp_connections{protocol=\u0026quot;http\u0026quot;} 2 go_gc_duration_seconds_sum 0.0040902 go_gc_duration_seconds_count 6 go_goroutines 50 log_messages_total{level=\u0026quot;debug\u0026quot;} 44 log_messages_total{level=\u0026quot;error\u0026quot;} 0 log_messages_total{level=\u0026quot;info\u0026quot;} 13 log_messages_total{level=\u0026quot;warn\u0026quot;} 0 loki_logql_querystats_duplicates_total 0 loki_logql_querystats_ingester_sent_lines_total 0 net_conntrack_dialer_conn_attempted_total{dialer_name=\u0026quot;local_scrape\u0026quot;} 1 net_conntrack_dialer_conn_attempted_total{dialer_name=\u0026quot;remote_storage_write_client\u0026quot;} 1 net_conntrack_dialer_conn_closed_total{dialer_name=\u0026quot;local_scrape\u0026quot;} 0 net_conntrack_dialer_conn_closed_total{dialer_name=\u0026quot;remote_storage_write_client\u0026quot;} 0 net_conntrack_dialer_conn_established_total{dialer_name=\u0026quot;local_scrape\u0026quot;} 1 net_conntrack_dialer_conn_established_total{dialer_name=\u0026quot;remote_storage_write_client\u0026quot;} 1 process_cpu_seconds_total 11.53 process_max_fds 1.048576e+06 process_open_fds 17 process_resident_memory_bytes 9.4773248e+07 process_start_time_seconds 1.64499076013e+09 process_virtual_memory_bytes 1.356931072e+09 process_virtual_memory_max_bytes 1.8446744073709552e+19 prometheus_interner_num_strings 275 prometheus_interner_string_interner_zero_reference_releases_total 0 prometheus_sd_consulagent_rpc_duration_seconds_sum{call=\u0026quot;services\u0026quot;,endpoint=\u0026quot;agent\u0026quot;} 0 prometheus_sd_consulagent_rpc_duration_seconds_count{call=\u0026quot;services\u0026quot;,endpoint=\u0026quot;agent\u0026quot;} 0 prometheus_sd_consulagent_rpc_failures_total 0 prometheus_sd_dns_lookup_failures_total 0 prometheus_sd_dns_lookups_total 0 prometheus_sd_file_read_errors_total 0 prometheus_sd_file_scan_duration_seconds{quantile=\u0026quot;0.5\u0026quot;} NaN ...  您也可以通过访问 grafana-agent 所暴露的 API，获取到 targets 列表来确认是否符合预期：\ncurl http://localhost:12345/agent/api/v1/targets |jq { \u0026quot;status\u0026quot;: \u0026quot;success\u0026quot;, \u0026quot;data\u0026quot;: [ { \u0026quot;instance\u0026quot;: \u0026quot;7f383657f506f53a739e2df61be58891\u0026quot;, \u0026quot;target_group\u0026quot;: \u0026quot;local_scrape\u0026quot;, \u0026quot;endpoint\u0026quot;: \u0026quot;http://127.0.0.1:12345/metrics\u0026quot;, \u0026quot;state\u0026quot;: \u0026quot;up\u0026quot;, \u0026quot;labels\u0026quot;: { \u0026quot;cluster\u0026quot;: \u0026quot;mymac\u0026quot;, \u0026quot;instance\u0026quot;: \u0026quot;127.0.0.1:12345\u0026quot;, \u0026quot;job\u0026quot;: \u0026quot;local_scrape\u0026quot; }, \u0026quot;discovered_labels\u0026quot;: { \u0026quot;__address__\u0026quot;: \u0026quot;127.0.0.1:12345\u0026quot;, \u0026quot;__metrics_path__\u0026quot;: \u0026quot;/metrics\u0026quot;, \u0026quot;__scheme__\u0026quot;: \u0026quot;http\u0026quot;, \u0026quot;__scrape_interval__\u0026quot;: \u0026quot;15s\u0026quot;, \u0026quot;__scrape_timeout__\u0026quot;: \u0026quot;10s\u0026quot;, \u0026quot;cluster\u0026quot;: \u0026quot;mymac\u0026quot;, \u0026quot;job\u0026quot;: \u0026quot;local_scrape\u0026quot; }, \u0026quot;last_scrape\u0026quot;: \u0026quot;2022-02-16T07:18:55.6221085Z\u0026quot;, \u0026quot;scrape_duration_ms\u0026quot;: 6, \u0026quot;scrape_error\u0026quot;: \u0026quot;\u0026quot; } ] }  在本机安装运行grafana-agent # 如果您的主机上没有docker或者您希望直接把grafana-agent运行在宿主机上，可以依照以下步骤：\n1. 下载预先编译好的二进制包 # 下载地址为: https://github.com/grafana/agent/releases/download/${version}/agent-${platform}-${arch}.zip\n 其中，version当前为v0.23.0 其中，可下载的platform和arch列表如下：  linux/amd64 linux/arm64 linux/armv7 linux/armv6 darwin/amd64 darwin/arm64 windows/amd64 linux/mipsle freebsd/amd64    比如，我们现在的操作系统为Linux，架构为Amd64， 那么grafana-agent的二进制包下载命令如下：\n# download the binary curl -SOL \u0026quot;https://github.com/grafana/agent/releases/download/v0.23.0/agent-linux-amd64.zip\u0026quot; # extract the binary gunzip ./agent-linux-amd64.zip # make sure it is executable chmod a+x \u0026quot;agent-linux-amd64\u0026quot;  2. 生成 grafana-agent 的配置文件 # cat \u0026lt;\u0026lt;EOF \u0026gt; ./agent-cfg.yaml server: log_level: info http_listen_port: 12345 metrics: global: scrape_interval: 15s scrape_timeout: 10s remote_write: - url: https://n9e-server:19000/prometheus/v1/write basic_auth: username: \u0026lt;string\u0026gt; password: \u0026lt;string\u0026gt; integrations: agent: enabled: true node_exporter: enabled: true include_exporter_metrics: true EOF  3. 启动 grafana-agent # nohup ./agent-linux-amd64 \\ -config.file ./agent-cfg.yaml \\ -metrics.wal-directory ./data \\ \u0026amp;\u0026gt; grafana-agent.log \u0026amp;  4. 验证 grafana-agent 是否正常工作 #  您可以通过直接 curl http://localhost:12345/metrics 来验证数据的产生是否符合预期； 您也可以通过访问 grafana-agent 所暴露的 API ，获取到 targets 列表来确认是否符合预期，操作命令为 curl http://localhost:12345/agent/api/v1/targets；  至此，我们已经成功的将 grafana-agent 运行起来，并且开始收集 grafana-agent 自身的 metrics 指标。下一步，我们讲述如何通过 grafana-agent 的内嵌的各种 exporter 来采集主机、进程、MySQL等监控指标。\n"}),e.add({id:28,href:"/docs/appendix/usecase/a-startup-way-to-building-monitoring-system/",title:"高科技Startup构建监控体系之路",description:"夜莺监控集成Grafana、Loki、Prometheus",content:" 前言 监控搭建  夜莺搭建 主机监控安装 BlackBox Exporter Mysqld Exporter consul + consul-template 动态生成配置  安装 Consul 安装Consul-template 配置Consul K/V 动态生成URL监控   修改Promtheus配置   日志监控搭建 告警规则配置  系统运维  CPU利用率 \u0026gt; 90 Innode 利用率\u0026gt;90 sshd 服务挂了 内存利用率 \u0026gt; 95 文件句柄 \u0026gt; 90 IO wait \u0026gt; 30% 过去一分钟IOutil \u0026gt; 80 Ping \u0026gt; 1s 平均负载\u0026gt;2 TCP重传率\u0026gt;5% 磁盘利用率 \u0026gt; 85% 节点重启   业务运维  一分钟内日志ERROR\u0026gt;10 URL探测不通 过去一分钟出现Panic   数据库运维  数据库重启 连接数超过80% 最近一分钟有慢查询       贝联珠贯科技, 一家ToB科技公司，定位于帮助客户大幅提升利用率，从而显著降低IT机器投入。\n 前言 # 公司当前机器总数100台左右, 没有监控, 总是在机器挂了才知道. 业务问题也只能依靠测试报障. 因为内部涉及多个K8s集群. 每个环境有独立的监控,日志收集系统, 所以需要一个All IN ONE的运维监控系统.\n尝试过Grafana+ Mimir + Loki的方式.二次开发成本过大, 并且短期内不能有效告警. 遂放弃. 接着尝试夜莺V5.\n通过夜莺监控，免去了我们对告警通知的开发成本, 传统的 Grafana 或者 Alertmanager, 都需要二次对接自己的IM. 而夜莺支持了业务组或者部门的功能, 我们就可以利用这些功能做到告警细化, 并不需要再次对接IM平台. 并且有着更详细、易用的告警配置. 可以做到开箱即用, 学习成本近乎为零。\n以下是实践过程，会从系统运维,业务运维,数据库运维等几个方面来进行监控系统搭建.\n监控搭建 # 夜莺搭建 #  https://github.com/ccfos/nightingale\n 这里选用最简单的Docker Compose 方式创建夜莺. 正如文档所说如果不是Docker专家, 不建议以这样的形式创建.   启动命令如下所示.\ngit clone https://gitlink.org.cn/ccfos/nightingale.git cd nightingale/docker docker compose up -d  服务启动之后，浏览器访问nwebapi的端口，即18000，默认用户是root，密码是root.2020\n主机监控安装 # 这里的主机监控agent 选用的grafana-agent, grafana-agent 集成了绝大部分会使用到的exporter, 做到了All IN ONE.\n并且支持Push 模式,简化流程, 这样在流程上只需要在主机启动时,预装grafana-agent, 由grafana-agent主动Push 到中心即可.\n安装脚本如下所示:\n 这个脚本有如下几个注意点:\n  remote_write 地址要根据自己部署夜莺的地址修改,将x.x.x.x更换为自己的IP即可\n  $_hostip: 这个建议写为主机IP, 因为对运维来说IP才是最直观的数据\n   function InstallMonitor(){ [ ! -f /usr/local/bin/grafana-agent ] \u0026amp;\u0026amp; wget -O /usr/local/bin/grafana-agent https://lcc-init.oss-cn-hangzhou-internal.aliyuncs.com/grafana-agent chmod +x /usr/local/bin/grafana-agent mkdir -p /metrics /etc/grafana-agent cat \u0026gt;/etc/systemd/system/grafana-agent.service \u0026lt;\u0026lt;EOF [Unit] Description=\u0026quot;grafana-agent\u0026quot; After=network.target [Service] Type=simple ExecStart=/usr/local/bin/grafana-agent -config.file /etc/grafana-agent/grafana-agent.yml WorkingDirectory=/usr/local/bin SuccessExitStatus=0 LimitNOFILE=65536 StandardOutput=syslog StandardError=syslog SyslogIdentifier=grafana-agent KillMode=process KillSignal=SIGQUIT TimeoutStopSec=5 Restart=always [Install] WantedBy=multi-user.target EOF chmod 0644 /etc/systemd/system/grafana-agent.service cat \u0026gt;/etc/grafana-agent/grafana-agent.yml \u0026lt;\u0026lt;EOF server: log_level: info http_listen_port: 12345 metrics: wal_directory: /metrics global: scrape_interval: 15s scrape_timeout: 10s remote_write: # 远程写入的地址需要根据云上云下环境来切换. - url: http://x.x.x.x:19000/prometheus/v1/write integrations: agent: enabled: true node_exporter: enabled: true instance: \u0026quot;$_hostip\u0026quot; include_exporter_metrics: true process_exporter: enabled: true instance: \u0026quot;$_hostip\u0026quot; process_names: - name: \u0026quot;{{.Comm}}\u0026quot; cmdline: - '.+' EOF systemctl daemon-reload systemctl enable --now grafana-agent }  BlackBox Exporter #  下载地址: https://github.com/prometheus/blackbox_exporter/releases\n 下载二进制文件并解压到/usr/local/bin/\n安装脚本如下:\nfunction InstallBlackboxExporter(){ cat \u0026gt;/etc/systemd/system/blackbox_exporter.service \u0026lt;\u0026lt;EOF [Unit] Description=\u0026quot;blackbox_exporter\u0026quot; After=network.target [Service] Type=simple ExecStart=/usr/local/bin/blackbox_exporter --config.file=/etc/blackbox-exporter/blackbox.yml WorkingDirectory=/usr/local/bin SuccessExitStatus=0 LimitNOFILE=65536 StandardOutput=syslog StandardError=syslog SyslogIdentifier=blackbox_exporter KillMode=process KillSignal=SIGQUIT TimeoutStopSec=5 Restart=always [Install] WantedBy=multi-user.target EOF chmod 0644 /etc/systemd/system/blackbox_exporter.service cat \u0026gt;/etc/blackbox-exporter/blackbox.yml \u0026lt;\u0026lt;EOF modules: http_2xx: prober: http http_post_2xx: prober: http http: method: POST tcp_connect: prober: tcp pop3s_banner: prober: tcp tcp: query_response: - expect: \u0026quot;^+OK\u0026quot; tls: true tls_config: insecure_skip_verify: false grpc: prober: grpc grpc: tls: true preferred_ip_protocol: \u0026quot;ip4\u0026quot; grpc_plain: prober: grpc grpc: tls: false service: \u0026quot;service1\u0026quot; ssh_banner: prober: tcp tcp: query_response: - expect: \u0026quot;^SSH-2.0-\u0026quot; - send: \u0026quot;SSH-2.0-blackbox-ssh-check\u0026quot; irc_banner: prober: tcp tcp: query_response: - send: \u0026quot;NICK prober\u0026quot; - send: \u0026quot;USER prober prober prober :prober\u0026quot; - expect: \u0026quot;PING :([^ ]+)\u0026quot; send: \u0026quot;PONG ${1}\u0026quot; - expect: \u0026quot;^:[^ ]+ 001\u0026quot; icmp: prober: icmp EOF systemctl daemon-reload systemctl enable --now blackbox_exporter }  Mysqld Exporter #  下载地址: https://github.com/prometheus/mysqld_exporter\n 下载二进制文件并解压到/usr/local/bin/\n需要监听的数据库执行如下SQL:\n xxxxx替换为你设定的密码\n create user 'exporter'@'%' identified by 'xxxxx'; GRANT PROCESS, REPLICATION CLIENT, SELECT ON *.* TO 'exporter'@'%' WITH MAX_USER_CONNECTIONS 3; flush privileges;  安装脚本如下:\n mysqld_exporter.cnf: 中密码账户为上面执行SQL创建的用户密码.\n function InstallMysqldExporter(){ cat \u0026gt;/etc/systemd/system/mysqld_exporter.service \u0026lt;\u0026lt;EOF [Unit] Description=\u0026quot;mysqld_exporter\u0026quot; After=network.target [Service] Type=simple ExecStart=/usr/local/bin/mysqld_exporter --config.my-cnf=/etc/mysqld_exporter.cnf --collect.auto_increment.columns --collect.binlog_size --collect.global_status --collect.global_variables --collect.info_schema.innodb_metrics --collect.info_schema.innodb_cmp --collect.info_schema.innodb_cmpmem --collect.info_schema.processlist --collect.info_schema.query_response_time --collect.info_schema.tables --collect.info_schema.tablestats --collect.info_schema.userstats --collect.perf_schema.eventswaits --collect.perf_schema.file_events --collect.perf_schema.indexiowaits --collect.perf_schema.tableiowaits --collect.perf_schema.tablelocks --collect.slave_status WorkingDirectory=/usr/local/bin SuccessExitStatus=0 LimitNOFILE=65536 StandardOutput=syslog StandardError=syslog SyslogIdentifier=mysqld_exporter KillMode=process KillSignal=SIGQUIT TimeoutStopSec=5 Restart=always [Install] WantedBy=multi-user.target EOF chmod 0644 /etc/systemd/system/mysqld_exporter.service cat \u0026gt;/etc/mysqld_exporter.cnf \u0026lt;\u0026lt;EOF [client] user=exporter password=xxxx host=x.x.x.x port=3306 EOF systemctl daemon-reload systemctl enable --now mysqld_exporter }  consul + consul-template 动态生成配置 # 安装 Consul #  -bind 和 -client 需要替换为本机IP\n function InstallConsul(){ yum-config-manager --add-repo https://rpm.releases.hashicorp.com/RHEL/hashicorp.repo yum -y install consul mkdir -p /data/consul cat \u0026gt;/etc/systemd/system/consul.service \u0026lt;\u0026lt;EOF [Unit] Description=\u0026quot;consul\u0026quot; After=network.target [Service] Type=simple ExecStart=/usr/bin/consul agent -server -bootstrap-expect 1 -bind=x.x.x.x -client=x.x.x.x -data-dir=/data/consul -node=agent-one -config-dir=/etc/consul.d -ui WorkingDirectory=/usr/bin/ SuccessExitStatus=0 LimitNOFILE=65536 StandardOutput=syslog StandardError=syslog SyslogIdentifier=consul KillMode=process KillSignal=SIGQUIT TimeoutStopSec=5 Restart=always [Install] WantedBy=multi-user.target EOF chmod 0644 /etc/systemd/system/consul.service systemctl daemon-reload systemctl enable --now consul }  安装Consul-template # 安装脚本如下所示:\n x.x.x.x 替换为夜莺地址 , a.b.c.d 替换为consul部署地址\n wget https://releases.hashicorp.com/consul-template/0.29.0/consul-template_0.29.0_linux_amd64.zip unzip consul-template_0.29.0_linux_amd64.zip chmod +x consul-template mv consul-template /usr/local/bin/consul-template mkdir -p /etc/consul-template/template cat \u0026gt; /etc/consul-template/consul-template.conf \u0026lt;\u0026lt; EOF log_level = \u0026quot;warn\u0026quot; syslog { # This enables syslog logging. enabled = true # This is the name of the syslog facility to log to. facility = \u0026quot;LOCAL5\u0026quot; } consul { # auth { # enabled = true # username = \u0026quot;test\u0026quot; # password = \u0026quot;test\u0026quot; # } # 注意替换为consul地址 address = \u0026quot;a.b.c.d:8500\u0026quot; retry { enabled = true attempts = 12 backoff = \u0026quot;250ms\u0026quot; # If max_backoff is set to 10s and backoff is set to 1s, sleep times # would be: 1s, 2s, 4s, 8s, 10s, 10s, ... max_backoff = \u0026quot;3m\u0026quot; } } template { source = \u0026quot;/etc/consul-template/templates/url-monitor.ctmpl\u0026quot; destination = \u0026quot;/home/nightingale-main/docker/prometc/conf.d/url/url.yaml\u0026quot; command = \u0026quot;curl -X POST http://x.x.x.x:9090/-/reload\u0026quot; command_timeout = \u0026quot;60s\u0026quot; backup = true wait { min = \u0026quot;2s\u0026quot; max = \u0026quot;20s\u0026quot; } } template { source = \u0026quot;/etc/consul-template/templates/icmp-monitor.ctmpl\u0026quot; destination = \u0026quot;/home/nightingale-main/docker/prometc/conf.d/icmp/icmp.yaml\u0026quot; command = \u0026quot;\u0026quot; command_timeout = \u0026quot;60s\u0026quot; backup = true wait { min = \u0026quot;2s\u0026quot; max = \u0026quot;20s\u0026quot; } } EOF cat \u0026gt; /etc/consul-template/consul-template.conf/template/url-monitor.ctmpl \u0026lt;\u0026lt;EOF - targets: {{- range ls \u0026quot;blackbox/url/http200\u0026quot; }} - http://{{ .Key }}{{ .Value }} {{- end }} EOF cat \u0026gt; /etc/consul-template/consul-template.conf/template/icmp-monitor.ctmpl \u0026lt;\u0026lt;EOF {{- range ls \u0026quot;blackbox/icmp\u0026quot; }} - targets: - {{ .Key }} labels: instance: {{ .Key }} {{- end }} EOF cat \u0026gt; /etc/systemd/system/consul-template.service \u0026lt;\u0026lt;EOF [Unit] Description=\u0026quot;consul-template\u0026quot; After=network.target [Service] Type=simple ExecStart=/usr/local/bin/consul-template -config /etc/consul-template/consul-template.conf WorkingDirectory=/usr/local/bin SuccessExitStatus=0 LimitNOFILE=65536 StandardOutput=syslog StandardError=syslog SyslogIdentifier=consul-template KillMode=process KillSignal=SIGQUIT TimeoutStopSec=5 Restart=always [Install] WantedBy=multi-user.target EOF systemctl daemon-reload systemctl enable --now consul-template.service  配置Consul K/V 动态生成URL监控 # 添加如下K/V,K/V 对应上文*.ctmpl 文件中渲染地址. 在这里Key 为域名,Values 为路径   修改Promtheus配置 # nightingale-main/docker/prometc/prometheus.yml追加如下内容:\n- job_name: MySQL static_configs: - targets: - x.x.x.x:9104 labels: instance: MySQL-dev - job_name: process static_configs: - targets: - x.x.x.x:9256 - job_name: 'blackbox-url-monitor' metrics_path: /probe params: module: [http_2xx] # Look for a HTTP 200 response. file_sd_configs: - refresh_interval: 1m files: - ./conf.d/url/*.yaml relabel_configs: - source_labels: [__address__] target_label: __param_target - source_labels: [__param_target] target_label: instance - target_label: __address__ replacement: x.x.x.x:9115 - job_name: 'blackbox-icmp-monitor' scrape_interval: 1m metrics_path: /probe params: module: [icmp] file_sd_configs: - refresh_interval: 1m files: - ./conf.d/icmp/*.yaml relabel_configs: - source_labels: [__address__] target_label: __param_target - target_label: __address__ replacement: x.x.x.x:9115  在nightingale-main/docker/prometc/ 下创建目录conf.d. 命令如下:\ncd nightingale-main/docker/prometc/ mkdir -p conf.d/{icmp,url}  重启promtheus,命令如下所示:\ndocker restart prometheus  重启后检查prometheus状态   日志监控搭建 #  感谢夜莺社区支持.\n 大前提, 夜莺版本高于5.9.2 已有Loki. 并且Loki已经支持多租户.   Loki的配置在这里不做赘述,网上教程太多了.\ndocker-compose.yml 追加如下内容, 与nserver 同级\nlokinserver: image: registry.cn-hangzhou.aliyuncs.com/lcc-middleware/nightingale:5.9.2 container_name: lokinserver hostname: nserver restart: always environment: GIN_MODE: release TZ: Asia/Shanghai WAIT_HOSTS: mysql:3306, redis:6379 volumes: - ./lokin9eetc:/app/etc ports: - \u0026quot;20000:20000\u0026quot; networks: - nightingale depends_on: - mysql - redis - prometheus - ibex links: - mysql:mysql - redis:redis - prometheus:prometheus - ibex:ibex command: \u0026gt; sh -c \u0026quot;/wait \u0026amp;\u0026amp; /app/n9e server\u0026quot;  生成lokinserver容器的配置文件.操作如下.\ncp -r n9eetc lokin9eetc cd lokin9eetc  修改lokin9eetc/server.conf文件中Reader字段,内容如下:\n 如果开启多租户记得传Headers, 如果没开,则去除Headers字段 Loki的API中带loki前缀的都是兼容prometheus风格的API 所以一定要加. Prom字段替换为自己的域名\n [Reader] # prometheus base url Url = \u0026quot;http://loki.xxx.xxx/loki/\u0026quot; # Basic auth username BasicAuthUser = \u0026quot;\u0026quot; # Basic auth password BasicAuthPass = \u0026quot;\u0026quot; # timeout settings, unit: ms Timeout = 30000 DialTimeout = 10000 TLSHandshakeTimeout = 30000 ExpectContinueTimeout = 1000 IdleConnTimeout = 90000 # time duration, unit: ms KeepAlive = 30000 MaxConnsPerHost = 0 MaxIdleConns = 100 MaxIdleConnsPerHost = 10 Headers = [\u0026quot;X-Scope-OrgID\u0026quot;,\u0026quot;lcc-loki\u0026quot;]  修改配置文件nightingale-main/docker/n9eetc/webapi.conf, 追加如下内容\n 如果开启多租户记得传Headers, 如果没开,则去除Headers字段 Loki的API中带loki前缀的都是兼容prometheus风格的API 所以一定要加. Prom字段替换为自己的域名\n [[Clusters]] # Prometheus cluster name Name = \u0026quot;Loki\u0026quot; # # Prometheus APIs base url Prom = \u0026quot;http://loki.xxx.xxx/loki/\u0026quot; # # Basic auth username BasicAuthUser = \u0026quot;\u0026quot; # Basic auth password BasicAuthPass = \u0026quot;\u0026quot; # timeout settings, unit: ms Timeout = 30000 DialTimeout = 10000 TLSHandshakeTimeout = 30000 ExpectContinueTimeout = 1000 IdleConnTimeout = 90000 # time duration, unit: ms KeepAlive = 30000 MaxConnsPerHost = 0 MaxIdleConns = 100 MaxIdleConnsPerHost = 100 Headers = [\u0026quot;X-Scope-OrgID\u0026quot;,\u0026quot;lcc-loki\u0026quot;]  重启夜莺监控:\ndocker-compose up -d  告警规则配置 # 系统运维 # CPU利用率 \u0026gt; 90 # (100-(avg by (mode, instance)(rate(node_cpu_seconds_total{mode=\u0026quot;idle\u0026quot;}[1m])))*100) \u0026gt; 90  Innode 利用率\u0026gt;90 # (100 - ((node_filesystem_files_free * 100) / node_filesystem_files))\u0026gt;90  sshd 服务挂了 # (namedprocess_namegroup_num_procs{groupname=\u0026quot;sshd\u0026quot;}) == 0  内存利用率 \u0026gt; 95 # (node_memory_MemTotal_bytes - node_memory_MemFree_bytes - (node_memory_Cached_bytes + node_memory_Buffers_bytes))/node_memory_MemTotal_bytes*100 \u0026gt; 95  文件句柄 \u0026gt; 90 # (node_filefd_allocated{}/node_filefd_maximum{}*100)  IO wait \u0026gt; 30% # avg by (instance) (rate(node_cpu_seconds_total{mode=\u0026quot;iowait\u0026quot;}[5m])) * 100 \u0026gt; 30  过去一分钟IOutil \u0026gt; 80 # (rate(node_disk_io_time_seconds_total{} [1m]) *100) \u0026gt; 80  Ping \u0026gt; 1s # avg_over_time(probe_icmp_duration_seconds[1m]) \u0026gt; 1  平均负载\u0026gt;2 # (avg(node_load1) by(instance)/count by (instance)(node_cpu_seconds_total{mode='idle'})) \u0026gt;2  TCP重传率\u0026gt;5% # (rate(node_netstat_Tcp_RetransSegs{}[5m])/ rate(node_netstat_Tcp_OutSegs{}[5m])*100) \u0026gt; 5  磁盘利用率 \u0026gt; 85% # (100 - ((node_filesystem_avail_bytes * 100) / node_filesystem_size_bytes) ) \u0026gt; 85  节点重启 # node_reboot_required \u0026gt; 0  业务运维 #  我们是GO应用,其他应用根据需要设定\n 一分钟内日志ERROR\u0026gt;10 #  日志这里主要选,我们上面添加的Loki集群\n    URL探测不通 # probe_http_status_code \u0026lt;= 199 OR probe_http_status_code \u0026gt;= 400  过去一分钟出现Panic #    数据库运维 #  仅罗列部分, 更多可以在导入规则中查找\n    数据库重启 # mysql_global_status_uptime \u0026lt; 60  连接数超过80% # avg by (instance) (mysql_global_status_threads_connected) / avg by (instance) (mysql_global_variables_max_connections) * 100 \u0026gt; 80`  最近一分钟有慢查询 # increase(mysql_global_status_slow_queries[1m]) \u0026gt; 0  "}),e.add({id:29,href:"/docs/appendix/grafana-agent/k8s_metrics/",title:"收集metrics",description:"在本文档中，介绍如何以Deployment或者Daemonset的方式部署grafana-agent到您的k8s集群中，抓取宿主机上kubelet和cAdvisor的metrics指标，并把抓取到的数据，以remote_write的方式推送到Nightingale.\n通过本文档，我们预期达成以下目标：\n 部署grafana-agent到您的K8s集群中； 配置grafana-agent抓取kubelet和cAdvisor的metrics；  K8s是开源的容器编排系统，自动化管理容器的部署、扩缩容等工作。K8s默认会暴露Node和控制面的若干metrics接口，这些接口兼容Prometheus的metrics规范。我们可以部署grafana-agent来收集Node的cAdvisor和kubelet metrics，并以remote_write的方式发送到Nightingale.\n前置依赖 #  一个开启RBAC（role-based access control）的Kubernetes集群； 安装并配置好了kubectl命令行工具；  步骤一：创建 ServiceAcount、ClusterRole、ClusterRoleBinding # export NAMESPACE=default MANIFEST_URL=https://raw.githubusercontent.com/flashcatcloud/fc-agent/fc-release/etc/k8s/agent-bare.yaml curl -fsSL $MANIFEST_URL | envsubst | kubectl apply -f -  步骤二：创建ConfigMap，配置grafana-agent # export NAMESPACE=default export CLUSTER_NAME=kubernetes export FC_REMOTE_WRITE_URL=http://10.206.0.16:8480/insert/0/prometheus/api/v1/write #export FC_REMOTE_WRITE_URL=https://n9e-server:19000/prometheus/v1/write #export FC_REMOTE_WRITE_USERNAME=fc_laiwei #export FC_REMOTE_WRITE_PASSWORD=fc_laiweisecret cat \u0026lt;\u0026lt;EOF | kind: ConfigMap metadata: name: grafana-agent apiVersion: v1 data: agent.yaml: | server: http_listen_port: 12345 metrics: wal_directory: /tmp/grafana-agent-wal global: scrape_interval: 15s scrape_timeout: 10s external_labels: cluster: ${CLUSTER_NAME} configs: - name: integrations remote_write: - url: ${FC_REMOTE_WRITE_URL} basic_auth: username: ${FC_REMOTE_WRITE_USERNAME} password: ${FC_REMOTE_WRITE_PASSWORD} scrape_configs: - job_name: integrations/kubernetes/cadvisor bearer_token_file: /var/run/secrets/kubernetes.",content:"在本文档中，介绍如何以Deployment或者Daemonset的方式部署grafana-agent到您的k8s集群中，抓取宿主机上kubelet和cAdvisor的metrics指标，并把抓取到的数据，以remote_write的方式推送到Nightingale.\n通过本文档，我们预期达成以下目标：\n 部署grafana-agent到您的K8s集群中； 配置grafana-agent抓取kubelet和cAdvisor的metrics；  K8s是开源的容器编排系统，自动化管理容器的部署、扩缩容等工作。K8s默认会暴露Node和控制面的若干metrics接口，这些接口兼容Prometheus的metrics规范。我们可以部署grafana-agent来收集Node的cAdvisor和kubelet metrics，并以remote_write的方式发送到Nightingale.\n前置依赖 #  一个开启RBAC（role-based access control）的Kubernetes集群； 安装并配置好了kubectl命令行工具；  步骤一：创建 ServiceAcount、ClusterRole、ClusterRoleBinding # export NAMESPACE=default MANIFEST_URL=https://raw.githubusercontent.com/flashcatcloud/fc-agent/fc-release/etc/k8s/agent-bare.yaml curl -fsSL $MANIFEST_URL | envsubst | kubectl apply -f -  步骤二：创建ConfigMap，配置grafana-agent # export NAMESPACE=default export CLUSTER_NAME=kubernetes export FC_REMOTE_WRITE_URL=http://10.206.0.16:8480/insert/0/prometheus/api/v1/write #export FC_REMOTE_WRITE_URL=https://n9e-server:19000/prometheus/v1/write #export FC_REMOTE_WRITE_USERNAME=fc_laiwei #export FC_REMOTE_WRITE_PASSWORD=fc_laiweisecret cat \u0026lt;\u0026lt;EOF | kind: ConfigMap metadata: name: grafana-agent apiVersion: v1 data: agent.yaml: | server: http_listen_port: 12345 metrics: wal_directory: /tmp/grafana-agent-wal global: scrape_interval: 15s scrape_timeout: 10s external_labels: cluster: ${CLUSTER_NAME} configs: - name: integrations remote_write: - url: ${FC_REMOTE_WRITE_URL} basic_auth: username: ${FC_REMOTE_WRITE_USERNAME} password: ${FC_REMOTE_WRITE_PASSWORD} scrape_configs: - job_name: integrations/kubernetes/cadvisor bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token kubernetes_sd_configs: - role: node metric_relabel_configs: - action: drop regex: container_([a-z_]+); source_labels: - __name__ - image - action: drop regex: container_(network_tcp_usage_total|network_udp_usage_total|tasks_state|cpu_load_average_10s) source_labels: - __name__ relabel_configs: - replacement: kubernetes.default.svc:443 target_label: __address__ - regex: (.+) replacement: /api/v1/nodes/\\$1/proxy/metrics/cadvisor source_labels: - __meta_kubernetes_node_name target_label: __metrics_path__ scheme: https tls_config: ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt insecure_skip_verify: false server_name: kubernetes - job_name: integrations/kubernetes/kubelet bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token kubernetes_sd_configs: - role: node relabel_configs: - replacement: kubernetes.default.svc:443 target_label: __address__ - regex: (.+) replacement: /api/v1/nodes/\\$1/proxy/metrics source_labels: - __meta_kubernetes_node_name target_label: __metrics_path__ scheme: https tls_config: ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt insecure_skip_verify: false server_name: kubernetes EOF envsubst | kubectl apply -n $NAMESPACE -f -  步骤三：在K8s中创建grafana-agent实例 #  Daemonset\n 对于采集 node_exporter/ kubelet/ cAdvisor等指标，每个节点上只运行一个grafana-agent实例的情况，推荐以daemonset运行 # export NAMESPACE=default MANIFEST_URL=https://raw.githubusercontent.com/flashcatcloud/fc-agent/fc-release/etc/k8s/agent-daemonset.yaml curl -fsSL $MANIFEST_URL | envsubst | kubectl apply -f -   Deployment\n 对于采集MySQLd_Exporter等需要运行多个grafana-agent实例的情况，推荐以deployment运行。 # export NAMESPACE=default MANIFEST_URL=https://raw.githubusercontent.com/flashcatcloud/fc-agent/fc-release/etc/k8s/agent-deployment.yaml curl -fsSL $MANIFEST_URL | envsubst | kubectl apply -f -  如何重建grafana-agent #  Daemonset\n kubectl rollout restart daemonset/grafana-agent   Deployment\n kubectl rollout restart deployment/grafana-agent  至此，我们已经完成了在K8s中部署grafana-agent并收集metrics，进一步，我们还可以配置grafana-agent来建立起完整的kubernetes指标监控体系。\n"}),e.add({id:30,href:"/docs/appendix/usecase/",title:"用户案例研究",description:"",content:""}),e.add({id:31,href:"/docs/appendix/grafana-agent/k8s_logs/",title:"收集logs",description:"在本文档中，介绍如何以Daemonset的形式部署grafana-agent到您的k8s集群中，收集您的K8s集群中应用的日志，并将其推送到Nightingale.",content:"在本文档中，介绍如何以Daemonset的形式部署grafana-agent到您的k8s集群中，收集您的K8s集群中应用的日志，并将其推送到Nightingale.\n"}),e.add({id:32,href:"/docs/appendix/grafana-agent/k8s_traces/",title:"收集trace",description:"在本文档中，介绍如何以 Deployment 的形式部署grafana-agent到您的K8s集群中，收集您的K8s集群中应用的trace数据，并将其推送到Nightingale.",content:"在本文档中，介绍如何以 Deployment 的形式部署grafana-agent到您的K8s集群中，收集您的K8s集群中应用的trace数据，并将其推送到Nightingale.\n"}),e.add({id:33,href:"/docs/appendix/grafana-agent/scrape_exporters/",title:"收集三方exporter",description:"对于未嵌入到 grafana-agent中的 exporter，则可以在 grafana-agent 中配置 scrape_configs 来完成抓取和收集，请参考抓取第三方exporter。",content:"对于未嵌入到 grafana-agent中的 exporter，则可以在 grafana-agent 中配置 scrape_configs 来完成抓取和收集，请参考抓取第三方exporter。\n"}),e.add({id:34,href:"/docs/appendix/grafana-agent/how-to-monitoring-k8s/",title:"监控K8s",description:"Acknowledgement: grafana-agent is powered by Grafana Agent. Grafana Agent is a lightweight telemetry collector based on Prometheus that only performs its scraping and remote_write functions. Agent can also collect metrics, logs, and traces for storage in Grafana Cloud and Grafana Enterprise, as well as OSS deployments of Loki (logs), and Tempo (traces), Prometheus (metrics), and Cortex (metrics). Grafana Agent also contains several integrations (embedded metrics exporters) like node-exporter, a MySQL exporter, and many more.",content:" Acknowledgement: grafana-agent is powered by Grafana Agent. Grafana Agent is a lightweight telemetry collector based on Prometheus that only performs its scraping and remote_write functions. Agent can also collect metrics, logs, and traces for storage in Grafana Cloud and Grafana Enterprise, as well as OSS deployments of Loki (logs), and Tempo (traces), Prometheus (metrics), and Cortex (metrics). Grafana Agent also contains several integrations (embedded metrics exporters) like node-exporter, a MySQL exporter, and many more.\nThe Grafana Agent uses the same code as Prometheus, but tackles these issues by only using the most relevant parts of Prometheus for interaction with hosted metrics:\n Service Discovery Scraping Write Ahead Log (WAL) Remote Write   对于Kubernetes集群及其上应用，我们推荐从以下几个方面，建立起完整的kubernetes指标监控体系：\n前置依赖 #  如何在K8s中运行和启动grafana-agent，请参考在kubernetes中运行grafana-agent收集。 推荐您以daemonset，在每个节点上启动一个grafana-agent实例。  通过kubelet来了解和监控k8s节点的基本运行状态数据 # 方案一：直接访问kubelet来获取节点状态指标数据 # Kubelet组件运行在Kubernetes集群的各个节点中，其负责维护和管理节点上Pod的运行状态。kubelet组件的正常运行直接关系到该节点是否能够正常的被Kubernetes集群正常使用。\n基于Prometheus在K8s环境下的服务发现能力，在Node模式，grafana-agent会自动发现Kubernetes中所有Node节点的信息并作为监控的目标Target。 而这些Target的访问地址实际上就是Kubelet的访问地址。\n 创建ConfigMap，其中包含grafana-agent的配置文件如下\n export NAMESPACE=default export CLUSTER_NAME=kubernetes export REMOTE_WRITE_URL=http://n9e-server:19000/prometheus/v1/write export REMOTE_WRITE_USERNAME=fc_laiwei export REMOTE_WRITE_PASSWORD=fc_laiweisecret cat \u0026lt;\u0026lt;EOF | kind: ConfigMap metadata: name: grafana-agent apiVersion: v1 data: agent.yaml: | server: http_listen_port: 12345 metrics: wal_directory: /tmp/grafana-agent-wal global: scrape_interval: 15s scrape_timeout: 10s external_labels: cluster: ${CLUSTER_NAME} configs: - name: fc_k8s_scrape remote_write: - url: ${REMOTE_WRITE_URL} basic_auth: username: ${REMOTE_WRITE_USERNAME} password: ${REMOTE_WRITE_PASSWORD} scrape_configs: - job_name: integrations/kubernetes/kubelet scheme: https tls_config: ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt insecure_skip_verify: true bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token kubernetes_sd_configs: - role: node relabel_configs: - action: labelmap regex: __meta_kubernetes_node_label_(.+) EOF envsubst | kubectl apply -n $NAMESPACE -f -   重建grafana-agent实例\n kubectl rollout restart daemonset/grafana-agent  这里使用Node模式自动发现集群中所有Kubelet作为监控的数据采集目标，同时通过labelmap步骤，将Node节点上的标签，作为样本的标签保存到时间序列当中。 重新加载grafana-agent的配置文件，并重建grafana-agent的Pod实例后，在nightingale dashboard中搜索{job=\u0026quot;integrations/kubernetes/kubelet\u0026quot;}，即可看到相应的时序数据了。\n方案二：通过kube-apiserver提供的API间接获取kubelet的指标数据 # 不同于上面第一种方法，其直接通过kubelet的metrics服务采集监控数据，方法二通过Kubernetes的api-server提供的代理API访问各个节点中kubelet的metrics服务。\n 创建ConfigMap，其中包含grafana-agent的配置文件如下\n export NAMESPACE=default export CLUSTER_NAME=kubernetes export REMOTE_WRITE_URL=http://10.206.0.16:8480/insert/0/prometheus/api/v1/write export REMOTE_WRITE_URL=http://n9e-server:19000/prometheus/v1/write export REMOTE_WRITE_USERNAME=fc_laiwei export REMOTE_WRITE_PASSWORD=fc_laiweisecret cat \u0026lt;\u0026lt;EOF | kind: ConfigMap metadata: name: grafana-agent apiVersion: v1 data: agent.yaml: | server: http_listen_port: 12345 metrics: wal_directory: /tmp/grafana-agent-wal global: scrape_interval: 15s scrape_timeout: 10s external_labels: cluster: ${CLUSTER_NAME} configs: - name: fc_k8s_scrape remote_write: - url: ${REMOTE_WRITE_URL} basic_auth: username: ${REMOTE_WRITE_USERNAME} password: ${REMOTE_WRITE_PASSWORD} scrape_configs: - job_name: 'integrations/kubernetes/kubelet' scheme: https tls_config: ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token kubernetes_sd_configs: - role: node relabel_configs: - action: labelmap regex: __meta_kubernetes_node_label_(.+) - target_label: __address__ replacement: kubernetes.default.svc:443 - source_labels: [__meta_kubernetes_node_name] regex: (.+) target_label: __metrics_path__ replacement: /api/v1/nodes/\\${1}/proxy/metrics EOF envsubst | kubectl apply -n $NAMESPACE -f -  通过relabeling，将从Kubernetes获取到的默认地址__address__替换为kubernetes.default.svc:443。同时将__metrics_path__替换为api-server的代理地址/api/v1/nodes/${1}/proxy/metrics。\n通过获取各个节点中kubelet的监控指标，您可以评估集群中各节点的性能表现。例如:\n1. 通过指标kubelet_pod_start_duration_seconds可以获得当前节点中Pod启动时间相关的统计数据。\nkubelet_pod_start_duration_seconds{quantile=\u0026quot;0.99\u0026quot;}  2. Pod平均启动时间（包含镜像下载时间）：\nkubelet_pod_start_duration_seconds_sum / kubelet_pod_start_duration_seconds_count  除此以外，监控指标kubelet_docker_*还可以体现出kubelet与当前节点的docker服务的调用情况，从而可以反映出docker本身是否会影响kubelet的性能表现等问题。\n通过cAdvisor来了解和监控节点中的容器运行状态 # 各节点的kubelet组件中除了包含自身的监控指标信息以外，kubelet组件还内置了对cAdvisor的支持。cAdvisor能够获取当前节点上运行的所有容器的资源使用情况，通过访问kubelet的/metrics/cadvisor地址可以获取到cadvisor的监控指标，因此和获取kubelet监控指标类似，这里同样通过node模式自动发现所有的kubelet信息，并通过适当的relabel过程，修改监控采集任务的配置。 与采集kubelet自身监控指标相似，这里也有两种方式采集cadvisor中的监控指标：\n方案一：直接访问kubelet的/metrics/cadvisor地址，需要跳过ca证书认证 # export NAMESPACE=default export CLUSTER_NAME=kubernetes export REMOTE_WRITE_URL=http://10.206.0.16:8480/insert/0/prometheus/api/v1/write export REMOTE_WRITE_URL=http://n9e-server:19000/prometheus/v1/write export REMOTE_WRITE_USERNAME=fc_laiwei export REMOTE_WRITE_PASSWORD=fc_laiweisecret cat \u0026lt;\u0026lt;EOF | kind: ConfigMap metadata: name: grafana-agent apiVersion: v1 data: agent.yaml: | server: http_listen_port: 12345 metrics: wal_directory: /tmp/grafana-agent-wal global: scrape_interval: 15s scrape_timeout: 10s external_labels: cluster: ${CLUSTER_NAME} configs: - name: fc_k8s_scrape remote_write: - url: ${REMOTE_WRITE_URL} basic_auth: username: ${REMOTE_WRITE_USERNAME} password: ${REMOTE_WRITE_PASSWORD} scrape_configs: - job_name: 'integrations/kubernetes/cadvisor' scheme: https tls_config: ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt insecure_skip_verify: true bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token kubernetes_sd_configs: - role: node relabel_configs: - source_labels: [__meta_kubernetes_node_name] regex: (.+) target_label: __metrics_path__ replacement: metrics/cadvisor - action: labelmap regex: __meta_kubernetes_node_label_(.+) EOF envsubst | kubectl apply -n $NAMESPACE -f -  方案二：通过api-server提供的代理地址访问kubelet的/metrics/cadvisor地址 # export NAMESPACE=default export CLUSTER_NAME=kubernetes export REMOTE_WRITE_URL=http://10.206.0.16:8480/insert/0/prometheus/api/v1/write export REMOTE_WRITE_URL=http://n9e-server:19000/prometheus/v1/write export REMOTE_WRITE_USERNAME=fc_laiwei export REMOTE_WRITE_PASSWORD=fc_laiweisecret cat \u0026lt;\u0026lt;EOF | kind: ConfigMap metadata: name: grafana-agent apiVersion: v1 data: agent.yaml: | server: http_listen_port: 12345 metrics: wal_directory: /tmp/grafana-agent-wal global: scrape_interval: 15s scrape_timeout: 10s external_labels: cluster: ${CLUSTER_NAME} configs: - name: fc_k8s_scrape remote_write: - url: ${REMOTE_WRITE_URL} basic_auth: username: ${REMOTE_WRITE_USERNAME} password: ${REMOTE_WRITE_PASSWORD} scrape_configs: - job_name: 'integrations/kubernetes/cadvisor' scheme: https tls_config: ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token kubernetes_sd_configs: - role: node relabel_configs: - target_label: __address__ replacement: kubernetes.default.svc:443 - source_labels: [__meta_kubernetes_node_name] regex: (.+) target_label: __metrics_path__ replacement: /api/v1/nodes/${1}/proxy/metrics/cadvisor - action: labelmap regex: __meta_kubernetes_node_label_(.+)  使用NodeExporter监控节点资源使用情况 # 为了能够采集集群中各个节点的资源使用情况，我们可以借助grafana-agent内置的NodeExporter。具体的步骤可以参考：grafana-agent node_exporter。\n通过kube-apiserver来了解整个K8s集群的详细运行状态 # kube-apiserver扮演了整个Kubernetes集群管理的入口的角色，负责对外暴露Kubernetes API。kube-apiserver组件一般是独立部署在集群外的，为了能够让部署在集群内的应用（kubernetes插件或者用户应用）能够与kube-apiserver交互，Kubernetes会默认在命名空间下创建一个名为kubernetes的服务，如下所示：\n$ kubectl get svc kubernetes -o wide NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE SELECTOR kubernetes ClusterIP 10.96.0.1 \u0026lt;none\u0026gt; 443/TCP 166d \u0026lt;none\u0026gt;  而该kubernetes服务代理的后端实际地址通过endpoints进行维护，如下所示：\n$ kubectl get endpoints kubernetes NAME ENDPOINTS AGE kubernetes 10.0.2.15:8443 166d  通过这种方式集群内的应用或者系统主机就可以通过集群内部的DNS域名kubernetes.default.svc访问到部署外部的kube-apiserver实例。\n因此，如果我们想要监控kube-apiserver相关的指标，只需要通过endpoints资源找到kubernetes对应的所有后端地址即可。\n如下所示，创建监控任务kubernetes-apiservers，这里指定了服务发现模式为endpoints。grafana-agent会查找当前集群中所有的endpoints配置，并通过relabel进行判断是否为apiserver对应的访问地址：\n- job_name: 'kubernetes-apiservers' kubernetes_sd_configs: - role: endpoints scheme: https tls_config: ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token relabel_configs: - source_labels: [__meta_kubernetes_namespace, __meta_kubernetes_service_name, __meta_kubernetes_endpoint_port_name] action: keep regex: default;kubernetes;https - target_label: __address__ replacement: kubernetes.default.svc:443  在relabel_configs配置中第一步用于判断当前endpoints是否为kube-apiserver对用的地址。第二步，替换监控采集地址到kubernetes.default.svc:443即可。重新加载配置文件，重建grafana-agent实例，用以下promql {service=\u0026quot;kubernetes\u0026quot;, job=\u0026quot;apiserver\u0026quot;}即可在nightingale dashboard中得到kube-apiserver相关的metrics数据。\n通过BlackboxExporter了解和监控K8s集群中的网络连通状况 # 为了能够对Ingress和Service进行探测，我们需要在K8s集群部署Blackbox Exporter实例。 如下所示，创建blackbox-exporter.yaml用于描述部署相关的内容:\ncat \u0026lt;\u0026lt; EOF | apiVersion: v1 kind: Service metadata: labels: app: blackbox-exporter name: blackbox-exporter spec: ports: - name: blackbox port: 9115 protocol: TCP selector: app: blackbox-exporter type: ClusterIP --- apiVersion: extensions/v1beta1 kind: Deployment metadata: labels: app: blackbox-exporter name: blackbox-exporter spec: replicas: 1 selector: matchLabels: app: blackbox-exporter template: metadata: labels: app: blackbox-exporter spec: containers: - image: prom/blackbox-exporter imagePullPolicy: IfNotPresent name: blackbox-exporter EOF kubectl apply -f -  通过以上命令，将在K8s集群中部署了一个Blackbox Exporter的Pod实例，同时通过服务blackbox-exporter在集群内暴露访问地址blackbox-exporter.default.svc.cluster.local，对于集群内的任意服务都可以通过该内部DNS域名访问Blackbox Exporter实例：\n$ kubectl get pods NAME READY STATUS RESTARTS AGE blackbox-exporter-f77fc78b6-72bl5 1/1 Running 0 4s $ kubectl get svc NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE blackbox-exporter ClusterIP 10.109.144.192 \u0026lt;none\u0026gt; 9115/TCP 3m  为了能够让grafana-agent能够自动的对Service进行探测，我们需要通过服务发现自动找到所有的Service信息。 如下所示，在grafana-agent的配置文件中添加名为kubernetes-services的监控采集任务：\n- job_name: 'kubernetes-services' metrics_path: /probe params: module: [http_2xx] kubernetes_sd_configs: - role: service relabel_configs: - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_probe] action: keep regex: true - source_labels: [__address__] target_label: __param_target - target_label: __address__ replacement: blackbox-exporter.default.svc.cluster.local:9115 - source_labels: [__param_target] target_label: instance - action: labelmap regex: __meta_kubernetes_service_label_(.+) - source_labels: [__meta_kubernetes_namespace] target_label: kubernetes_namespace - source_labels: [__meta_kubernetes_service_name] target_label: kubernetes_name  在该任务配置中，通过指定kubernetes_sd_config的role为service指定服务发现模式：\nkubernetes_sd_configs: - role: service  为了区分集群中需要进行探测的Service实例，我们通过标签‘prometheus.io/probe: true’进行判断，从而过滤出需要探测的所有Service实例：\n- source_labels: [__meta_kubernetes_service_annotation_prometheus_io_probe] action: keep regex: true  并且将通过服务发现获取到的Service实例地址__address__转换为获取监控数据的请求参数。同时将__address执行Blackbox Exporter实例的访问地址，并且重写了标签instance的内容：\n- source_labels: [__address__] target_label: __param_target - target_label: __address__ replacement: blackbox-exporter.default.svc.cluster.local:9115 - source_labels: [__param_target] target_label: instance  最后，为监控样本添加了额外的标签信息：\n- action: labelmap regex: __meta_kubernetes_service_label_(.+) - source_labels: [__meta_kubernetes_namespace] target_label: kubernetes_namespace - source_labels: [__meta_kubernetes_service_name] target_label: kubernetes_name  对于Ingress而言，也是一个相对类似的过程，这里给出对Ingress探测的grafana-agent任务配置作为参考：\n- job_name: 'kubernetes-ingresses' metrics_path: /probe params: module: [http_2xx] kubernetes_sd_configs: - role: ingress relabel_configs: - source_labels: [__meta_kubernetes_ingress_annotation_prometheus_io_probe] action: keep regex: true - source_labels: [__meta_kubernetes_ingress_scheme,__address__,__meta_kubernetes_ingress_path] regex: (.+);(.+);(.+) replacement: ${1}://${2}${3} target_label: __param_target - target_label: __address__ replacement: blackbox-exporter.default.svc.cluster.local:9115 - source_labels: [__param_target] target_label: instance - action: labelmap regex: __meta_kubernetes_ingress_label_(.+) - source_labels: [__meta_kubernetes_namespace] target_label: kubernetes_namespace - source_labels: [__meta_kubernetes_ingress_name] target_label: kubernetes_name  通过kube-state-metrics了解和监控K8s集群自身和应用的运行状态 # kube-state-metrics重点回答以下方面的问题：\n 我调度了多少个replicas？现在可用的有几个？ 多少个Pod是running/stopped/terminated状态？ Pod重启了多少次？ 我有多少job在运行中？  kube-state-metrics基于client-go开发，轮询Kubernetes API，并将Kubernetes的结构化信息转换为metrics。他所支持的指标包括：\n CronJob Metrics DaemonSet Metrics Deployment Metrics Job Metrics LimitRange Metrics Node Metrics PersistentVolume Metrics PersistentVolumeClaim Metrics Pod Metrics Pod Disruption Budget Metrics ReplicaSet Metrics ReplicationController Metrics ResourceQuota Metrics Service Metrics StatefulSet Metrics Namespace Metrics Horizontal Pod Autoscaler Metrics Endpoint Metrics Secret Metrics ConfigMap Metrics  以Pod为例：\n kube_pod_info kube_pod_owner kube_pod_status_phase kube_pod_status_ready kube_pod_status_scheduled kube_pod_container_status_waiting kube_pod_container_status_terminated_reason \u0026hellip;  部署清单：\n├── cluster-role-binding.yaml ├── cluster-role.yaml ├── deployment.yaml ├── service-account.yaml ├── service.yaml  主要镜像有：\n image: quay.io/coreos/kube-state-metrics:v2.4.2 image: k8s.gcr.io/kube-state-metrics/kube-state-metrics  由于 quay.io/coreos/kube-state-metrics 不再更新，推荐使用 k8s.gcr.io/kube-state-metrics/kube-state-metrics\n quay.io/coreos/kube-state-metrics images will no longer be updated. k8s.gcr.io/kube-state-metrics/kube-state-metrics is the new canonical location.\n 对于pod的资源限制，一般情况下：\n200MiB memory 0.1 cores  超过100节点的集群：\n2MiB memory per node 0.001 cores per node  因为kube-state-metrics-service.yaml中有prometheus.io/scrape: 'true'标识，因此会将metric暴露给grafana-agent，而grafana-agent会在kubernetes-service-endpoints这个job下自动发现kube-state-metrics，并开始拉取metrics，无需其他配置。\n使用kube-state-metrics后的常用场景有：\n 存在执行失败的Job: kube_job_status_failed{job=\u0026ldquo;kubernetes-service-endpoints\u0026rdquo;,k8s_app=\u0026ldquo;kube-state-metrics\u0026rdquo;}==1 集群节点状态错误: kube_node_status_condition{condition=\u0026ldquo;Ready\u0026rdquo;,status!=\u0026ldquo;true\u0026rdquo;}==1 集群中存在启动失败的Pod：kube_pod_status_phase{phase=~\u0026ldquo;Failed|Unknown\u0026rdquo;}==1 最近30分钟内有Pod容器重启: changes(kube_pod_container_status_restarts[30m])\u0026gt;0   参考资料\n  Prometheus与服务发现 基于文件的服务发现 基于Consul的服务发现 服务发现与Relabel Kubernetes下的服务发现 监控Kubernetes集群 kube-state-metrics kube-state-metrics deoplyment   Acknowledgement:本文档在yunlzheng 监控Kubernetes集群的基础上修改和补充而成，相关文字的版权归属原作者yunlzheng所有，并致以谢意。\n "}),e.add({id:35,href:"/docs/appendix/grafana-agent/integrations/",title:"integrations",description:"grafana-agent内置集成的采集功能",content:""}),e.add({id:36,href:"/docs/appendix/grafana-agent/integrations/overview/",title:"Overview",description:"grafana-agent内置集成的采集功能",content:" grafana-agent 的 metrics采集，完全兼容 prometheus exporter 生态，一些常见的 exporter，会在 grafana-agent 中内嵌实现（列表如下）; 对于未嵌入到 grafana-agent中的 exporter，则可以在 grafana-agent 中配置 scrape_configs 来完成抓取和收集，请参考抓取第三方exporter;  grafana-agent 内置实现的 exporter 列表 #  node-exporter mysqld-exporter process-exporter cadvisor windows-exporter postgres-exporter mongodb-exporter redis-exporter memcached-exporter kafka-exporter elasticsearch-exporter consul-exporter dnsmasq-exporter  内置exporter的配置项说明 # grafana-agent 本身的配置 # server: log_level: info http_listen_port: 12345  grafana-agent 抓取 metrics 的相关配置（类似于prometheus的scrape_configs） # metrics: global: scrape_interval: 15s scrape_timeout: 10s remote_write: - url: https://n9e-server:19000/prometheus/v1/write basic_auth: username: \u0026lt;string\u0026gt; password: \u0026lt;string\u0026gt; # grafana-agent integration 相关的配置 integrations: ## grafana-agent self-integration ## grafana-agent 本身的metrics 采集，这也是一个内嵌的 integration，可以选择启用或者关闭。 agent: ### 是否开启针对grafana-agent 自身的integration，允许grafana-agent自动采集和发送其自身的metrics [enabled: \u0026lt;boolean\u0026gt; | default = false] # Sets an explicit value for the instance label when the integration is # self-scraped. Overrides inferred values. # # The default value for this integration is inferred from the agent hostname # and HTTP listen port, delimited by a colon. [instance: \u0026lt;string\u0026gt;] # Automatically collect metrics from this integration. If disabled, # the agent integration will be run but not scraped and thus not # remote_written. Metrics for the integration will be exposed at # /integrations/agent/metrics and can be scraped by an external process. ### 这个配置项如果设置为false，那么 /integrations/agent/metrics 的数据并不会被自动抓取和发送 ### 但是，该接口 /integrations/agent/metrics 的数据仍然支持被外部的抓取进程所抓取 [scrape_integration: \u0026lt;boolean\u0026gt; | default = \u0026lt;integrations_config.scrape_integrations\u0026gt;] # How often should the metrics be collected? Defaults to # prometheus.global.scrape_interval. [scrape_interval: \u0026lt;duration\u0026gt; | default = \u0026lt;global_config.scrape_interval\u0026gt;] # The timeout before considering the scrape a failure. Defaults to # prometheus.global.scrape_timeout. [scrape_timeout: \u0026lt;duration\u0026gt; | default = \u0026lt;global_config.scrape_timeout\u0026gt;] # How frequent to truncate the WAL for this integration. [wal_truncate_frequency: \u0026lt;duration\u0026gt; | default = \u0026quot;60m\u0026quot;] # Allows for relabeling labels on the target. relabel_configs: [- \u0026lt;relabel_config\u0026gt; ... ] # Relabel metrics coming from the integration, allowing to drop series # from the integration that you don't care about. metric_relabel_configs: [ - \u0026lt;relabel_config\u0026gt; ... ] # Client TLS Configuration # Client Cert/Key Values need to be defined if the server is requesting a certificate # (Client Auth Type = RequireAndVerifyClientCert || RequireAnyClientCert). http_tls_config: \u0026lt;tls_config\u0026gt; ## 控制内嵌的 node_exporter 工作逻辑 node_exporter: \u0026lt;node_exporter_config\u0026gt; ## 控制内嵌的 process_exporter 工作逻辑 process_exporter: \u0026lt;process_exporter_config\u0026gt; ## 控制内嵌的 mysqld_exporter 工作逻辑 mysqld_exporter: \u0026lt;mysqld_exporter_config\u0026gt; ## 控制内嵌的 redis_exporter 工作逻辑 redis_exporter: \u0026lt;redis_exporter_config\u0026gt; ## 控制内嵌的 dnsmasq_exporter 工作逻辑 dnsmasq_exporter: \u0026lt;dnsmasq_exporter_config\u0026gt; ## 控制内嵌的 elasticsearch_exporter 工作逻辑 elasticsearch_expoter: \u0026lt;elasticsearch_expoter_config\u0026gt; # Controls the memcached_exporter integration memcached_exporter: \u0026lt;memcached_exporter_config\u0026gt; ## 控制内嵌的 postgres_exporter 工作逻辑 postgres_exporter: \u0026lt;postgres_exporter_config\u0026gt; ## 控制内嵌的 statsd_exporter 工作逻辑 statsd_exporter: \u0026lt;statsd_exporter_config\u0026gt; ## 控制内嵌的 consul_exporter 工作逻辑 consul_exporter: \u0026lt;consul_exporter_config\u0026gt; ## 控制内嵌的 windows_exporter 工作逻辑 windows_exporter: \u0026lt;windows_exporter_config\u0026gt; ## 控制内嵌的 kafka_exporter 工作逻辑 kafka_exporter: \u0026lt;kafka_exporter_config\u0026gt; ## 控制内嵌的 mongodb_exporter 工作逻辑 mongodb_exporter: \u0026lt;mongodb_exporter_config\u0026gt; ## 控制内嵌的 github_exporter 工作逻辑 github_exporter: \u0026lt;github_exporter_config\u0026gt; # Automatically collect metrics from enabled integrations. If disabled, # integrations will be run but not scraped and thus not remote_written. Metrics # for integrations will be exposed at /integrations/\u0026lt;integration_key\u0026gt;/metrics # and can be scraped by an external process. ## 如果设置为false，相关的exporter metrics接口仍会被暴露出来，但是grafana-agent不会去主动抓取和发送 [scrape_integrations: \u0026lt;boolean\u0026gt; | default = true] # Extra labels to add to all samples coming from integrations. labels: { \u0026lt;string\u0026gt;: \u0026lt;string\u0026gt; } # The period to wait before restarting an integration that exits with an # error. [integration_restart_backoff: \u0026lt;duration\u0026gt; | default = \u0026quot;5s\u0026quot;] # A list of remote_write targets. Defaults to global_config.remote_write. # If provided, overrides the global defaults. prometheus_remote_write: - [\u0026lt;remote_write\u0026gt;]  通过grafana-agent抓取第三方exporter并收集 # 如文章开头所述，对于未嵌入到grafana-agent中的exporter，则可以在grafana-agent中配置scrape_configs来完成抓取和收集，其配置形式完全等同于 prometheus scrape_configs。\ngrafana-agent中关于自定义配置scrape_configs的详细说明如下：\n# scrape_configs like prometheus style configs: scrape_timeout: 10s # 比如，我们可以配置抓取 grafana-agent 本身的 metrics ： http://127.0.0.1:12345/metrics - name: grafana-agent host_filter: false scrape_configs: - job_name: grafana-agent static_configs: - targets: ['127.0.0.1:12345'] remote_write: - url: http://localhost:9090/api/v1/write # 再比如,我们也可以配置抓取您的应用程序暴露的metrics接口： http://helloworld.app:8088/metrics - name: outside-exporters host_filter: false scrape_configs: - job_name: prometheus static_configs: - targets: ['127.0.0.1:9090'] labels: cluster: 'fc-monitoring' remote_write: - url: https://n9e-server:19000/prometheus/v1/write basic_auth: username: \u0026lt;string\u0026gt; password: \u0026lt;string\u0026gt;  "}),e.add({id:37,href:"/docs/appendix/grafana-agent/integrations/node-exporter-config/",title:"Node Exporter",description:"grafana-agent 内置了 node_exporter, 可以通过在配置文件中 integrations 部分定义 node_exporter_config 来开启该功能。\n配置并启用node_exporter # 下面是开启了node_exporter的配置文件示例，生成的配置文件保存为 ./grafana-agent-cfg.yaml:\ncat \u0026lt;\u0026lt;EOF \u0026gt; ./grafana-agent-cfg.yaml # grafana-agent 本身的配置 server: log_level: info http_listen_port: 12345 # grafana-agent 抓取 metrics 的相关配置（类似于prometheus的scrape_configs） metrics: global: scrape_interval: 15s scrape_timeout: 10s remote_write: - url: https://n9e-server:19000/prometheus/v1/write basic_auth: username: \u0026lt;string\u0026gt; password: \u0026lt;string\u0026gt; integrations: node_exporter: enabled: true EOF  注意： remote_write 可以配置在 global 部分，也可以针对每个 integration 单独配置不同的remote_write 地址。\n重启grafana-agent后，通过以下两个命令，验证 node_exporter 工作是否符合预期。\ncurl http://localhost:12345/integrations/node_exporter/metrics ，预期输出如下内容：\nnode_boot_time_seconds 1.643256088e+09 node_context_switches_total 1.5136425575e+10 node_cooling_device_cur_state{name=\u0026quot;0\u0026quot;,type=\u0026quot;Processor\u0026quot;} 0 node_cooling_device_cur_state{name=\u0026quot;1\u0026quot;,type=\u0026quot;Processor\u0026quot;} 0 node_cooling_device_cur_state{name=\u0026quot;2\u0026quot;,type=\u0026quot;Processor\u0026quot;} 0 node_cooling_device_cur_state{name=\u0026quot;3\u0026quot;,type=\u0026quot;Processor\u0026quot;} 0 node_cooling_device_max_state{name=\u0026quot;0\u0026quot;,type=\u0026quot;Processor\u0026quot;} 0 node_cooling_device_max_state{name=\u0026quot;1\u0026quot;,type=\u0026quot;Processor\u0026quot;} 0 node_cooling_device_max_state{name=\u0026quot;2\u0026quot;,type=\u0026quot;Processor\u0026quot;} 0 node_cooling_device_max_state{name=\u0026quot;3\u0026quot;,type=\u0026quot;Processor\u0026quot;} 0 node_cpu_seconds_total{cpu=\u0026quot;0\u0026quot;,mode=\u0026quot;idle\u0026quot;} 1.",content:"grafana-agent 内置了 node_exporter, 可以通过在配置文件中 integrations 部分定义 node_exporter_config 来开启该功能。\n配置并启用node_exporter # 下面是开启了node_exporter的配置文件示例，生成的配置文件保存为 ./grafana-agent-cfg.yaml:\ncat \u0026lt;\u0026lt;EOF \u0026gt; ./grafana-agent-cfg.yaml # grafana-agent 本身的配置 server: log_level: info http_listen_port: 12345 # grafana-agent 抓取 metrics 的相关配置（类似于prometheus的scrape_configs） metrics: global: scrape_interval: 15s scrape_timeout: 10s remote_write: - url: https://n9e-server:19000/prometheus/v1/write basic_auth: username: \u0026lt;string\u0026gt; password: \u0026lt;string\u0026gt; integrations: node_exporter: enabled: true EOF  注意： remote_write 可以配置在 global 部分，也可以针对每个 integration 单独配置不同的remote_write 地址。\n重启grafana-agent后，通过以下两个命令，验证 node_exporter 工作是否符合预期。\ncurl http://localhost:12345/integrations/node_exporter/metrics ，预期输出如下内容：\nnode_boot_time_seconds 1.643256088e+09 node_context_switches_total 1.5136425575e+10 node_cooling_device_cur_state{name=\u0026quot;0\u0026quot;,type=\u0026quot;Processor\u0026quot;} 0 node_cooling_device_cur_state{name=\u0026quot;1\u0026quot;,type=\u0026quot;Processor\u0026quot;} 0 node_cooling_device_cur_state{name=\u0026quot;2\u0026quot;,type=\u0026quot;Processor\u0026quot;} 0 node_cooling_device_cur_state{name=\u0026quot;3\u0026quot;,type=\u0026quot;Processor\u0026quot;} 0 node_cooling_device_max_state{name=\u0026quot;0\u0026quot;,type=\u0026quot;Processor\u0026quot;} 0 node_cooling_device_max_state{name=\u0026quot;1\u0026quot;,type=\u0026quot;Processor\u0026quot;} 0 node_cooling_device_max_state{name=\u0026quot;2\u0026quot;,type=\u0026quot;Processor\u0026quot;} 0 node_cooling_device_max_state{name=\u0026quot;3\u0026quot;,type=\u0026quot;Processor\u0026quot;} 0 node_cpu_seconds_total{cpu=\u0026quot;0\u0026quot;,mode=\u0026quot;idle\u0026quot;} 1.66906519e+06 node_cpu_seconds_total{cpu=\u0026quot;0\u0026quot;,mode=\u0026quot;iowait\u0026quot;} 5031.48 node_cpu_seconds_total{cpu=\u0026quot;0\u0026quot;,mode=\u0026quot;irq\u0026quot;} 0 node_cpu_seconds_total{cpu=\u0026quot;0\u0026quot;,mode=\u0026quot;nice\u0026quot;} 82.84 node_cpu_seconds_total{cpu=\u0026quot;0\u0026quot;,mode=\u0026quot;softirq\u0026quot;} 2332.39  curl http://localhost:12345/agent/api/v1/targets | jq，预期输出如下内容：\n{ \u0026quot;status\u0026quot;: \u0026quot;success\u0026quot;, \u0026quot;data\u0026quot;: [ { \u0026quot;instance\u0026quot;: \u0026quot;b81030837ec7f1d162489cb4009325c9\u0026quot;, \u0026quot;target_group\u0026quot;: \u0026quot;integrations/node_exporter\u0026quot;, \u0026quot;endpoint\u0026quot;: \u0026quot;http://127.0.0.1:12345/integrations/node_exporter/metrics\u0026quot;, \u0026quot;state\u0026quot;: \u0026quot;up\u0026quot;, \u0026quot;labels\u0026quot;: { \u0026quot;agent_hostname\u0026quot;: \u0026quot;tt-fc-dev01.nj\u0026quot;, \u0026quot;instance\u0026quot;: \u0026quot;tt-fc-dev01.nj:12345\u0026quot;, \u0026quot;job\u0026quot;: \u0026quot;integrations/node_exporter\u0026quot; }, \u0026quot;discovered_labels\u0026quot;: { \u0026quot;__address__\u0026quot;: \u0026quot;127.0.0.1:12345\u0026quot;, \u0026quot;__metrics_path__\u0026quot;: \u0026quot;/integrations/node_exporter/metrics\u0026quot;, \u0026quot;__scheme__\u0026quot;: \u0026quot;http\u0026quot;, \u0026quot;__scrape_interval__\u0026quot;: \u0026quot;15s\u0026quot;, \u0026quot;__scrape_timeout__\u0026quot;: \u0026quot;10s\u0026quot;, \u0026quot;agent_hostname\u0026quot;: \u0026quot;tt-fc-dev01.nj\u0026quot;, \u0026quot;job\u0026quot;: \u0026quot;integrations/node_exporter\u0026quot; }, \u0026quot;last_scrape\u0026quot;: \u0026quot;2022-02-16T18:53:08.79288957+08:00\u0026quot;, \u0026quot;scrape_duration_ms\u0026quot;: 20, \u0026quot;scrape_error\u0026quot;: \u0026quot;\u0026quot; }, { \u0026quot;instance\u0026quot;: \u0026quot;b81030837ec7f1d162489cb4009325c9\u0026quot;, \u0026quot;target_group\u0026quot;: \u0026quot;local_scrape\u0026quot;, \u0026quot;endpoint\u0026quot;: \u0026quot;http://127.0.0.1:12345/metrics\u0026quot;, \u0026quot;state\u0026quot;: \u0026quot;up\u0026quot;, \u0026quot;labels\u0026quot;: { \u0026quot;cluster\u0026quot;: \u0026quot;txnjdev01\u0026quot;, \u0026quot;instance\u0026quot;: \u0026quot;127.0.0.1:12345\u0026quot;, \u0026quot;job\u0026quot;: \u0026quot;local_scrape\u0026quot; }, \u0026quot;discovered_labels\u0026quot;: { \u0026quot;__address__\u0026quot;: \u0026quot;127.0.0.1:12345\u0026quot;, \u0026quot;__metrics_path__\u0026quot;: \u0026quot;/metrics\u0026quot;, \u0026quot;__scheme__\u0026quot;: \u0026quot;http\u0026quot;, \u0026quot;__scrape_interval__\u0026quot;: \u0026quot;15s\u0026quot;, \u0026quot;__scrape_timeout__\u0026quot;: \u0026quot;10s\u0026quot;, \u0026quot;cluster\u0026quot;: \u0026quot;txnjdev01\u0026quot;, \u0026quot;job\u0026quot;: \u0026quot;local_scrape\u0026quot; }, \u0026quot;last_scrape\u0026quot;: \u0026quot;2022-02-16T18:53:22.336820442+08:00\u0026quot;, \u0026quot;scrape_duration_ms\u0026quot;: 4, \u0026quot;scrape_error\u0026quot;: \u0026quot;\u0026quot; } ] }  可以看到，上面的返回结果的 targets 列表中，已经新增了一个instance，其 job 为 integrations/node_exporter，这说明 node_exporter 已经在正常工作了。\n注意：如果 grafana-agent 是运行在容器中时，那么要做以下修改调整：\n 确保在运行容器时，将宿主机的相关目录映射到容器中，如下所示，即 -v \u0026quot;/:/host/root\u0026quot;、 -v \u0026quot;/sys:/host/sys\u0026quot;、-v \u0026quot;/proc:/host/proc\u0026quot;.  docker run \\ --net=\u0026quot;host\u0026quot; \\ --pid=\u0026quot;host\u0026quot; \\ --cap-add=SYS_TIME \\ -d \\ -v \u0026quot;/:/host/root:ro\u0026quot; \\ -v \u0026quot;/sys:/host/sys:ro\u0026quot; \\ -v \u0026quot;/proc:/host/proc:ro\u0026quot; \\ -v /tmp/grafana-agent:/etc/agent/data \\ -v /tmp/grafana-agent-config.yaml:/etc/agent/agent.yaml \\ grafana/agent:v0.23.0 \\ --config.file=/etc/agent/agent.yaml \\ --metrics.wal-directory=/etc/agent/data  其中，配置文件 /tmp/grafana-agent-config.yaml 中 node_exporter 部分要指定 rootfs/sysfs/procfs 在容器中的路径，您可以运行以下命令生成该测试配置文件（当然，您需要把 remote_write 替换为适合您的地址）。  cat \u0026lt;\u0026lt;EOF \u0026gt; /tmp/grafana-agent-config.yaml server: log_level: info http_listen_port: 12345 metrics: global: scrape_interval: 15s scrape_timeout: 10s remote_write: - url: https://n9e-server:19000/prometheus/v1/write basic_auth: username: \u0026lt;string\u0026gt; password: \u0026lt;string\u0026gt; integrations: node_exporter: enabled: true rootfs_path: /host/root sysfs_path: /host/sys procfs_path: /host/proc EOF  注意：如果 grafana-agent 是运行在 K8s 环境中，那么调整步骤如下：\n 推荐将 grafana-agent 的配置文件存储在configmap中, manifest文件如下：  cat \u0026lt;\u0026lt;EOF | apiVersion: v1 kind: ConfigMap metadata: name: grafana-agent namespace: ${NAMESPACE} data: agent.yaml: | server: log_level: info http_listen_port: 12345 metrics: global: scrape_interval: 15s remote_write: - url: 'https://n9e-server:19000/prometheus/v1/write' basic_auth: username: ${FC_USERNAME} password: ${FC_PASSWORD} integrations: agent: enabled: true node_exporter: enabled: true EOF envsubst | kubectl apply -f - kubectl describe configmap grafana-agent  生成grafana-agent的pod manifest文件如下，并创建相应Pod实例：  cat \u0026lt;\u0026lt; EOF | apiVersion: v1 kind: Pod metadata: name: grafana-agent namespace: ${NAMESPACE} spec: containers: - image: grafana/agent:v0.23.0 name: grafana-agent args: - --config.file=/fcetc/agent.yaml - --metrics.wal-directory=/etc/agent/data securityContext: capabilities: add: [\u0026quot;SYS_TIME\u0026quot;] privileged: true runAsUser: 0 volumeMounts: - name: rootfs mountPath: /host/root readOnly: true - name: sysfs mountPath: /host/sys readOnly: true - name: procfs mountPath: /host/proc readOnly: true - name: fccfg mountPath: /fcetc hostPID: true hostNetwork: true dnsPolicy: ClusterFirstWithHostNet volumes: - name: rootfs hostPath: path: / - name: sysfs hostPath: path: /sys - name: procfs hostPath: path: /proc - name: fccfg configMap: name: grafana-agent EOF envsubst |kubectl apply -f - kubectl logs grafana-agent #查看 grafana-agent 的日志  node_exporter采集的关键指标解析 # # SYSTEM # CPU context switch 次数 node_context_switches_total: context_switches # Interrupts 次数 node_intr_total: Interrupts # 运行的进程数 node_procs_running: Processes in runnable state # 熵池大小 node_entropy_available_bits: Entropy available to random number generators node_time_seconds: System time in seconds since epoch (1970) node_boot_time_seconds: Node boot time, in unixtime # CPU node_cpu_seconds_total: Seconds the CPUs spent in each mode node_load1: cpu load 1m node_load5: cpu load 5m node_load15: cpu load 15m # MEM # 内核态 # 用户追踪已从交换区获取但尚未修改的页面的内存 node_memory_SwapCached_bytes: Memory that keeps track of pages that have been fetched from swap but not yet been modified # 内核用于缓存数据结构供自己使用的内存 node_memory_Slab_bytes: Memory used by the kernel to cache data structures for its own use # slab中可回收的部分 node_memory_SReclaimable_bytes: SReclaimable - Part of Slab, that might be reclaimed, such as caches # slab中不可回收的部分 node_memory_SUnreclaim_bytes: Part of Slab, that cannot be reclaimed on memory pressure # Vmalloc内存区的大小 node_memory_VmallocTotal_bytes: Total size of vmalloc memory area # vmalloc已分配的内存，虚拟地址空间上的连续的内存 node_memory_VmallocUsed_bytes: Amount of vmalloc area which is used # vmalloc区可用的连续最大快的大小，通过此指标可以知道vmalloc可分配连续内存的最大值 node_memory_VmallocChunk_bytes: Largest contigious block of vmalloc area which is free # 内存的硬件故障删除掉的内存页的总大小 node_memory_HardwareCorrupted_bytes: Amount of RAM that the kernel identified as corrupted / not working # 用于在虚拟和物理内存地址之间映射的内存 node_memory_PageTables_bytes: Memory used to map between virtual and physical memory addresses (gauge) # 内核栈内存，常驻内存，不可回收 node_memory_KernelStack_bytes: Kernel memory stack. This is not reclaimable # 用来访问高端内存，复制高端内存的临时buffer，称为“bounce buffering”，会降低I/O 性能 node_memory_Bounce_bytes: Memory used for block device bounce buffers #用户态 # 单个巨页大小 node_memory_Hugepagesize_bytes: Huge Page size # 系统分配的常驻巨页数 node_memory_HugePages_Total: Total size of the pool of huge pages # 系统空闲的巨页数 node_memory_HugePages_Free: Huge pages in the pool that are not yet allocated # 进程已申请但未使用的巨页数 node_memory_HugePages_Rsvd: Huge pages for which a commitment to allocate from the pool has been made, but no allocation # 超过系统设定的常驻HugePages数量的个数 node_memory_HugePages_Surp: Huge pages in the pool above the value in /proc/sys/vm/nr_hugepages # 透明巨页 Transparent HugePages (THP) node_memory_AnonHugePages_bytes: Memory in anonymous huge pages # inactivelist中的File-backed内存 node_memory_Inactive_file_bytes: File-backed memory on inactive LRU list # inactivelist中的Anonymous内存 node_memory_Inactive_anon_bytes: Anonymous and swap cache on inactive LRU list, including tmpfs (shmem) # activelist中的File-backed内存 node_memory_Active_file_bytes: File-backed memory on active LRU list # activelist中的Anonymous内存 node_memory_Active_anon_bytes: Anonymous and swap cache on active least-recently-used (LRU) list, including tmpfs # 禁止换出的页，对应 Unevictable 链表 node_memory_Unevictable_bytes: Amount of unevictable memory that can't be swapped out for a variety of reasons # 共享内存 node_memory_Shmem_bytes: Used shared memory (shared between several processes, thus including RAM disks) # 匿名页内存大小 node_memory_AnonPages_bytes: Memory in user pages not backed by files # 被关联的内存页大小 node_memory_Mapped_bytes: Used memory in mapped pages files which have been mmaped, such as libraries # file-backed内存页缓存大小 node_memory_Cached_bytes: Parked file data (file content) cache # 系统中有多少匿名页曾经被swap-out、现在又被swap-in并且swap-in之后页面中的内容一直没发生变化 node_memory_SwapCached_bytes: Memory that keeps track of pages that have been fetched from swap but not yet been modified # 被mlock()系统调用锁定的内存大小 node_memory_Mlocked_bytes: Size of pages locked to memory using the mlock() system call # 块设备(block device)所占用的缓存页 node_memory_Buffers_bytes: Block device (e.g. harddisk) cache node_memory_SwapTotal_bytes: Memory information field SwapTotal_bytes node_memory_SwapFree_bytes: Memory information field SwapFree_bytes # DISK node_filesystem_files_free: Filesystem space available to non-root users in byte node_filesystem_free_bytes: Filesystem free space in bytes node_filesystem_size_bytes: Filesystem size in bytes node_filesystem_files_free: Filesystem total free file nodes node_filesystem_files: Filesystem total free file nodes node_filefd_maximum: Max open files node_filefd_allocated: Open files node_filesystem_readonly: Filesystem read-only status node_filesystem_device_error: Whether an error occurred while getting statistics for the given device node_disk_reads_completed_total: The total number of reads completed successfully node_disk_writes_completed_total: The total number of writes completed successfully node_disk_reads_merged_total: The number of reads merged node_disk_writes_merged_total: The number of writes merged node_disk_read_bytes_total: The total number of bytes read successfully node_disk_written_bytes_total: The total number of bytes written successfully node_disk_io_time_seconds_total: Total seconds spent doing I/Os node_disk_read_time_seconds_total: The total number of seconds spent by all reads node_disk_write_time_seconds_total: The total number of seconds spent by all writes node_disk_io_time_weighted_seconds_total: The weighted of seconds spent doing I/Os # NET node_network_receive_bytes_total: Network device statistic receive_bytes (counter) node_network_transmit_bytes_total: Network device statistic transmit_bytes (counter) node_network_receive_packets_total: Network device statistic receive_bytes node_network_transmit_packets_total: Network device statistic transmit_bytes node_network_receive_errs_total: Network device statistic receive_errs node_network_transmit_errs_total: Network device statistic transmit_errs node_network_receive_drop_total: Network device statistic receive_drop node_network_transmit_drop_total: Network device statistic transmit_drop node_nf_conntrack_entries: Number of currently allocated flow entries for connection tracking node_sockstat_TCP_alloc: Number of TCP sockets in state alloc node_sockstat_TCP_inuse: Number of TCP sockets in state inuse node_sockstat_TCP_orphan: Number of TCP sockets in state orphan node_sockstat_TCP_tw: Number of TCP sockets in state tw node_netstat_Tcp_CurrEstab: Statistic TcpCurrEstab node_sockstat_sockets_used: Number of IPv4 sockets in use  node_expoter integration 完整的配置项说明 # # Enables the node_exporter integration, allowing the Agent to automatically # collect system metrics from the host UNIX system. [enabled: \u0026lt;boolean\u0026gt; | default = false] # Sets an explicit value for the instance label when the integration is # self-scraped. Overrides inferred values. # # The default value for this integration is inferred from the agent hostname # and HTTP listen port, delimited by a colon. [instance: \u0026lt;string\u0026gt;] # Automatically collect metrics from this integration. If disabled, # the node_exporter integration will be run but not scraped and thus not remote-written. Metrics for the # integration will be exposed at /integrations/node_exporter/metrics and can # be scraped by an external process. [scrape_integration: \u0026lt;boolean\u0026gt; | default = \u0026lt;integrations_config.scrape_integrations\u0026gt;] # How often should the metrics be collected? Defaults to # prometheus.global.scrape_interval. [scrape_interval: \u0026lt;duration\u0026gt; | default = \u0026lt;global_config.scrape_interval\u0026gt;] # The timtout before considering the scrape a failure. Defaults to # prometheus.global.scrape_timeout. [scrape_timeout: \u0026lt;duration\u0026gt; | default = \u0026lt;global_config.scrape_timeout\u0026gt;] # Allows for relabeling labels on the target. relabel_configs: [- \u0026lt;relabel_config\u0026gt; ... ] # Relabel metrics coming from the integration, allowing to drop series # from the integration that you don't care about. metric_relabel_configs: [ - \u0026lt;relabel_config\u0026gt; ... ] # How frequent to truncate the WAL for this integration. [wal_truncate_frequency: \u0026lt;duration\u0026gt; | default = \u0026quot;60m\u0026quot;] # Monitor the exporter itself and include those metrics in the results. [include_exporter_metrics: \u0026lt;boolean\u0026gt; | default = false] # Optionally defines the the list of enabled-by-default collectors. # Anything not provided in the list below will be disabled by default, # but requires at least one element to be treated as defined. # # This is useful if you have a very explicit set of collectors you wish # to run. set_collectors: - [\u0026lt;string\u0026gt;] # Additional collectors to enable on top of the default set of enabled # collectors or on top of the list provided by set_collectors. # # This is useful if you have a few collectors you wish to run that are # not enabled by default, but do not want to explicitly provide an entire # list through set_collectors. enable_collectors: - [\u0026lt;string\u0026gt;] # Additional collectors to disable on top of the default set of disabled # collectors. Takes precedence over enable_collectors. # # This is useful if you have a few collectors you do not want to run that # are enabled by default, but do not want to explicitly provide an entire # list through set_collectors. disable_collectors: - [\u0026lt;string\u0026gt;] # procfs mountpoint. [procfs_path: \u0026lt;string\u0026gt; | default = \u0026quot;/proc\u0026quot;] # sysfs mountpoint. [sysfs_path: \u0026lt;string\u0026gt; | default = \u0026quot;/sys\u0026quot;] # rootfs mountpoint. If running in docker, the root filesystem of the host # machine should be mounted and this value should be changed to the mount # directory. [rootfs_path: \u0026lt;string\u0026gt; | default = \u0026quot;/\u0026quot;] # Expose expensive bcache priority stats. [enable_bcache_priority_stats: \u0026lt;boolean\u0026gt;] # Regexp of `bugs` field in cpu info to filter. [cpu_bugs_include: \u0026lt;string\u0026gt;] # Enable the node_cpu_guest_seconds_total metric. [enable_cpu_guest_seconds_metric: \u0026lt;boolean\u0026gt; | default = true] # Enable the cpu_info metric for the cpu collector. [enable_cpu_info_metric: \u0026lt;boolean\u0026gt; | default = true] # Regexp of `flags` field in cpu info to filter. [cpu_flags_include: \u0026lt;string\u0026gt;] # Regexmp of devices to ignore for diskstats. [diskstats_ignored_devices: \u0026lt;string\u0026gt; | default = \u0026quot;^(ram|loop|fd|(h|s|v|xv)d[a-z]|nvme\\\\d+n\\\\d+p)\\\\d+$\u0026quot;] # Regexp of ethtool devices to exclude (mutually exclusive with ethtool_device_include) [ethtool_device_exclude: \u0026lt;string\u0026gt;] # Regexp of ethtool devices to include (mutually exclusive with ethtool_device_exclude) [ethtool_device_include: \u0026lt;string\u0026gt;] # Regexp of ethtool stats to include. [ethtool_metrics_include: \u0026lt;string\u0026gt; | default = \u0026quot;.*\u0026quot;] # Regexp of mount points to ignore for filesystem collector. [filesystem_mount_points_exclude: \u0026lt;string\u0026gt; | default = \u0026quot;^/(dev|proc|sys|var/lib/docker/.+)($|/)\u0026quot;] # Regexp of filesystem types to ignore for filesystem collector. [filesystem_fs_types_exclude: \u0026lt;string\u0026gt; | default = \u0026quot;^(autofs|binfmt_misc|bpf|cgroup2?|configfs|debugfs|devpts|devtmpfs|fusectl|hugetlbfs|iso9660|mqueue|nsfs|overlay|proc|procfs|pstore|rpc_pipefs|securityfs|selinuxfs|squashfs|sysfs|tracefs)$\u0026quot;] # How long to wait for a mount to respond before marking it as stale. [filesystem_mount_timeout: \u0026lt;duration\u0026gt; | default = \u0026quot;5s\u0026quot;] # Array of IPVS backend stats labels. # # The default is [local_address, local_port, remote_address, remote_port, proto, local_mark]. ipvs_backend_labels: [- \u0026lt;string\u0026gt;] # NTP server to use for ntp collector [ntp_server: \u0026lt;string\u0026gt; | default = \u0026quot;127.0.0.1\u0026quot;] # NTP protocol version [ntp_protocol_version: \u0026lt;int\u0026gt; | default = 4] # Certify that the server address is not a public ntp server. [ntp_server_is_local: \u0026lt;boolean\u0026gt; | default = false] # IP TTL to use wile sending NTP query. [ntp_ip_ttl: \u0026lt;int\u0026gt; | default = 1] # Max accumulated distance to the root. [ntp_max_distance: \u0026lt;duration\u0026gt; | default = \u0026quot;3466080us\u0026quot;] # Offset between local clock and local ntpd time to tolerate. [ntp_local_offset_tolerance: \u0026lt;duration\u0026gt; | default = \u0026quot;1ms\u0026quot;] # Regexp of net devices to ignore for netclass collector. [netclass_ignored_devices: \u0026lt;string\u0026gt; | default = \u0026quot;^$\u0026quot;] # Ignore net devices with invalid speed values. This will default to true in # node_exporter 2.0. [netclass_ignore_invalid_speed_device: \u0026lt;boolean\u0026gt; | default = false] # Enable collecting address-info for every device. [netdev_address_info: \u0026lt;boolean\u0026gt;] # Regexp of net devices to exclude (mutually exclusive with include) [netdev_device_exclude: \u0026lt;string\u0026gt; | default = \u0026quot;\u0026quot;] # Regexp of net devices to include (mutually exclusive with exclude) [netdev_device_include: \u0026lt;string\u0026gt; | default = \u0026quot;\u0026quot;] # Regexp of fields to return for netstat collector. [netstat_fields: \u0026lt;string\u0026gt; | default = \u0026quot;^(.*_(InErrors|InErrs)|Ip_Forwarding|Ip(6|Ext)_(InOctets|OutOctets)|Icmp6?_(InMsgs|OutMsgs)|TcpExt_(Listen.*|Syncookies.*|TCPSynRetrans|TCPTimeouts)|Tcp_(ActiveOpens|InSegs|OutSegs|OutRsts|PassiveOpens|RetransSegs|CurrEstab)|Udp6?_(InDatagrams|OutDatagrams|NoPorts|RcvbufErrors|SndbufErrors))$\u0026quot;] # List of CPUs from which perf metrics should be collected. [perf_cpus: \u0026lt;string\u0026gt; | default = \u0026quot;\u0026quot;] # Array of perf tracepoints that should be collected. perf_tracepoint: [- \u0026lt;string\u0026gt;] # Regexp of power supplies to ignore for the powersupplyclass collector. [powersupply_ignored_supplies: \u0026lt;string\u0026gt; | default = \u0026quot;^$\u0026quot;] # Path to runit service directory. [runit_service_dir: \u0026lt;string\u0026gt; | default = \u0026quot;/etc/service\u0026quot;] # XML RPC endpoint for the supervisord collector. # # Setting SUPERVISORD_URL in the environment will override the default value. # An explicit value in the YAML config takes precedence over the environment # variable. [supervisord_url: \u0026lt;string\u0026gt; | default = \u0026quot;http://localhost:9001/RPC2\u0026quot;] # Regexp of systemd units to include. Units must both match include and not # match exclude to be collected. [systemd_unit_include: \u0026lt;string\u0026gt; | default = \u0026quot;.+\u0026quot;] # Regexp of systemd units to exclude. Units must both match include and not # match exclude to be collected. [systemd_unit_exclude: \u0026lt;string\u0026gt; | default = \u0026quot;.+\\\\.(automount|device|mount|scope|slice)\u0026quot;] # Enables service unit tasks metrics unit_tasks_current and unit_tasks_max [systemd_enable_task_metrics: \u0026lt;boolean\u0026gt; | default = false] # Enables service unit metric service_restart_total [systemd_enable_restarts_metrics: \u0026lt;boolean\u0026gt; | default = false] # Enables service unit metric unit_start_time_seconds [systemd_enable_start_time_metrics: \u0026lt;boolean\u0026gt; | default = false] # Regexp of tapestats devices to ignore. [tapestats_ignored_devices: \u0026lt;string\u0026gt; | default = \u0026quot;^$\u0026quot;] # Directory to read *.prom files from for the textfile collector. [textfile_directory: \u0026lt;string\u0026gt; | default = \u0026quot;\u0026quot;] # Regexp of fields to return for the vmstat collector. [vmstat_fields: \u0026lt;string\u0026gt; | default = \u0026quot;^(oom_kill|pgpg|pswp|pg.*fault).*\u0026quot;]  node_exporter 自定义 collectors # 您可以在 integrations node_export 配置中，通过设置和修改 set_collectors enable_collectors disable_collectors，以控制哪些 collector 生效。\nconst ( CollectorARP = \u0026quot;arp\u0026quot; CollectorBCache = \u0026quot;bcache\u0026quot; CollectorBTRFS = \u0026quot;btrfs\u0026quot; CollectorBonding = \u0026quot;bonding\u0026quot; CollectorBootTime = \u0026quot;boottime\u0026quot; CollectorBuddyInfo = \u0026quot;buddyinfo\u0026quot; CollectorCPU = \u0026quot;cpu\u0026quot; CollectorCPUFreq = \u0026quot;cpufreq\u0026quot; CollectorConntrack = \u0026quot;conntrack\u0026quot; CollectorDMI = \u0026quot;dmi\u0026quot; CollectorDRBD = \u0026quot;drbd\u0026quot; CollectorDRM = \u0026quot;drm\u0026quot; CollectorDevstat = \u0026quot;devstat\u0026quot; CollectorDiskstats = \u0026quot;diskstats\u0026quot; CollectorEDAC = \u0026quot;edac\u0026quot; CollectorEntropy = \u0026quot;entropy\u0026quot; CollectorEthtool = \u0026quot;ethtool\u0026quot; CollectorExec = \u0026quot;exec\u0026quot; CollectorFibrechannel = \u0026quot;fibrechannel\u0026quot; CollectorFileFD = \u0026quot;filefd\u0026quot; CollectorFilesystem = \u0026quot;filesystem\u0026quot; CollectorHWMon = \u0026quot;hwmon\u0026quot; CollectorIPVS = \u0026quot;ipvs\u0026quot; CollectorInfiniband = \u0026quot;infiniband\u0026quot; CollectorInterrupts = \u0026quot;interrupts\u0026quot; CollectorKSMD = \u0026quot;ksmd\u0026quot; CollectorLnstat = \u0026quot;lnstat\u0026quot; CollectorLoadAvg = \u0026quot;loadavg\u0026quot; CollectorLogind = \u0026quot;logind\u0026quot; CollectorMDADM = \u0026quot;mdadm\u0026quot; CollectorMeminfo = \u0026quot;meminfo\u0026quot; CollectorMeminfoNuma = \u0026quot;meminfo_numa\u0026quot; CollectorMountstats = \u0026quot;mountstats\u0026quot; CollectorNFS = \u0026quot;nfs\u0026quot; CollectorNFSD = \u0026quot;nfsd\u0026quot; CollectorNTP = \u0026quot;ntp\u0026quot; CollectorNVME = \u0026quot;nvme\u0026quot; CollectorNetclass = \u0026quot;netclass\u0026quot; CollectorNetdev = \u0026quot;netdev\u0026quot; CollectorNetstat = \u0026quot;netstat\u0026quot; CollectorNetworkRoute = \u0026quot;network_route\u0026quot; CollectorOS = \u0026quot;os\u0026quot; CollectorPerf = \u0026quot;perf\u0026quot; CollectorPowersuppply = \u0026quot;powersupplyclass\u0026quot; CollectorPressure = \u0026quot;pressure\u0026quot; CollectorProcesses = \u0026quot;processes\u0026quot; CollectorQDisc = \u0026quot;qdisc\u0026quot; CollectorRAPL = \u0026quot;rapl\u0026quot; CollectorRunit = \u0026quot;runit\u0026quot; CollectorSchedstat = \u0026quot;schedstat\u0026quot; CollectorSockstat = \u0026quot;sockstat\u0026quot; CollectorSoftnet = \u0026quot;softnet\u0026quot; CollectorStat = \u0026quot;stat\u0026quot; CollectorSupervisord = \u0026quot;supervisord\u0026quot; CollectorSystemd = \u0026quot;systemd\u0026quot; CollectorTCPStat = \u0026quot;tcpstat\u0026quot; CollectorTapestats = \u0026quot;tapestats\u0026quot; CollectorTextfile = \u0026quot;textfile\u0026quot; CollectorThermal = \u0026quot;thermal\u0026quot; CollectorThermalzone = \u0026quot;thermal_zone\u0026quot; CollectorTime = \u0026quot;time\u0026quot; CollectorTimex = \u0026quot;timex\u0026quot; CollectorUDPQueues = \u0026quot;udp_queues\u0026quot; CollectorUname = \u0026quot;uname\u0026quot; CollectorVMStat = \u0026quot;vmstat\u0026quot; CollectorWiFi = \u0026quot;wifi\u0026quot; CollectorXFS = \u0026quot;xfs\u0026quot; CollectorZFS = \u0026quot;zfs\u0026quot; CollectorZoneinfo = \u0026quot;zoneinfo\u0026quot; )  "}),e.add({id:38,href:"/docs/appendix/grafana-agent/integrations/mysqld-exporter-config/",title:"MySQLd Exporter",description:"grafana-agent 内置集成了 mysqld_exporter， 来收集MySQL Server的metrics指标。\n目前一个grafana-agent实例，只能配置和采集一个MySQL server的metrics，因此如果您想要配置采集多个MySQL server的指标，那么需要启动多个grafana-agent实例，并使用 relabel_configs 机制来给不同的MySQL server的metrics数据做区分。\n配置并启用mysqld_exporter # 下面是开启了mysqld_exporter的配置文件示例:\nmysqld_exporter: enabled: true data_source_name: root@(server-a:3306)/ relabel_configs: - source_labels: [__address__] target_label: instance replacement: server-a  为了安全起见，推荐您为grafana-agent mysqld_exporter 配置一个单独的数据库账号，并授予合适的权限，需要的权限配置详情可以参考 MySQL Expoter 官方文档.\n采集的关键指标列表 # mysql_global_status_uptime: The number of seconds that the server has been up.(Gauge) mysql_global_status_uptime_since_flush_status: The number of seconds since the most recent FLUSH STATUS statement.(Gauge) mysql_global_status_queries: The number of statements executed by the server. This variable includes statements executed within stored programs, unlike the Questions variable.",content:"grafana-agent 内置集成了 mysqld_exporter， 来收集MySQL Server的metrics指标。\n目前一个grafana-agent实例，只能配置和采集一个MySQL server的metrics，因此如果您想要配置采集多个MySQL server的指标，那么需要启动多个grafana-agent实例，并使用 relabel_configs 机制来给不同的MySQL server的metrics数据做区分。\n配置并启用mysqld_exporter # 下面是开启了mysqld_exporter的配置文件示例:\nmysqld_exporter: enabled: true data_source_name: root@(server-a:3306)/ relabel_configs: - source_labels: [__address__] target_label: instance replacement: server-a  为了安全起见，推荐您为grafana-agent mysqld_exporter 配置一个单独的数据库账号，并授予合适的权限，需要的权限配置详情可以参考 MySQL Expoter 官方文档.\n采集的关键指标列表 # mysql_global_status_uptime: The number of seconds that the server has been up.(Gauge) mysql_global_status_uptime_since_flush_status: The number of seconds since the most recent FLUSH STATUS statement.(Gauge) mysql_global_status_queries: The number of statements executed by the server. This variable includes statements executed within stored programs, unlike the Questions variable. It does not count COM_PING or COM_STATISTICS commands.(Counter) mysql_global_status_threads_connected: The number of currently open connections.(Counter) mysql_global_status_connections: The number of connection attempts (successful or not) to the MySQL server.(Gauge) mysql_global_status_max_used_connections: The maximum number of connections that have been in use simultaneously since the server started.(Gauge) mysql_global_status_threads_running: The number of threads that are not sleeping.(Gauge) mysql_global_status_questions: The number of statements executed by the server. This includes only statements sent to the server by clients and not statements executed within stored programs, unlike the Queries variable. This variable does not count COM_PING, COM_STATISTICS, COM_STMT_PREPARE, COM_STMT_CLOSE, or COM_STMT_RESET commands.(Counter) mysql_global_status_threads_cached: The number of threads in the thread cache.(Counter) mysql_global_status_threads_created: The number of threads created to handle connections. If Threads_created is big, you may want to increase the thread_cache_size value. The cache miss rate can be calculated as Threads_created/Connections.(Counter) mysql_global_status_created_tmp_tables: The number of internal temporary tables created by the server while executing statements.(Counter) mysql_global_status_created_tmp_disk_tables: The number of internal on-disk temporary tables created by the server while executing statements. You can compare the number of internal on-disk temporary tables created to the total number of internal temporary tables created by comparing Created_tmp_disk_tables and Created_tmp_tables values.(Counter) mysql_global_status_created_tmp_files: How many temporary files mysqld has created.(Counter) mysql_global_status_select_full_join: The number of joins that perform table scans because they do not use indexes. If this value is not 0, you should carefully check the indexes of your tables.(Counter) mysql_global_status_select_full_range_join: The number of joins that used a range search on a reference table.(Counter) mysql_global_status_select_range: The number of joins that used ranges on the first table. This is normally not a critical issue even if the value is quite large.(Counter) mysql_global_status_select_range_check: The number of joins without keys that check for key usage after each row. If this is not 0, you should carefully check the indexes of your tables.(Counter) mysql_global_status_select_scan: The number of joins that did a full scan of the first table.(Counter) mysql_global_status_sort_rows: The number of sorted rows.(Counter) mysql_global_status_sort_range: The number of sorts that were done using ranges.(Counter) mysql_global_status_sort_merge_passes: The number of merge passes that the sort algorithm has had to do. If this value is large, you should consider increasing the value of the sort_buffer_size system variable.(Counter) mysql_global_status_sort_scan: The number of sorts that were done by scanning the table.(Counter) mysql_global_status_slow_queries: The number of queries that have taken more than long_query_time seconds. This counter increments regardless of whether the slow query log is enabled.(Counter) mysql_global_status_aborted_connects: The number of failed attempts to connect to the MySQL server.(Counter) mysql_global_status_aborted_clients: The number of connections that were aborted because the client died without closing the connection properly.(Counter) mysql_global_status_table_locks_immediate: The number of times that a request for a table lock could be granted immediately. Locks Immediate rising and falling is normal activity.(Counter) mysql_global_status_table_locks_waited: The number of times that a request for a table lock could not be granted immediately and a wait was needed. If this is high and you have performance problems, you should first optimize your queries, and then either split your table or tables or use replication.(Counter) mysql_global_status_bytes_received: The number of bytes received from all clients.(Counter) mysql_global_status_bytes_sent: The number of bytes sent to all clients.(Counter) mysql_global_status_innodb_page_size: InnoDB page size (default 16KB). Many values are counted in pages; the page size enables them to be easily converted to bytes.(Gauge) mysql_global_status_buffer_pool_pages: The number of pages in the InnoDB buffer pool.(Gauge) mysql_global_status_commands_total: The number of times each xxx statement has been executed.(Counter) mysql_global_status_handlers_total: Handler statistics are internal statistics on how MySQL is selecting, updating, inserting, and modifying rows, tables, and indexes. This is in fact the layer between the Storage Engine and MySQL.(Counter) mysql_global_status_opened_files: The number of files that have been opened with my_open() (a mysys library function). Parts of the server that open files without using this function do not increment the count.(Counter) mysql_global_status_open_tables: The number of tables that are open.(Gauge) mysql_global_status_opened_tables: The number of tables that have been opened. If Opened_tables is big, your table_open_cache value is probably too small.(Counter) mysql_global_status_table_open_cache_hits: The number of hits for open tables cache lookups.(Counter) mysql_global_status_table_open_cache_misses: The number of misses for open tables cache lookups.(Counter) mysql_global_status_table_open_cache_overflows: The number of overflows for the open tables cache.(Counter) mysql_global_status_innodb_num_open_files: The number of files InnoDB currently holds open.(Gauge) mysql_global_variables_thread_cache_size: How many threads the server should cache for reuse.(Gauge) mysql_global_variables_max_connections: The maximum permitted number of simultaneous client connections.(Gauge) mysql_global_variables_innodb_buffer_pool_size: The size in bytes of the buffer pool, the memory area where InnoDB caches table and index data. The default value is 134217728 bytes (128MB).(Gauge) mysql_global_variables_innodb_log_buffer_size: The size in bytes of the buffer that InnoDB uses to write to the log files on disk.(Gauge) mysql_global_variables_key_buffer_size: Index blocks for MyISAM tables are buffered and are shared by all threads.(Gauge) mysql_global_variables_query_cache_size: The amount of memory allocated for caching query results.(Gauge) mysql_global_variables_table_open_cache: The number of open tables for all threads.(Gauge) mysql_global_variables_open_files_limit: The number of file descriptors available to mysqld from the operating system.(Gauge)  mysqld-exporter-config详细配置项说明 # # Enables the mysqld_exporter integration, allowing the Agent to collect # metrics from a MySQL server. [enabled: \u0026lt;boolean\u0026gt; | default = false] # Sets an explicit value for the instance label when the integration is # self-scraped. Overrides inferred values. # # The default value for this integration is a truncated version of the # connection DSN, containing only the server and db name. (Credentials # are not included.) [instance: \u0026lt;string\u0026gt;] # Automatically collect metrics from this integration. If disabled, # the mysqld_exporter integration will be run but not scraped and thus not # remote-written. Metrics for the integration will be exposed at # /integrations/mysqld_exporter/metrics and can be scraped by an external # process. [scrape_integration: \u0026lt;boolean\u0026gt; | default = \u0026lt;integrations_config.scrape_integrations\u0026gt;] # How often should the metrics be collected? Defaults to # prometheus.global.scrape_interval. [scrape_interval: \u0026lt;duration\u0026gt; | default = \u0026lt;global_config.scrape_interval\u0026gt;] # The timeout before considering the scrape a failure. Defaults to # prometheus.global.scrape_timeout. [scrape_timeout: \u0026lt;duration\u0026gt; | default = \u0026lt;global_config.scrape_timeout\u0026gt;] # Allows for relabeling labels on the target. relabel_configs: [- \u0026lt;relabel_config\u0026gt; ... ] # Relabel metrics coming from the integration, allowing to drop series # from the integration that you don't care about. metric_relabel_configs: [ - \u0026lt;relabel_config\u0026gt; ... ] # How frequent to truncate the WAL for this integration. [wal_truncate_frequency: \u0026lt;duration\u0026gt; | default = \u0026quot;60m\u0026quot;] # Data Source Name specifies the MySQL server to connect to. This is REQUIRED # but may also be specified by the MYSQLD_EXPORTER_DATA_SOURCE_NAME # environment variable. If neither are set, the integration will fail to # start. # # The format of this is specified here: https://github.com/go-sql-driver/mysql#dsn-data-source-name # # A working example value for a server with no required password # authentication is: \u0026quot;root@(localhost:3306)/\u0026quot; data_source_name: \u0026lt;string\u0026gt; # A list of collector names to enable on top of the default set. enable_collectors: [ - \u0026lt;string\u0026gt; ] # A list of collector names to disable from the default set. disable_collectors: [ - \u0026lt;string\u0026gt; ] # A list of collectors to run. Fully overrides the default set. set_collectors: [ - \u0026lt;string\u0026gt; ] # Set a lock_wait_timeout on the connection to avoid long metadata locking. [lock_wait_timeout: \u0026lt;int\u0026gt; | default = 2] # Add a low_slow_filter to avoid slow query logging of scrapes. NOT supported # by Oracle MySQL. [log_slow_filter: \u0026lt;bool\u0026gt; | default = false] ## Collector-specific options # Minimum time a thread must be in each state to be counted. [info_schema_processlist_min_time: \u0026lt;int\u0026gt; | default = 0] # Enable collecting the number of processes by user. [info_schema_processlist_processes_by_user: \u0026lt;bool\u0026gt; | default = true] # Enable collecting the number of processes by host. [info_schema_processlist_processes_by_host: \u0026lt;bool\u0026gt; | default = true] # The list of databases to collect table stats for. * for all [info_schema_tables_databases: \u0026lt;string\u0026gt; | default = \u0026quot;*\u0026quot;] # Limit the number of events statements digests by response time. [perf_schema_eventsstatements_limit: \u0026lt;int\u0026gt; | default = 250] # Limit how old the 'last_seen' events statements can be, in seconds. [perf_schema_eventsstatements_time_limit: \u0026lt;int\u0026gt; | default = 86400] # Maximum length of the normalized statement text. [perf_schema_eventsstatements_digtext_text_limit: \u0026lt;int\u0026gt; | default = 120] # Regex file_name filter for performance_schema.file_summary_by_instance [perf_schema_file_instances_filter: \u0026lt;string\u0026gt; | default = \u0026quot;.*\u0026quot;] # Remove path prefix in performance_schema.file_summary_by_instance [perf_schema_file_instances_remove_prefix: \u0026lt;string\u0026gt; | default = \u0026quot;/var/lib/mysql\u0026quot;] # Database from where to collect heartbeat data. [heartbeat_database: \u0026lt;string\u0026gt; | default = \u0026quot;heartbeat\u0026quot;] # Table from where to collect heartbeat data. [heartbeat_table: \u0026lt;string\u0026gt; | default = \u0026quot;heartbeat\u0026quot;] # Use UTC for timestamps of the current server (`pt-heartbeat` is called with `--utc`) [heartbeat_utc: \u0026lt;bool\u0026gt; | default = false] # Enable collecting user privileges from mysql.user [mysql_user_privileges: \u0026lt;bool\u0026gt; | default = false]  "}),e.add({id:39,href:"/docs/appendix/grafana-agent/integrations/process-exporter-config/",title:"Process Exporter",description:"grafana-agent内置集成了process-exporter，基于/proc的文件分析结果，来收集Linux系统进程相关的指标（注意，非Linux系统开启该exporter不起作用）。\n如果grafana-agent运行在container中，那么在容器的启动命令中，要做以下调整，即将宿主机的/proc目录映射到容器中相应的位置。\ndocker run \\ -v \u0026quot;/proc:/proc:ro\u0026quot; \\ -v /tmp/agent:/etc/agent \\ -v /path/to/config.yaml:/etc/agent-config/agent.yaml \\ grafana/agent:v0.23.0 \\ --config.file=/etc/agent-config/agent.yaml  注意，将/path/to/config.yaml替换成您自己相应的配置文件。\n如果grafana-agent运行在Kubernetes中，那么同样的需要在manifest文件中，做如下调整，即将宿主机的/proc目录映射到容器中相应的位置。\napiVersion: v1 kind: Pod metadata: name: grafana-agent spec: containers: - image: grafana/agent:v0.23.0 name: agent args: - --config.file=/etc/agent-config/agent.yaml volumeMounts: - name: procfs mountPath: /proc readOnly: true volumes: - name: procfs hostPath: path: /proc  配置并启用process_exporter # 如下的配置，将会开启process_exporter，并追踪系统中的所有进程。\nprocess_exporter: enabled: true process_names: - name: \u0026quot;{{.Comm}}\u0026quot; cmdline: - '.+'  采集的指标列表 # # Context switches # 上下文切换数量 # Counter namedprocess_namegroup_context_switches_total # Cpu user/system usage in seconds # CPU 时间（秒） # Counter namedprocess_namegroup_cpu_seconds_total # Major page faults # 主要页缺失次数 # Counter namedprocess_namegroup_major_page_faults_total # Minor page faults # 次要页缺失次数 # Counter namedprocess_namegroup_minor_page_faults_total # number of bytes of memory in use # 内存占用（byte） # Gauge namedprocess_namegroup_memory_bytes # number of processes in this group # 同名进程数量 # Gauge namedprocess_namegroup_num_procs # Number of processes in states Running, Sleeping, Waiting, Zombie, or Other # 同名进程状态分布 # Gauge namedprocess_namegroup_states # Number of threads # 线程数量 # Gauge namedprocess_namegroup_num_threads # start time in seconds since 1970/01/01 of oldest process in group # 启动时间戳 # Gauge namedprocess_namegroup_oldest_start_time_seconds # number of open file descriptors for this group # 打开文件描述符数量 # Gauge namedprocess_namegroup_open_filedesc # the worst (closest to 1) ratio between open fds and max fds among all procs in this group # 打开文件数 / 允许打开文件数 # Gauge namedprocess_namegroup_worst_fd_ratio # number of bytes read by this group # 读数据量（byte） # Counter namedprocess_namegroup_read_bytes_total # number of bytes written by this group # 写数据量（byte） # Counter namedprocess_namegroup_write_bytes_total # Number of threads in this group waiting on each wchan # 内核wchan等待线程数量 # Gauge namedprocess_namegroup_threads_wchan  process_exporter的详细配置项说明 # # Enables the process_exporter integration, allowing the Agent to automatically # collect system metrics from the host UNIX system.",content:"grafana-agent内置集成了process-exporter，基于/proc的文件分析结果，来收集Linux系统进程相关的指标（注意，非Linux系统开启该exporter不起作用）。\n如果grafana-agent运行在container中，那么在容器的启动命令中，要做以下调整，即将宿主机的/proc目录映射到容器中相应的位置。\ndocker run \\ -v \u0026quot;/proc:/proc:ro\u0026quot; \\ -v /tmp/agent:/etc/agent \\ -v /path/to/config.yaml:/etc/agent-config/agent.yaml \\ grafana/agent:v0.23.0 \\ --config.file=/etc/agent-config/agent.yaml  注意，将/path/to/config.yaml替换成您自己相应的配置文件。\n如果grafana-agent运行在Kubernetes中，那么同样的需要在manifest文件中，做如下调整，即将宿主机的/proc目录映射到容器中相应的位置。\napiVersion: v1 kind: Pod metadata: name: grafana-agent spec: containers: - image: grafana/agent:v0.23.0 name: agent args: - --config.file=/etc/agent-config/agent.yaml volumeMounts: - name: procfs mountPath: /proc readOnly: true volumes: - name: procfs hostPath: path: /proc  配置并启用process_exporter # 如下的配置，将会开启process_exporter，并追踪系统中的所有进程。\nprocess_exporter: enabled: true process_names: - name: \u0026quot;{{.Comm}}\u0026quot; cmdline: - '.+'  采集的指标列表 # # Context switches # 上下文切换数量 # Counter namedprocess_namegroup_context_switches_total # Cpu user/system usage in seconds # CPU 时间（秒） # Counter namedprocess_namegroup_cpu_seconds_total # Major page faults # 主要页缺失次数 # Counter namedprocess_namegroup_major_page_faults_total # Minor page faults # 次要页缺失次数 # Counter namedprocess_namegroup_minor_page_faults_total # number of bytes of memory in use # 内存占用（byte） # Gauge namedprocess_namegroup_memory_bytes # number of processes in this group # 同名进程数量 # Gauge namedprocess_namegroup_num_procs # Number of processes in states Running, Sleeping, Waiting, Zombie, or Other # 同名进程状态分布 # Gauge namedprocess_namegroup_states # Number of threads # 线程数量 # Gauge namedprocess_namegroup_num_threads # start time in seconds since 1970/01/01 of oldest process in group # 启动时间戳 # Gauge namedprocess_namegroup_oldest_start_time_seconds # number of open file descriptors for this group # 打开文件描述符数量 # Gauge namedprocess_namegroup_open_filedesc # the worst (closest to 1) ratio between open fds and max fds among all procs in this group # 打开文件数 / 允许打开文件数 # Gauge namedprocess_namegroup_worst_fd_ratio # number of bytes read by this group # 读数据量（byte） # Counter namedprocess_namegroup_read_bytes_total # number of bytes written by this group # 写数据量（byte） # Counter namedprocess_namegroup_write_bytes_total # Number of threads in this group waiting on each wchan # 内核wchan等待线程数量 # Gauge namedprocess_namegroup_threads_wchan  process_exporter的详细配置项说明 # # Enables the process_exporter integration, allowing the Agent to automatically # collect system metrics from the host UNIX system. [enabled: \u0026lt;boolean\u0026gt; | default = false] # Sets an explicit value for the instance label when the integration is # self-scraped. Overrides inferred values. # # The default value for this integration is inferred from the agent hostname # and HTTP listen port, delimited by a colon. [instance: \u0026lt;string\u0026gt;] # Automatically collect metrics from this integration. If disabled, # the process_exporter integration will be run but not scraped and thus not # remote-written. Metrics for the integration will be exposed at # /integrations/process_exporter/metrics and can be scraped by an external # process. [scrape_integration: \u0026lt;boolean\u0026gt; | default = \u0026lt;integrations_config.scrape_integrations\u0026gt;] # How often should the metrics be collected? Defaults to # prometheus.global.scrape_interval. [scrape_interval: \u0026lt;duration\u0026gt; | default = \u0026lt;global_config.scrape_interval\u0026gt;] # The timeout before considering the scrape a failure. Defaults to # prometheus.global.scrape_timeout. [scrape_timeout: \u0026lt;duration\u0026gt; | default = \u0026lt;global_config.scrape_timeout\u0026gt;] # Allows for relabeling labels on the target. relabel_configs: [- \u0026lt;relabel_config\u0026gt; ... ] # Relabel metrics coming from the integration, allowing to drop series # from the integration that you don't care about. metric_relabel_configs: [ - \u0026lt;relabel_config\u0026gt; ... ] # How frequent to truncate the WAL for this integration. [wal_truncate_frequency: \u0026lt;duration\u0026gt; | default = \u0026quot;60m\u0026quot;] # procfs mountpoint. [procfs_path: \u0026lt;string\u0026gt; | default = \u0026quot;/proc\u0026quot;] # If a proc is tracked, track with it any children that aren't a part of their # own group. [track_children: \u0026lt;boolean\u0026gt; | default = true] # Report on per-threadname metrics as well. [track_threads: \u0026lt;boolean\u0026gt; | default = true] # Gather metrics from smaps file, which contains proportional resident memory # size. [gather_smaps: \u0026lt;boolean\u0026gt; | default = true] # Recheck process names on each scrape. [recheck_on_scrape: \u0026lt;boolean\u0026gt; | default = false] # A collection of matching rules to use for deciding which processes to # monitor. Each config can match multiple processes to be tracked as a single # process \u0026quot;group.\u0026quot; process_names: [- \u0026lt;process_matcher_config\u0026gt;]   process_matcher_config\n # The name to use for identifying the process group name in the metric. By # default, it uses the base path of the executable. # # The following template variables are available: # # - {{.Comm}}: Basename of the original executable from /proc/\u0026lt;pid\u0026gt;/stat # - {{.ExeBase}}: Basename of the executable from argv[0] # - {{.ExeFull}}: Fully qualified path of the executable # - {{.Username}}: Username of the effective user # - {{.Matches}}: Map containing all regex capture groups resulting from # matching a process with the cmdline rule group. # - {{.PID}}: PID of the process. Note that the PID is copied from the # first executable found. # - {{.StartTime}}: The start time of the process. This is useful when combined # with PID as PIDS get reused over time. [name: \u0026lt;string\u0026gt; | default = \u0026quot;{{.ExeBase}}\u0026quot;] # A list of strings that match the base executable name for a process, truncated # at 15 characters. It is derived from reading the second field of # /proc/\u0026lt;pid\u0026gt;/stat minus the parens. # # If any of the strings match, the process will be tracked. comm: [- \u0026lt;string\u0026gt;] # A list of strings that match argv[0] for a process. If there are no slashes, # only the basename of argv[0] needs to match. Otherwise the name must be an # exact match. For example, \u0026quot;postgres\u0026quot; may match any postgres binary but # \u0026quot;/usr/local/bin/postgres\u0026quot; can only match a postgres at that path exactly. # # If any of the strings match, the process will be tracked. exe: [- \u0026lt;string\u0026gt;] # A list of regular expressions applied to the argv of the process. Each # regex here must match the corresponding argv for the process to be tracked. # The first element that is matched is argv[1]. # # Regex Captures are added to the .Matches map for use in the name. cmdline: [- \u0026lt;string\u0026gt;]  "}),e.add({id:40,href:"/docs/appendix/grafana-agent/integrations/cadvisor-config/",title:"cAdvisor Exporter",description:"grafana-agent 内置了 cadvisor, 可以支持采集容器的各项指标。不过 cadvisor 针对宿主机需要设置相关的权限，具体可以参考 cAdvisor docs.\n配置并启用cadvisor_exporter # 生成grafana-agent-cfg.yaml 配置文件，其中开启cadvisor integration，配置文件具体举例如下：\ncat \u0026lt;\u0026lt;EOF \u0026gt; /tmp/grafana-agent-cfg.yaml server: log_level: info http_listen_port: 12345 metrics: global: scrape_interval: 15s remote_write: - url: 'https://n9e-server:19000/prometheus/v1/write' basic_auth: username: ${FC_USERNAME} password: ${FC_PASSWORD} integrations: cadvisor: enabled: true EOF  在docker中启动 grafana-agent，同时映射相关目录 # docker run \\ -v /tmp/agent:/etc/agent/data \\ -v /tmp/grafana-agent-cfg.yaml:/etc/agent/agent.yaml \\ -p 12345:12345 \\ -d \\ --privileged \\ grafana/agent:v0.23.0 \\ --config.file=/etc/agent/agent.yaml \\ --metrics.wal-directory=/etc/agent/data  执行 curl http://localhost:12345/agent/api/v1/targets |jq,输出结果中预期应该包含 integrations/cadvisor 字段，如下：",content:"grafana-agent 内置了 cadvisor, 可以支持采集容器的各项指标。不过 cadvisor 针对宿主机需要设置相关的权限，具体可以参考 cAdvisor docs.\n配置并启用cadvisor_exporter # 生成grafana-agent-cfg.yaml 配置文件，其中开启cadvisor integration，配置文件具体举例如下：\ncat \u0026lt;\u0026lt;EOF \u0026gt; /tmp/grafana-agent-cfg.yaml server: log_level: info http_listen_port: 12345 metrics: global: scrape_interval: 15s remote_write: - url: 'https://n9e-server:19000/prometheus/v1/write' basic_auth: username: ${FC_USERNAME} password: ${FC_PASSWORD} integrations: cadvisor: enabled: true EOF  在docker中启动 grafana-agent，同时映射相关目录 # docker run \\ -v /tmp/agent:/etc/agent/data \\ -v /tmp/grafana-agent-cfg.yaml:/etc/agent/agent.yaml \\ -p 12345:12345 \\ -d \\ --privileged \\ grafana/agent:v0.23.0 \\ --config.file=/etc/agent/agent.yaml \\ --metrics.wal-directory=/etc/agent/data  执行 curl http://localhost:12345/agent/api/v1/targets |jq,输出结果中预期应该包含 integrations/cadvisor 字段，如下：\n{ \u0026quot;status\u0026quot;: \u0026quot;success\u0026quot;, \u0026quot;data\u0026quot;: [ { \u0026quot;instance\u0026quot;: \u0026quot;7f383657f506f53a739e2df61be58891\u0026quot;, \u0026quot;target_group\u0026quot;: \u0026quot;integrations/cadvisor\u0026quot;, \u0026quot;endpoint\u0026quot;: \u0026quot;http://127.0.0.1:12345/integrations/cadvisor/metrics\u0026quot;, \u0026quot;state\u0026quot;: \u0026quot;up\u0026quot;, \u0026quot;labels\u0026quot;: { \u0026quot;agent_hostname\u0026quot;: \u0026quot;509c1284c59c\u0026quot;, \u0026quot;instance\u0026quot;: \u0026quot;509c1284c59c:12345\u0026quot;, \u0026quot;job\u0026quot;: \u0026quot;integrations/cadvisor\u0026quot; }, \u0026quot;discovered_labels\u0026quot;: { \u0026quot;__address__\u0026quot;: \u0026quot;127.0.0.1:12345\u0026quot;, \u0026quot;__metrics_path__\u0026quot;: \u0026quot;/integrations/cadvisor/metrics\u0026quot;, \u0026quot;__scheme__\u0026quot;: \u0026quot;http\u0026quot;, \u0026quot;__scrape_interval__\u0026quot;: \u0026quot;15s\u0026quot;, \u0026quot;__scrape_timeout__\u0026quot;: \u0026quot;10s\u0026quot;, \u0026quot;agent_hostname\u0026quot;: \u0026quot;509c1284c59c\u0026quot;, \u0026quot;job\u0026quot;: \u0026quot;integrations/cadvisor\u0026quot; }, \u0026quot;last_scrape\u0026quot;: \u0026quot;2022-02-17T14:54:50.652267586Z\u0026quot;, \u0026quot;scrape_duration_ms\u0026quot;: 30, \u0026quot;scrape_error\u0026quot;: \u0026quot;\u0026quot; } ] }  执行 curl http://localhost:12345/integrations/cadvisor/metrics,预期输出结果下：\ncadvisor_version_info{cadvisorRevision=\u0026quot;\u0026quot;,cadvisorVersion=\u0026quot;\u0026quot;,dockerVersion=\u0026quot;\u0026quot;,kernelVersion=\u0026quot;5.10.76-linuxkit\u0026quot;,osVersion=\u0026quot;Debian GNU/Linux 10 (buster)\u0026quot;} 1 container_blkio_device_usage_total{device=\u0026quot;/dev/vda\u0026quot;,id=\u0026quot;/\u0026quot;,major=\u0026quot;254\u0026quot;,minor=\u0026quot;0\u0026quot;,operation=\u0026quot;Read\u0026quot;} 4.6509056e+07 1645109878135 container_blkio_device_usage_total{device=\u0026quot;/dev/vda\u0026quot;,id=\u0026quot;/\u0026quot;,major=\u0026quot;254\u0026quot;,minor=\u0026quot;0\u0026quot;,operation=\u0026quot;Write\u0026quot;} 3.13243648e+09 1645109878135 container_cpu_load_average_10s{id=\u0026quot;/\u0026quot;} 0 1645109878135 container_cpu_system_seconds_total{id=\u0026quot;/\u0026quot;} 57.789 1645109878135 container_cpu_usage_seconds_total{cpu=\u0026quot;total\u0026quot;,id=\u0026quot;/\u0026quot;} 91.57 1645109878135 container_cpu_user_seconds_total{id=\u0026quot;/\u0026quot;} 33.781 1645109878135 container_fs_inodes_free{device=\u0026quot;/dev\u0026quot;,id=\u0026quot;/\u0026quot;} 254415 1645109878135 container_fs_inodes_free{device=\u0026quot;/dev/shm\u0026quot;,id=\u0026quot;/\u0026quot;} 254551 1645109878135 container_fs_inodes_free{device=\u0026quot;/dev/vda1\u0026quot;,id=\u0026quot;/\u0026quot;} 3.890602e+06 1645109878135 container_fs_inodes_free{device=\u0026quot;/rootfs/dev/shm\u0026quot;,id=\u0026quot;/\u0026quot;} 254551 1645109878135 ...  采集的指标列表 # # CPU # 容器运行经过的cfs周期总数 container_cpu_cfs_periods_total: Number of elapsed enforcement period intervals # 容器运行时发生节流的cfs周期总数 container_cpu_cfs_throttled_periods_total: Number of throttled period intervals # 容器发生cpu节流的总时间 container_cpu_cfs_throttled_seconds_total: Total time duration the container has been throttled container_cpu_load_average_10s: Value of container cpu load average over the last 10 seconds container_cpu_system_seconds_total: Cumulative system cpu time consumed container_cpu_usage_seconds_total: Cumulative cpu time consumed container_cpu_user_seconds_total: Cumulative user cpu time consumed # 容器描述中的CPU周期配置 container_spec_cpu_period: CPU period of the container # 容器描述中的CPU quota配置 container_spec_cpu_quota: CPU quota of the container # 容器描述中的CPU权重配置 container_spec_cpu_shares: CPU share of the container # MEM container_memory_cache: Total page cache memory container_memory_failcnt: Number of memory usage hits limits container_memory_failures_total: Cumulative count of memory allocation failures container_memory_mapped_file: Size of memory mapped files container_memory_max_usage_bytes: Maximum memory usage recorded container_memory_rss: Size of RSS container_memory_swap: Container swap usage container_memory_usage_bytes: Current memory usage, including all memory regardless of when it was accessed container_oom_events_total: Count of out of memory events observed for the container container_spec_memory_limit_bytes: Memory limit for the container container_spec_memory_reservation_limit_bytes: Memory reservation limit for the container container_spec_memory_swap_limit_bytes: Memory swap limit for the container # Disk # 设备IO使用总量 container_blkio_device_usage_total: Blkio device bytes usage container_fs_inodes_free: Number of available Inodes container_fs_inodes_total: Total number of Inodes container_fs_io_current: Number of I/Os currently in progress # 容器IO总耗时 container_fs_io_time_seconds_total: Cumulative count of seconds spent doing I/Os container_fs_io_time_weighted_seconds_total: Cumulative weighted I/O time container_fs_limit_bytes: Number of bytes that can be consumed by the container on this filesystem container_fs_reads_bytes_total: Cumulative count of bytes read container_fs_read_seconds_total: Cumulative count of seconds spent reading container_fs_reads_merged_total: Cumulative count of reads merged container_fs_reads_total: Cumulative count of reads completed container_fs_sector_reads_total: Cumulative count of sector reads completed container_fs_sector_writes_total: Cumulative count of sector writes completed container_fs_usage_bytes: Number of bytes that are consumed by the container on this filesystem container_fs_writes_bytes_total: Cumulative count of bytes written container_fs_write_seconds_total: Cumulative count of seconds spent writing container_fs_writes_merged_total: Cumulative count of writes merged container_fs_writes_total: Cumulative count of writes completed # Network container_network_receive_bytes_total: Cumulative count of bytes received container_network_receive_errors_total: Cumulative count of errors encountered while receiving container_network_receive_packets_dropped_total: Cumulative count of packets dropped while receiving container_network_receive_packets_total: Cumulative count of packets received container_network_transmit_bytes_total: Cumulative count of bytes transmitted container_network_transmit_errors_total: Cumulative count of errors encountered while transmitting container_network_transmit_packets_dropped_total: Cumulative count of packets dropped while transmitting container_network_transmit_packets_total: Cumulative count of packets transmitted # System container_tasks_state: Number of tasks in given state (sleeping, running, stopped, uninterruptible, or ioawaiting) # Others container_last_seen: Last time a container was seen by the exporter container_start_time_seconds: Start time of the container since unix epoch  完整地配置项说明 # # Enables the cadvisor integration, allowing the Agent to automatically # collect metrics for the specified github objects. [enabled: \u0026lt;boolean\u0026gt; | default = false] # Sets an explicit value for the instance label when the integration is # self-scraped. Overrides inferred values. [instance: \u0026lt;string\u0026gt; | default = \u0026lt;integrations_config.instance\u0026gt;] # Automatically collect metrics from this integration. If disabled, # the cadvisor integration will be run but not scraped and thus not # remote-written. Metrics for the integration will be exposed at # /integrations/cadvisor/metrics and can be scraped by an external # process. [scrape_integration: \u0026lt;boolean\u0026gt; | default = \u0026lt;integrations_config.scrape_integrations\u0026gt;] # How often should the metrics be collected? Defaults to # prometheus.global.scrape_interval. [scrape_interval: \u0026lt;duration\u0026gt; | default = \u0026lt;global_config.scrape_interval\u0026gt;] # The timeout before considering the scrape a failure. Defaults to # prometheus.global.scrape_timeout. [scrape_timeout: \u0026lt;duration\u0026gt; | default = \u0026lt;global_config.scrape_timeout\u0026gt;] # Allows for relabeling labels on the target. relabel_configs: [- \u0026lt;relabel_config\u0026gt; ... ] # Relabel metrics coming from the integration, allowing to drop series # from the integration that you don't care about. metric_relabel_configs: [ - \u0026lt;relabel_config\u0026gt; ... ] # How frequent to truncate the WAL for this integration. [wal_truncate_frequency: \u0026lt;duration\u0026gt; | default = \u0026quot;60m\u0026quot;] # # cAdvisor-specific configuration options # # Convert container labels and environment variables into labels on prometheus metrics for each container. If false, then only metrics exported are container name, first alias, and image name. [store_container_labels: \u0026lt;boolean\u0026gt; | default = true] # List of container labels to be converted to labels on prometheus metrics for each container. store_container_labels must be set to false for this to take effect. allowlisted_container_labels: [ - \u0026lt;string\u0026gt; ] # List of environment variable keys matched with specified prefix that needs to be collected for containers, only support containerd and docker runtime for now. env_metadata_allowlist: [ - \u0026lt;string\u0026gt; ] # List of cgroup path prefix that needs to be collected even when docker_only is specified. raw_cgroup_prefix_allowlist: [ - \u0026lt;string\u0026gt; ] # Path to a JSON file containing configuration of perf events to measure. Empty value disabled perf events measuring. [perf_events_config: \u0026lt;boolean\u0026gt;] # resctrl mon groups updating interval. Zero value disables updating mon groups. [resctrl_interval: \u0026lt;int\u0026gt; | default = 0] # List of `metrics` to be disabled. If set, overrides the default disabled metrics. disabled_metrics: [ - \u0026lt;string\u0026gt; ] # List of `metrics` to be enabled. If set, overrides disabled_metrics enabled_metrics: [ - \u0026lt;string\u0026gt; ] # Length of time to keep data stored in memory [storage_duration: \u0026lt;duration\u0026gt; | default = \u0026quot;2m\u0026quot;] # Containerd endpoint [containerd: \u0026lt;string\u0026gt; | default = \u0026quot;/run/containerd/containerd.sock\u0026quot;] # Containerd namespace [containerd_namespace: \u0026lt;string\u0026gt; | default = \u0026quot;k8s.io\u0026quot;] # Docker endpoint [docker: \u0026lt;string\u0026gt; | default = \u0026quot;unix:///var/run/docker.sock\u0026quot;] # Use TLS to connect to docker [docker_tls: \u0026lt;boolean\u0026gt; | default = false] # Path to client certificate for TLS connection to docker [docker_tls_cert: \u0026lt;string\u0026gt; | default = \u0026quot;cert.pem\u0026quot;] # Path to private key for TLS connection to docker [docker_tls_key: \u0026lt;string\u0026gt; | default = \u0026quot;key.pem\u0026quot;] # Path to a trusted CA for TLS connection to docker [docker_tls_ca: \u0026lt;string\u0026gt; | default = \u0026quot;ca.pem\u0026quot;] # Only report docker containers in addition to root stats [docker_only: \u0026lt;boolean\u0026gt; | default = false]  "}),e.add({id:41,href:"/docs/appendix/grafana-agent/integrations/windows-exporter-config/",title:"Windows Exporter",description:"grafana-agent内置了windows_exporter的实现，可以采集到windows平台的指标。\n配置并启用windows_exporter # # grafana-agent 本身的配置 server: log_level: info http_listen_port: 12345 # grafana-agent 抓取 metrics 的相关配置（类似于prometheus的scrape_configs） metrics: global: scrape_interval: 15s scrape_timeout: 10s remote_write: - url: https://n9e-server:19000/prometheus/v1/write basic_auth: username: \u0026lt;string\u0026gt; password: \u0026lt;string\u0026gt; integrations: windows_exporter: enabled: true  采集的关键指标列表 # windows_cpu_clock_interrupts_total: Total number of received and serviced clock tick interrupts(counter) windows_cpu_core_frequency_mhz: Core frequency in megahertz(gauge) windows_cpu_cstate_seconds_total: Time spent in low-power idle state(counter) windows_cpu_dpcs_total: Total number of received and serviced deferred procedure calls (DPCs)(counter) windows_cpu_idle_break_events_total: Total number of time processor was woken from idle(counter) windows_cpu_interrupts_total: Total number of received and serviced hardware interrupts(counter) windows_cpu_parking_status: Parking Status represents whether a processor is parked or not(gauge) windows_cpu_processor_performance: Processor Performance is the average performance of the processor while it is executing instructions, as a percentage of the nominal performance of the processor.",content:"grafana-agent内置了windows_exporter的实现，可以采集到windows平台的指标。\n配置并启用windows_exporter # # grafana-agent 本身的配置 server: log_level: info http_listen_port: 12345 # grafana-agent 抓取 metrics 的相关配置（类似于prometheus的scrape_configs） metrics: global: scrape_interval: 15s scrape_timeout: 10s remote_write: - url: https://n9e-server:19000/prometheus/v1/write basic_auth: username: \u0026lt;string\u0026gt; password: \u0026lt;string\u0026gt; integrations: windows_exporter: enabled: true  采集的关键指标列表 # windows_cpu_clock_interrupts_total: Total number of received and serviced clock tick interrupts(counter) windows_cpu_core_frequency_mhz: Core frequency in megahertz(gauge) windows_cpu_cstate_seconds_total: Time spent in low-power idle state(counter) windows_cpu_dpcs_total: Total number of received and serviced deferred procedure calls (DPCs)(counter) windows_cpu_idle_break_events_total: Total number of time processor was woken from idle(counter) windows_cpu_interrupts_total: Total number of received and serviced hardware interrupts(counter) windows_cpu_parking_status: Parking Status represents whether a processor is parked or not(gauge) windows_cpu_processor_performance: Processor Performance is the average performance of the processor while it is executing instructions, as a percentage of the nominal performance of the processor. On some processors, Processor Performance may exceed 100%(gauge) windows_cpu_time_total: Time that processor spent in different modes (idle, user, system, ...)(counter) windows_cs_hostname: Labeled system hostname information as provided by ComputerSystem.DNSHostName and ComputerSystem.Domain(gauge) windows_cs_logical_processors: ComputerSystem.NumberOfLogicalProcessors(gauge) windows_cs_physical_memory_bytes: ComputerSystem.TotalPhysicalMemory(gauge) windows_exporter_build_info: A metric with a constant '1' value labeled by version, revision, branch, and goversion from which windows_exporter was built.(gauge) windows_exporter_collector_duration_seconds: Duration of a collection.(gauge) windows_exporter_collector_success: Whether the collector was successful.(gauge) windows_exporter_collector_timeout: Whether the collector timed out.(gauge) windows_exporter_perflib_snapshot_duration_seconds: Duration of perflib snapshot capture(gauge) windows_logical_disk_free_bytes: Free space in bytes (LogicalDisk.PercentFreeSpace)(gauge) windows_logical_disk_idle_seconds_total: Seconds that the disk was idle (LogicalDisk.PercentIdleTime)(counter) windows_logical_disk_read_bytes_total: The number of bytes transferred from the disk during read operations (LogicalDisk.DiskReadBytesPerSec)(counter) windows_logical_disk_read_latency_seconds_total: Shows the average time, in seconds, of a read operation from the disk (LogicalDisk.AvgDiskSecPerRead)(counter) windows_logical_disk_read_seconds_total: Seconds that the disk was busy servicing read requests (LogicalDisk.PercentDiskReadTime)(counter) windows_logical_disk_read_write_latency_seconds_total: Shows the time, in seconds, of the average disk transfer (LogicalDisk.AvgDiskSecPerTransfer)(counter) windows_logical_disk_reads_total: The number of read operations on the disk (LogicalDisk.DiskReadsPerSec)(counter) windows_logical_disk_requests_queued: The number of requests queued to the disk (LogicalDisk.CurrentDiskQueueLength)(gauge) windows_logical_disk_size_bytes: Total space in bytes (LogicalDisk.PercentFreeSpace_Base)(gauge) windows_logical_disk_split_ios_total: The number of I/Os to the disk were split into multiple I/Os (LogicalDisk.SplitIOPerSec)(counter) windows_logical_disk_write_bytes_total: The number of bytes transferred to the disk during write operations (LogicalDisk.DiskWriteBytesPerSec)(counter) windows_logical_disk_write_latency_seconds_total: Shows the average time, in seconds, of a write operation to the disk (LogicalDisk.AvgDiskSecPerWrite)(counter) windows_logical_disk_write_seconds_total: Seconds that the disk was busy servicing write requests (LogicalDisk.PercentDiskWriteTime)(counter) windows_logical_disk_writes_total: The number of write operations on the disk (LogicalDisk.DiskWritesPerSec)(counter) windows_net_bytes_received_total: (Network.BytesReceivedPerSec)(counter) windows_net_bytes_sent_total: (Network.BytesSentPerSec)(counter) windows_net_bytes_total: (Network.BytesTotalPerSec)(counter) windows_net_current_bandwidth: (Network.CurrentBandwidth)(gauge) windows_net_packets_outbound_discarded_total: (Network.PacketsOutboundDiscarded)(counter) windows_net_packets_outbound_errors_total: (Network.PacketsOutboundErrors)(counter) windows_net_packets_received_discarded_total: (Network.PacketsReceivedDiscarded)(counter) windows_net_packets_received_errors_total: (Network.PacketsReceivedErrors)(counter) windows_net_packets_received_total: (Network.PacketsReceivedPerSec)(counter) windows_net_packets_received_unknown_total: (Network.PacketsReceivedUnknown)(counter) windows_net_packets_sent_total: (Network.PacketsSentPerSec)(counter) windows_net_packets_total: (Network.PacketsPerSec)(counter) windows_os_info: OperatingSystem.Caption, OperatingSystem.Version(gauge) windows_os_paging_free_bytes: OperatingSystem.FreeSpaceInPagingFiles(gauge) windows_os_paging_limit_bytes: OperatingSystem.SizeStoredInPagingFiles(gauge) windows_os_physical_memory_free_bytes: OperatingSystem.FreePhysicalMemory(gauge) windows_os_process_memory_limix_bytes: OperatingSystem.MaxProcessMemorySize(gauge) windows_os_processes: OperatingSystem.NumberOfProcesses(gauge) windows_os_processes_limit: OperatingSystem.MaxNumberOfProcesses(gauge) windows_os_time: OperatingSystem.LocalDateTime(gauge) windows_os_timezone: OperatingSystem.LocalDateTime(gauge) windows_os_users: OperatingSystem.NumberOfUsers(gauge) windows_os_virtual_memory_bytes: OperatingSystem.TotalVirtualMemorySize(gauge) windows_os_virtual_memory_free_bytes: OperatingSystem.FreeVirtualMemory(gauge) windows_os_visible_memory_bytes: OperatingSystem.TotalVisibleMemorySize(gauge) windows_service_info: A metric with a constant '1' value labeled with service information(gauge) windows_service_start_mode: The start mode of the service (StartMode)(gauge) windows_service_state: The state of the service (State)(gauge) windows_service_status: The status of the service (Status)(gauge) windows_system_context_switches_total: Total number of context switches (WMI source is PerfOS_System.ContextSwitchesPersec)(counter) windows_system_exception_dispatches_total: Total number of exceptions dispatched (WMI source is PerfOS_System.ExceptionDispatchesPersec)(counter) windows_system_processor_queue_length: Length of processor queue (WMI source is PerfOS_System.ProcessorQueueLength)(gauge) windows_system_system_calls_total: Total number of system calls (WMI source is PerfOS_System.SystemCallsPersec)(counter) windows_system_system_up_time: System boot time (WMI source is PerfOS_System.SystemUpTime)(gauge) windows_system_threads: Current number of threads (WMI source is PerfOS_System.Threads)(gauge)  完整地配置项说明 # # Enables the windows_exporter integration, allowing the Agent to automatically # collect system metrics from the local windows instance [enabled: \u0026lt;boolean\u0026gt; | default = false] # Sets an explicit value for the instance label when the integration is # self-scraped. Overrides inferred values. # # The default value for this integration is inferred from the agent hostname # and HTTP listen port, delimited by a colon. [instance: \u0026lt;string\u0026gt;] # Automatically collect metrics from this integration. If disabled, # the consul_exporter integration will be run but not scraped and thus not # remote-written. Metrics for the integration will be exposed at # /integrations/windows_exporter/metrics and can be scraped by an external # process. [scrape_integration: \u0026lt;boolean\u0026gt; | default = \u0026lt;integrations_config.scrape_integrations\u0026gt;] # How often should the metrics be collected? Defaults to # prometheus.global.scrape_interval. [scrape_interval: \u0026lt;duration\u0026gt; | default = \u0026lt;global_config.scrape_interval\u0026gt;] # The timeout before considering the scrape a failure. Defaults to # prometheus.global.scrape_timeout. [scrape_timeout: \u0026lt;duration\u0026gt; | default = \u0026lt;global_config.scrape_timeout\u0026gt;] # Allows for relabeling labels on the target. relabel_configs: [- \u0026lt;relabel_config\u0026gt; ... ] # Relabel metrics coming from the integration, allowing to drop series # from the integration that you don't care about. metric_relabel_configs: [ - \u0026lt;relabel_config\u0026gt; ... ] # How frequent to truncate the WAL for this integration. [wal_truncate_frequency: \u0026lt;duration\u0026gt; | default = \u0026quot;60m\u0026quot;] # Monitor the exporter itself and include those metrics in the results. [include_exporter_metrics: \u0026lt;bool\u0026gt; | default = false] # # Exporter-specific configuration options # # List of collectors to enable. Any non-experimental collector from the # embeded version of windows_exporter can be enabeld here. [enabled_collectors: \u0026lt;string\u0026gt; | default = \u0026quot;cpu,cs,logical_disk,net,os,service,system,textfile\u0026quot;] # Settings for collectors which accept configuration. Settings specified here # are only used if the corresponding collector is enabled in # enabled_collectors. # Configuration for Exchange Mail Server exchange: # Comma-separated List of collectors to use. Defaults to all, if not specified. # Maps to collectors.exchange.enabled in windows_exporter [enabled_list: \u0026lt;string\u0026gt;] # Configuration for the IIS web server iis: # Regexp of sites to whitelist. Site name must both match whitelist and not match blacklist to be included. # Maps to collector.iis.site-whitelist in windows_exporter [site_whitelist: \u0026lt;string\u0026gt; | default = \u0026quot;.+\u0026quot;] # Regexp of sites to blacklist. Site name must both match whitelist and not match blacklist to be included. # Maps to collector.iis.site-blacklist in windows_exporter [site_blacklist: \u0026lt;string\u0026gt; | default = \u0026quot;\u0026quot;] # Regexp of apps to whitelist. App name must both match whitelist and not match blacklist to be included. # Maps to collector.iis.app-whitelist in windows_exporter [app_whitelist: \u0026lt;string\u0026gt; | default=\u0026quot;.+\u0026quot;] # Regexp of apps to blacklist. App name must both match whitelist and not match blacklist to be included. # Maps to collector.iis.app-blacklist in windows_exporter [app_blacklist: \u0026lt;string\u0026gt; | default=\u0026quot;.+\u0026quot;] # Configuration for reading metrics from a text files in a directory text_file: # Directory to read text files with metrics from. # Maps to collector.textfile.directory in windows_exporter [text_file_directory: \u0026lt;string\u0026gt; | default=\u0026quot;C:\\Program Files\\windows_exporter\\textfile_inputs\u0026quot;] # Configuration for SMTP metrics smtp: # Regexp of virtual servers to whitelist. Server name must both match whitelist and not match blacklist to be included. # Maps to collector.smtp.server-whitelist in windows_exporter [whitelist: \u0026lt;string\u0026gt; | default=\u0026quot;.+\u0026quot;] # Regexp of virtual servers to blacklist. Server name must both match whitelist and not match blacklist to be included. # Maps to collector.smtp.server-blacklist in windows_exporter [blacklist: \u0026lt;string\u0026gt; | default=\u0026quot;\u0026quot;] # Configuration for Windows Services service: # \u0026quot;WQL 'where' clause to use in WMI metrics query. Limits the response to the services you specify and reduces the size of the response. # Maps to collector.service.services-where in windows_exporter [where_clause: \u0026lt;string\u0026gt; | default=\u0026quot;\u0026quot;] # Configuration for Windows Processes process: # Regexp of processes to include. Process name must both match whitelist and not match blacklist to be included. # Maps to collector.process.whitelist in windows_exporter [whitelist: \u0026lt;string\u0026gt; | default=\u0026quot;.+\u0026quot;] # Regexp of processes to exclude. Process name must both match whitelist and not match blacklist to be included. # Maps to collector.process.blacklist in windows_exporter [blacklist: \u0026lt;string\u0026gt; | default=\u0026quot;\u0026quot;] # Configuration for NICs network: # Regexp of NIC's to whitelist. NIC name must both match whitelist and not match blacklist to be included. # Maps to collector.net.nic-whitelist in windows_exporter [whitelist: \u0026lt;string\u0026gt; | default=\u0026quot;.+\u0026quot;] # Regexp of NIC's to blacklist. NIC name must both match whitelist and not match blacklist to be included. # Maps to collector.net.nic-blacklist in windows_exporter [blacklist: \u0026lt;string\u0026gt; | default=\u0026quot;\u0026quot;] # Configuration for Microsoft SQL Server mssql: # Comma-separated list of mssql WMI classes to use. # Maps to collectors.mssql.classes-enabled in windows_exporter [enabled_classes: \u0026lt;string\u0026gt; | default=\u0026quot;accessmethods,availreplica,bufman,databases,dbreplica,genstats,locks,memmgr,sqlstats,sqlerrors,transactions\u0026quot;] # Configuration for Microsoft Queue msqm: # WQL 'where' clause to use in WMI metrics query. Limits the response to the msmqs you specify and reduces the size of the response. # Maps to collector.msmq.msmq-where in windows_exporter [where_clause: \u0026lt;string\u0026gt; | default=\u0026quot;\u0026quot;] # Configuration for disk information logical_disk: # Regexp of volumes to whitelist. Volume name must both match whitelist and not match blacklist to be included. # Maps to collector.logical_disk.volume-whitelist in windows_exporter [whitelist: \u0026lt;string\u0026gt; | default=\u0026quot;.+\u0026quot;] # Regexp of volumes to blacklist. Volume name must both match whitelist and not match blacklist to be included. # Maps to collector.logical_disk.volume-blacklist in windows_exporter [blacklist: \u0026lt;string\u0026gt; | default=\u0026quot;.+\u0026quot;]  "}),e.add({id:42,href:"/docs/appendix/grafana-agent/integrations/postgres-exporter-config/",title:"Postgres Exporter",description:"grafana-agent内置了postgres_exporter，来采集Postgres Server的metrics采集。\n我们强烈推荐您分配独立的账号，供grafana-agent来连接到Postgres server，以避免过度授权带来的安全性问题，具体可以餐你考postgres exporter官方文档.\n配置并启用cadvisor_exporter # server: log_level: info http_listen_port: 12345 metrics: global: scrape_interval: 15s remote_write: - url: 'https://n9e-server:19000/prometheus/v1/write' basic_auth: username: ${FC_USERNAME} password: ${FC_PASSWORD} integrations: postgres_exporter: enabled: true EOF  采集的关键指标列表 # pg_locks_count : pg_locks_count{datname=~\u0026quot;$datname\u0026quot;, instance=~\u0026quot;$instance\u0026quot;, mode=~\u0026quot;$mode\u0026quot;} != 0 pg_postmaster_start_time_seconds : pg_postmaster_start_time_seconds{release=\u0026quot;$release\u0026quot;, instance=\u0026quot;$instance\u0026quot;} * 1000 pg_settings_effective_cache_size_bytes : pg_settings_effective_cache_size_bytes{instance=\u0026quot;$instance\u0026quot;} pg_settings_maintenance_work_mem_bytes : pg_settings_maintenance_work_mem_bytes{instance=\u0026quot;$instance\u0026quot;} pg_settings_max_connections : pg_settings_max_connections{release=\u0026quot;$release\u0026quot;, instance=\u0026quot;$instance\u0026quot;} pg_settings_max_parallel_workers : pg_settings_max_parallel_workers{instance=\u0026quot;$instance\u0026quot;} pg_settings_max_wal_size_bytes : pg_settings_max_wal_size_bytes{instance=\u0026quot;$instance\u0026quot;} pg_settings_max_worker_processes : pg_settings_max_worker_processes{instance=\u0026quot;$instance\u0026quot;} pg_settings_random_page_cost : pg_settings_random_page_cost{instance=\u0026quot;$instance\u0026quot;} pg_settings_seq_page_cost : pg_settings_seq_page_cost pg_settings_shared_buffers_bytes : pg_settings_shared_buffers_bytes{instance=\u0026quot;$instance\u0026quot;} pg_settings_work_mem_bytes : pg_settings_work_mem_bytes{instance=\u0026quot;$instance\u0026quot;} pg_stat_activity_count : pg_stat_activity_count{datname=~\u0026quot;$datname\u0026quot;, instance=~\u0026quot;$instance\u0026quot;, state=\u0026quot;active\u0026quot;} !",content:"grafana-agent内置了postgres_exporter，来采集Postgres Server的metrics采集。\n我们强烈推荐您分配独立的账号，供grafana-agent来连接到Postgres server，以避免过度授权带来的安全性问题，具体可以餐你考postgres exporter官方文档.\n配置并启用cadvisor_exporter # server: log_level: info http_listen_port: 12345 metrics: global: scrape_interval: 15s remote_write: - url: 'https://n9e-server:19000/prometheus/v1/write' basic_auth: username: ${FC_USERNAME} password: ${FC_PASSWORD} integrations: postgres_exporter: enabled: true EOF  采集的关键指标列表 # pg_locks_count : pg_locks_count{datname=~\u0026quot;$datname\u0026quot;, instance=~\u0026quot;$instance\u0026quot;, mode=~\u0026quot;$mode\u0026quot;} != 0 pg_postmaster_start_time_seconds : pg_postmaster_start_time_seconds{release=\u0026quot;$release\u0026quot;, instance=\u0026quot;$instance\u0026quot;} * 1000 pg_settings_effective_cache_size_bytes : pg_settings_effective_cache_size_bytes{instance=\u0026quot;$instance\u0026quot;} pg_settings_maintenance_work_mem_bytes : pg_settings_maintenance_work_mem_bytes{instance=\u0026quot;$instance\u0026quot;} pg_settings_max_connections : pg_settings_max_connections{release=\u0026quot;$release\u0026quot;, instance=\u0026quot;$instance\u0026quot;} pg_settings_max_parallel_workers : pg_settings_max_parallel_workers{instance=\u0026quot;$instance\u0026quot;} pg_settings_max_wal_size_bytes : pg_settings_max_wal_size_bytes{instance=\u0026quot;$instance\u0026quot;} pg_settings_max_worker_processes : pg_settings_max_worker_processes{instance=\u0026quot;$instance\u0026quot;} pg_settings_random_page_cost : pg_settings_random_page_cost{instance=\u0026quot;$instance\u0026quot;} pg_settings_seq_page_cost : pg_settings_seq_page_cost pg_settings_shared_buffers_bytes : pg_settings_shared_buffers_bytes{instance=\u0026quot;$instance\u0026quot;} pg_settings_work_mem_bytes : pg_settings_work_mem_bytes{instance=\u0026quot;$instance\u0026quot;} pg_stat_activity_count : pg_stat_activity_count{datname=~\u0026quot;$datname\u0026quot;, instance=~\u0026quot;$instance\u0026quot;, state=\u0026quot;active\u0026quot;} !=0 pg_stat_activity_count : pg_stat_activity_count{datname=~\u0026quot;$datname\u0026quot;, instance=~\u0026quot;$instance\u0026quot;, state=~\u0026quot;idle|idle in transaction|idle in transaction (aborted)\u0026quot;} pg_stat_bgwriter_buffers_alloc : irate(pg_stat_bgwriter_buffers_alloc{instance=\u0026quot;$instance\u0026quot;}[5m]) pg_stat_bgwriter_buffers_backend : irate(pg_stat_bgwriter_buffers_backend{instance=\u0026quot;$instance\u0026quot;}[5m]) pg_stat_bgwriter_buffers_backend_fsync : irate(pg_stat_bgwriter_buffers_backend_fsync{instance=\u0026quot;$instance\u0026quot;}[5m]) pg_stat_bgwriter_buffers_checkpoint : irate(pg_stat_bgwriter_buffers_checkpoint{instance=\u0026quot;$instance\u0026quot;}[5m]) pg_stat_bgwriter_buffers_clean : irate(pg_stat_bgwriter_buffers_clean{instance=\u0026quot;$instance\u0026quot;}[5m]) pg_stat_bgwriter_checkpoint_sync_time : irate(pg_stat_bgwriter_checkpoint_sync_time{instance=\u0026quot;$instance\u0026quot;}[5m]) pg_stat_bgwriter_checkpoint_write_time : irate(pg_stat_bgwriter_checkpoint_write_time{instance=\u0026quot;$instance\u0026quot;}[5m]) pg_stat_database_blks_hit : pg_stat_database_blks_hit{instance=\u0026quot;$instance\u0026quot;, datname=~\u0026quot;$datname\u0026quot;} / (pg_stat_database_blks_read{instance=\u0026quot;$instance\u0026quot;, datname=~\u0026quot;$datname\u0026quot;} + pg_stat_database_blks_hit{instance=\u0026quot;$instance\u0026quot;, datname=~\u0026quot;$datname\u0026quot;}) pg_stat_database_conflicts : irate(pg_stat_database_conflicts{instance=\u0026quot;$instance\u0026quot;, datname=~\u0026quot;$datname\u0026quot;}[5m]) pg_stat_database_deadlocks : irate(pg_stat_database_deadlocks{instance=\u0026quot;$instance\u0026quot;, datname=~\u0026quot;$datname\u0026quot;}[5m]) pg_stat_database_temp_bytes : irate(pg_stat_database_temp_bytes{instance=\u0026quot;$instance\u0026quot;, datname=~\u0026quot;$datname\u0026quot;}[5m]) pg_stat_database_tup_deleted : pg_stat_database_tup_deleted{datname=~\u0026quot;$datname\u0026quot;, instance=~\u0026quot;$instance\u0026quot;} != 0 pg_stat_database_tup_fetched : SUM(pg_stat_database_tup_fetched{datname=~\u0026quot;$datname\u0026quot;, instance=~\u0026quot;$instance\u0026quot;}) pg_stat_database_tup_fetched : pg_stat_database_tup_fetched{datname=~\u0026quot;$datname\u0026quot;, instance=~\u0026quot;$instance\u0026quot;} != 0 pg_stat_database_tup_inserted : SUM(pg_stat_database_tup_inserted{release=\u0026quot;$release\u0026quot;, datname=~\u0026quot;$datname\u0026quot;, instance=~\u0026quot;$instance\u0026quot;}) pg_stat_database_tup_inserted : pg_stat_database_tup_inserted{datname=~\u0026quot;$datname\u0026quot;, instance=~\u0026quot;$instance\u0026quot;} != 0 pg_stat_database_tup_returned : pg_stat_database_tup_returned{datname=~\u0026quot;$datname\u0026quot;, instance=~\u0026quot;$instance\u0026quot;} != 0 pg_stat_database_tup_updated : SUM(pg_stat_database_tup_updated{datname=~\u0026quot;$datname\u0026quot;, instance=~\u0026quot;$instance\u0026quot;}) pg_stat_database_tup_updated : pg_stat_database_tup_updated{datname=~\u0026quot;$datname\u0026quot;, instance=~\u0026quot;$instance\u0026quot;} != 0 pg_stat_database_xact_commit : irate(pg_stat_database_xact_commit{instance=\u0026quot;$instance\u0026quot;, datname=~\u0026quot;$datname\u0026quot;}[5m]) pg_stat_database_xact_rollback : irate(pg_stat_database_xact_rollback{instance=\u0026quot;$instance\u0026quot;, datname=~\u0026quot;$datname\u0026quot;}[5m]) pg_static : pg_static{release=\u0026quot;$release\u0026quot;, instance=\u0026quot;$instance\u0026quot;} process_cpu_seconds_total : avg(rate(process_cpu_seconds_total{release=\u0026quot;$release\u0026quot;, instance=\u0026quot;$instance\u0026quot;}[5m]) * 1000) process_open_fds : process_open_fds{release=\u0026quot;$release\u0026quot;, instance=\u0026quot;$instance\u0026quot;} process_resident_memory_bytes : avg(rate(process_resident_memory_bytes{release=\u0026quot;$release\u0026quot;, instance=\u0026quot;$instance\u0026quot;}[5m])) process_virtual_memory_bytes : avg(rate(process_virtual_memory_bytes{release=\u0026quot;$release\u0026quot;, instance=\u0026quot;$instance\u0026quot;}[5m]))  完整地配置项说明 # # Enables the postgres_exporter integration, allowing the Agent to automatically # collect system metrics from the configured postgres server address [enabled: \u0026lt;boolean\u0026gt; | default = false] # Sets an explicit value for the instance label when the integration is # self-scraped. Overrides inferred values. # # The default value for this integration is inferred from a truncated version of # the first DSN in data_source_names. The truncated DSN includes the hostname # and database name (if used) of the server, but does not include any user # information. # # If data_source_names contains more than one entry, the integration will fail to # load and a value for instance must be manually provided. [instance: \u0026lt;string\u0026gt;] # Automatically collect metrics from this integration. If disabled, # the postgres_exporter integration will be run but not scraped and thus not # remote-written. Metrics for the integration will be exposed at # /integrations/postgres_exporter/metrics and can be scraped by an external # process. [scrape_integration: \u0026lt;boolean\u0026gt; | default = \u0026lt;integrations_config.scrape_integrations\u0026gt;] # How often should the metrics be collected? Defaults to # prometheus.global.scrape_interval. [scrape_interval: \u0026lt;duration\u0026gt; | default = \u0026lt;global_config.scrape_interval\u0026gt;] # The timeout before considering the scrape a failure. Defaults to # prometheus.global.scrape_timeout. [scrape_timeout: \u0026lt;duration\u0026gt; | default = \u0026lt;global_config.scrape_timeout\u0026gt;] # Allows for relabeling labels on the target. relabel_configs: [- \u0026lt;relabel_config\u0026gt; ... ] # Relabel metrics coming from the integration, allowing to drop series # from the integration that you don't care about. metric_relabel_configs: [ - \u0026lt;relabel_config\u0026gt; ... ] # How frequent to truncate the WAL for this integration. [wal_truncate_frequency: \u0026lt;duration\u0026gt; | default = \u0026quot;60m\u0026quot;] # Monitor the exporter itself and include those metrics in the results. [include_exporter_metrics: \u0026lt;bool\u0026gt; | default = false] # # Exporter-specific configuration options # # Data Source Names specifies the Postgres server(s) to connect to. This is # REQUIRED but may also be specified by the POSTGRES_EXPORTER_DATA_SOURCE_NAME # environment variable, where DSNs the environment variable are separated by # commas. If neither are set, the integration will fail to start. # # The format of this is specified here: https://pkg.go.dev/github.com/lib/pq#ParseURL # # A working example value for a server with a password is: # \u0026quot;postgresql://username:passwword@localhost:5432/database?sslmode=disable\u0026quot; # # Multiple DSNs may be provided here, allowing for scraping from multiple # servers. data_source_names: - \u0026lt;string\u0026gt; # Disables collection of metrics from pg_settings. [disable_settings_metrics: \u0026lt;boolean\u0026gt; | default = false] # Autodiscover databases to collect metrics from. If false, only collects # metrics from databases collected from data_source_names. [autodiscover_databases: \u0026lt;boolean\u0026gt; | default = false] # Excludes specific databases from being collected when autodiscover_databases # is true. exclude_databases: [ - \u0026lt;string\u0026gt; ] # Includes only specific databases (excluding all others) when autodiscover_databases # is true. include_databases: [ - \u0026lt;string\u0026gt; ] # Path to a YAML file containing custom queries to run. Check out # postgres_exporter's queries.yaml for examples of the format: # https://github.com/prometheus-community/postgres_exporter/blob/master/queries.yaml [query_path: \u0026lt;string\u0026gt; | default = \u0026quot;\u0026quot;] # When true, only exposes metrics supplied from query_path. [disable_default_metrics: \u0026lt;boolean\u0026gt; | default = false]  "}),e.add({id:43,href:"/docs/appendix/grafana-agent/integrations/mongodb-exporter-config/",title:"Mongodb Exporter",description:"grafana-agent内置了mongodb_exporter，可以采集mongodb的metrics。\n该mongodb_exporter，不支持同时配置多个mongodb node，目前只支持配置一个mongodb node，对其进行数据采集。此外您需要通过relabel_configs对label做自定义处理，一个是service_name，用来标识mongodb node（例如ReplicaSet1-Node1）；另一个是mongodb_cluster，标识该mongodb cluster（比如prod-cluster）\n一个relabel_configs的例子：\nrelabel_configs: - source_labels: [__address__] target_label: service_name replacement: 'replicaset1-node1' - source_labels: [__address__] target_label: mongodb_cluster replacement: 'prod-cluster'  强烈推荐您为grafana-agent设置一个单独的账号来访问您的mongodb，以避免过度授权带来的安全隐患，具体可以参考official documentation。\n配置并启用mongodb_exporter # # grafana-agent 本身的配置 server: log_level: info http_listen_port: 12345 # grafana-agent 抓取 metrics 的相关配置（类似于prometheus的scrape_configs） metrics: global: scrape_interval: 15s scrape_timeout: 10s remote_write: - url: https://n9e-server:19000/prometheus/v1/write basic_auth: username: \u0026lt;string\u0026gt; password: \u0026lt;string\u0026gt; integrations: mongodb_exporter: enabled: true  采集的关键指标列表 # # Whether MongoDB is up. # 实例是否存活 # Gauge mongodb_up # The number of seconds that the current MongoDB process has been active # 实例启动累计时间（秒） # Counter mongodb_instance_uptime_seconds # The amount of memory, in mebibyte (MiB), currently used by the database process # 内存占用（MiB） # Gauge # mongodb_memory # The total combined latency in microseconds # 累计操作耗时（毫秒） mongodb_mongod_op_latencies_latency_total # The total number of operations performed since startup # 累计操作次数 # Counter mongodb_mongod_op_latencies_ops_total # The total number of operations received since the mongod instance last started # 累计接收的操作请求次数（即使操作不成功也会增加） # Counter mongodb_op_counters_total # The number of incoming connections from clients to the database server.",content:"grafana-agent内置了mongodb_exporter，可以采集mongodb的metrics。\n该mongodb_exporter，不支持同时配置多个mongodb node，目前只支持配置一个mongodb node，对其进行数据采集。此外您需要通过relabel_configs对label做自定义处理，一个是service_name，用来标识mongodb node（例如ReplicaSet1-Node1）；另一个是mongodb_cluster，标识该mongodb cluster（比如prod-cluster）\n一个relabel_configs的例子：\nrelabel_configs: - source_labels: [__address__] target_label: service_name replacement: 'replicaset1-node1' - source_labels: [__address__] target_label: mongodb_cluster replacement: 'prod-cluster'  强烈推荐您为grafana-agent设置一个单独的账号来访问您的mongodb，以避免过度授权带来的安全隐患，具体可以参考official documentation。\n配置并启用mongodb_exporter # # grafana-agent 本身的配置 server: log_level: info http_listen_port: 12345 # grafana-agent 抓取 metrics 的相关配置（类似于prometheus的scrape_configs） metrics: global: scrape_interval: 15s scrape_timeout: 10s remote_write: - url: https://n9e-server:19000/prometheus/v1/write basic_auth: username: \u0026lt;string\u0026gt; password: \u0026lt;string\u0026gt; integrations: mongodb_exporter: enabled: true  采集的关键指标列表 # # Whether MongoDB is up. # 实例是否存活 # Gauge mongodb_up # The number of seconds that the current MongoDB process has been active # 实例启动累计时间（秒） # Counter mongodb_instance_uptime_seconds # The amount of memory, in mebibyte (MiB), currently used by the database process # 内存占用（MiB） # Gauge # mongodb_memory # The total combined latency in microseconds # 累计操作耗时（毫秒） mongodb_mongod_op_latencies_latency_total # The total number of operations performed since startup # 累计操作次数 # Counter mongodb_mongod_op_latencies_ops_total # The total number of operations received since the mongod instance last started # 累计接收的操作请求次数（即使操作不成功也会增加） # Counter mongodb_op_counters_total # The number of incoming connections from clients to the database server. This number includes the current shell session # 连接数 # Gauge # mongodb_connections # The number of open cursors # 打开游标数量 # Gauge mongodb_mongod_metrics_cursor_open # The total number of document access and modification patterns # 累计文档操作次数 # Counter mongodb_mongod_metrics_document_total # The total number of operations queued waiting for the lock # 当前排队等待获取锁的操作个数 # Gauge mongodb_mongod_global_lock_current_queue # The total number of (index or document) items scanned during queries and query-plan evaluation # 查询和查询计划评估过程扫描的（索引或文档）条目总数 # Counter mongodb_mongod_metrics_query_executor_total # The number of assertions raised since the MongoDB process started # 累计断言错误次数 # Counter mongodb_asserts_total # The total number of getLastError operations with a specified write concern (i.e. w) that wait for one or more members of a replica set to acknowledge the write operation (i.e. a w value greater than 1.) # 累计getLastError操作数量 # Counter mongodb_mongod_metrics_get_last_error_wtime_num_total # The number of times that write concern operations have timed out as a result of the wtimeout threshold to getLastError. This number increments for both default and non-default write concern specifications. # 累计getLastError超时操作数量 # Counter mongodb_mongod_metrics_get_last_error_wtimeouts_total # Size in byte of the data currently in cache # 当前缓存数据大小（byte） # Gauge mongodb_mongod_wiredtiger_cache_bytes # Size in byte of the data read into or write from cache # 写入或读取的缓存数据大小（byte） # Counter mongodb_mongod_wiredtiger_cache_bytes_total # Number of pages currently held in the cache # 当前缓存页数量 # Gauge mongodb_mongod_wiredtiger_cache_pages # The total number of pages (modified or unmodified) evicted # 累计缓存移除页数量 # Counter mongodb_mongod_wiredtiger_cache_evicted_total # The total number of page faults # 累计缺页中断次数 # Counter mongodb_extra_info_page_faults_total # The total number of bytes that the server has sent over network connections initiated by clients or other mongod or mongos instances. # 累计发送网络流量（byte） # Counter mongodb_ss_network_bytesOut # The total number of bytes that the server has received over network connections initiated by clients or other mongod or mongos instances # 累计接收网络流量（byte） # Counter mongodb_ss_network_bytesIn # The timestamp the node was elected as replica leader # 副本集选主时间 # Gauge mongodb_mongod_replset_member_election_date # The replication lag that this member has with the primary # 副本集成员主从延迟（秒） # Gauge mongodb_mongod_replset_member_replication_lag  完整地配置项说明 # # Enables the mongodb_exporter integration [enabled: \u0026lt;boolean\u0026gt; | default = false] # Sets an explicit value for the instance label when the integration is # self-scraped. Overrides inferred values. # # The default value for this integration is inferred from the hostname # portion of the mongodb_uri field. [instance: \u0026lt;string\u0026gt;] # Automatically collect metrics from this integration. If disabled, # the mongodb_exporter integration will be run but not scraped and thus not # remote-written. Metrics for the integration will be exposed at # /integrations/mongodb_exporter/metrics and can be scraped by an external # process. [scrape_integration: \u0026lt;boolean\u0026gt; | default = \u0026lt;integrations_config.scrape_integrations\u0026gt;] # How often should the metrics be collected? Defaults to # metrics.global.scrape_interval. [scrape_interval: \u0026lt;duration\u0026gt; | default = \u0026lt;global_config.scrape_interval\u0026gt;] # The timeout before considering the scrape a failure. Defaults to # metrics.global.scrape_timeout. [scrape_timeout: \u0026lt;duration\u0026gt; | default = \u0026lt;global_config.scrape_timeout\u0026gt;] # Allows for relabeling labels on the target. relabel_configs: [- \u0026lt;relabel_config\u0026gt; ... ] # Relabel metrics coming from the integration, allowing to drop series # from the integration that you don't care about. metric_relabel_configs: [ - \u0026lt;relabel_config\u0026gt; ... ] # How frequent to truncate the WAL for this integration. [wal_truncate_frequency: \u0026lt;duration\u0026gt; | default = \u0026quot;60m\u0026quot;] # Monitor the exporter itself and include those metrics in the results. [include_exporter_metrics: \u0026lt;bool\u0026gt; | default = false] # # Exporter-specific configuration options # # MongoDB node connection URL, which must be in the [`Standard Connection String Format`](https://docs.mongodb.com/manual/reference/connection-string/#std-label-connections-standard-connection-string-format) [mongodb_uri: \u0026lt;string\u0026gt;]  "}),e.add({id:44,href:"/docs/appendix/grafana-agent/integrations/redis-exporter-config/",title:"Redis Exporter",description:"grafana-agent内置了redis_exporter，可以采集Redis server的运行指标。\n目前grafana-agent，只支持配置一个Redis server地址，对其进行数据采集。如果您希望采集多个redis实例的metrics数据，那么需要启动多个grafana-agent实例，并通过relabel_configs来区分来自不同redis实例的数据。\n配置并启用redis_exporter # redis_exporter: enabled: true redis_addr: \u0026quot;redis-2:6379\u0026quot; relabel_configs: - source_labels: [__address__] target_label: instance replacement: redis-2  我们强烈推荐您使用独立的账号运行grafana-agent，并做好访问redis实例的最小化授权，避免过度授权带来的安全隐患，更多可以参考official documentation。\n采集的关键指标列表 # redis_active_defrag_running: When activedefrag is enabled, this indicates whether defragmentation is currently active, and the CPU percentage it intends to utilize. redis_allocator_active_bytes: Total bytes in the allocator active pages, this includes external-fragmentation. redis_allocator_allocated_bytes: Total bytes allocated form the allocator, including internal-fragmentation. Normally the same as used_memory. redis_allocator_frag_bytes: Delta between allocator_active and allocator_allocated.",content:"grafana-agent内置了redis_exporter，可以采集Redis server的运行指标。\n目前grafana-agent，只支持配置一个Redis server地址，对其进行数据采集。如果您希望采集多个redis实例的metrics数据，那么需要启动多个grafana-agent实例，并通过relabel_configs来区分来自不同redis实例的数据。\n配置并启用redis_exporter # redis_exporter: enabled: true redis_addr: \u0026quot;redis-2:6379\u0026quot; relabel_configs: - source_labels: [__address__] target_label: instance replacement: redis-2  我们强烈推荐您使用独立的账号运行grafana-agent，并做好访问redis实例的最小化授权，避免过度授权带来的安全隐患，更多可以参考official documentation。\n采集的关键指标列表 # redis_active_defrag_running: When activedefrag is enabled, this indicates whether defragmentation is currently active, and the CPU percentage it intends to utilize. redis_allocator_active_bytes: Total bytes in the allocator active pages, this includes external-fragmentation. redis_allocator_allocated_bytes: Total bytes allocated form the allocator, including internal-fragmentation. Normally the same as used_memory. redis_allocator_frag_bytes: Delta between allocator_active and allocator_allocated. See note about mem_fragmentation_bytes. redis_allocator_frag_ratio: Ratio between allocator_active and allocator_allocated. This is the true (external) fragmentation metric (not mem_fragmentation_ratio). redis_allocator_resident_bytes: Total bytes resident (RSS) in the allocator, this includes pages that can be released to the OS (by MEMORY PURGE, or just waiting). redis_allocator_rss_bytes: Delta between allocator_resident and allocator_active. redis_allocator_rss_ratio: Ratio between allocator_resident and allocator_active. This usually indicates pages that the allocator can and probably will soon release back to the OS. redis_aof_current_rewrite_duration_sec: Duration of the on-going AOF rewrite operation if any. redis_aof_enabled: Flag indicating AOF logging is activated. redis_aof_last_bgrewrite_status: Status of the last AOF rewrite operation. redis_aof_last_cow_size_bytes: The size in bytes of copy-on-write memory during the last AOF rewrite operation. redis_aof_last_rewrite_duration_sec: Duration of the last AOF rewrite operation in seconds. redis_aof_last_write_status: Status of the last write operation to the AOF. redis_aof_rewrite_in_progress: Flag indicating a AOF rewrite operation is on-going. redis_aof_rewrite_scheduled: Flag indicating an AOF rewrite operation will be scheduled once the on-going RDB save is complete. redis_blocked_clients: Number of clients pending on a blocking call (BLPOP, BRPOP, BRPOPLPUSH, BLMOVE, BZPOPMIN, BZPOPMAX). redis_client_recent_max_input_buffer_bytes: Biggest input buffer among current client connections. redis_client_recent_max_output_buffer_bytes: Biggest output buffer among current client connections. redis_cluster_enabled: Indicate Redis cluster is enabled. redis_commands_duration_seconds_total: The total CPU time consumed by these commands.(Counter) redis_commands_processed_total: Total number of commands processed by the server.(Counter) redis_commands_total: The number of calls that reached command execution (not rejected).(Counter) redis_config_maxclients: The value of the maxclients configuration directive. This is the upper limit for the sum of connected_clients, connected_slaves and cluster_connections. redis_config_maxmemory: The value of the maxmemory configuration directive. redis_connected_clients: Number of client connections (excluding connections from replicas). redis_connected_slaves: Number of connected replicas. redis_connections_received_total: Total number of connections accepted by the server.(Counter) redis_cpu_sys_children_seconds_total: System CPU consumed by the background processes.(Counter) redis_cpu_sys_seconds_total: System CPU consumed by the Redis server, which is the sum of system CPU consumed by all threads of the server process (main thread and background threads).(Counter) redis_cpu_user_children_seconds_total: User CPU consumed by the background processes.(Counter) redis_cpu_user_seconds_total: User CPU consumed by the Redis server, which is the sum of user CPU consumed by all threads of the server process (main thread and background threads).(Counter) redis_db_keys: Total number of keys by DB. redis_db_keys_expiring: Total number of expiring keys by DB redis_defrag_hits: Number of value reallocations performed by active the defragmentation process. redis_defrag_misses: Number of aborted value reallocations started by the active defragmentation process. redis_defrag_key_hits: Number of keys that were actively defragmented. redis_defrag_key_misses: Number of keys that were skipped by the active defragmentation process. redis_evicted_keys_total: Number of evicted keys due to maxmemory limit.(Counter) redis_expired_keys_total: Total number of key expiration events.(Counter) redis_expired_stale_percentage: The percentage of keys probably expired. redis_expired_time_cap_reached_total: The count of times that active expiry cycles have stopped early. redis_exporter_last_scrape_connect_time_seconds: The duration(in seconds) to connect when scrape. redis_exporter_last_scrape_duration_seconds: The last scrape duration. redis_exporter_last_scrape_error: The last scrape error status. redis_exporter_scrape_duration_seconds_count: Durations of scrapes by the exporter redis_exporter_scrape_duration_seconds_sum: Durations of scrapes by the exporter redis_exporter_scrapes_total: Current total redis scrapes.(Counter) redis_instance_info: Information about the Redis instance. redis_keyspace_hits_total: Hits total.(Counter) redis_keyspace_misses_total: Misses total.(Counter) redis_last_key_groups_scrape_duration_milliseconds: Duration of the last key group metrics scrape in milliseconds. redis_last_slow_execution_duration_seconds: The amount of time needed for last slow execution, in seconds. redis_latest_fork_seconds: The amount of time needed for last fork, in seconds. redis_lazyfree_pending_objects: The number of objects waiting to be freed (as a result of calling UNLINK, or FLUSHDB and FLUSHALL with the ASYNC option). redis_master_repl_offset: The server's current replication offset. redis_mem_clients_normal: Memory used by normal clients.(Gauge) redis_mem_clients_slaves: Memory used by replica clients - Starting Redis 7.0, replica buffers share memory with the replication backlog, so this field can show 0 when replicas don't trigger an increase of memory usage. redis_mem_fragmentation_bytes: Delta between used_memory_rss and used_memory. Note that when the total fragmentation bytes is low (few megabytes), a high ratio (e.g. 1.5 and above) is not an indication of an issue. redis_mem_fragmentation_ratio: Ratio between used_memory_rss and used_memory. Note that this doesn't only includes fragmentation, but also other process overheads (see the allocator_* metrics), and also overheads like code, shared libraries, stack, etc. redis_mem_not_counted_for_eviction_bytes: (Gauge) redis_memory_max_bytes: Max memory limit in bytes. redis_memory_used_bytes: Total number of bytes allocated by Redis using its allocator (either standard libc, jemalloc, or an alternative allocator such as tcmalloc) redis_memory_used_dataset_bytes: The size in bytes of the dataset (used_memory_overhead subtracted from used_memory) redis_memory_used_lua_bytes: Number of bytes used by the Lua engine. redis_memory_used_overhead_bytes: The sum in bytes of all overheads that the server allocated for managing its internal data structures. redis_memory_used_peak_bytes: Peak memory consumed by Redis (in bytes) redis_memory_used_rss_bytes: Number of bytes that Redis allocated as seen by the operating system (a.k.a resident set size). This is the number reported by tools such as top(1) and ps(1) redis_memory_used_scripts_bytes: Number of bytes used by cached Lua scripts redis_memory_used_startup_bytes: Initial amount of memory consumed by Redis at startup in bytes redis_migrate_cached_sockets_total: The number of sockets open for MIGRATE purposes redis_net_input_bytes_total: Total input bytes(Counter) redis_net_output_bytes_total: Total output bytes(Counter) redis_process_id: Process ID redis_pubsub_channels: Global number of pub/sub channels with client subscriptions redis_pubsub_patterns: Global number of pub/sub pattern with client subscriptions redis_rdb_bgsave_in_progress: Flag indicating a RDB save is on-going redis_rdb_changes_since_last_save: Number of changes since the last dump redis_rdb_current_bgsave_duration_sec: Duration of the on-going RDB save operation if any redis_rdb_last_bgsave_duration_sec: Duration of the last RDB save operation in seconds redis_rdb_last_bgsave_status: Status of the last RDB save operation redis_rdb_last_cow_size_bytes: The size in bytes of copy-on-write memory during the last RDB save operation redis_rdb_last_save_timestamp_seconds: Epoch-based timestamp of last successful RDB save redis_rejected_connections_total: Number of connections rejected because of maxclients limit(Counter) redis_repl_backlog_first_byte_offset: The master offset of the replication backlog buffer redis_repl_backlog_history_bytes: Size in bytes of the data in the replication backlog buffer redis_repl_backlog_is_active: Flag indicating replication backlog is active redis_replica_partial_resync_accepted: The number of accepted partial resync requests(Gauge) redis_replica_partial_resync_denied: The number of denied partial resync requests(Gauge) redis_replica_resyncs_full: The number of full resyncs with replicas redis_replication_backlog_bytes: Memory used by replication backlog redis_second_repl_offset: The offset up to which replication IDs are accepted. redis_slave_expires_tracked_keys: The number of keys tracked for expiry purposes (applicable only to writable replicas)(Gauge) redis_slowlog_last_id: Last id of slowlog redis_slowlog_length: Total slowlog redis_start_time_seconds: Start time of the Redis instance since unix epoch in seconds. redis_target_scrape_request_errors_total: Errors in requests to the exporter redis_up: Flag indicating redis instance is up redis_uptime_in_seconds: Number of seconds since Redis server start  完整地配置项说明 # # Enables the redis_exporter integration, allowing the Agent to automatically # collect system metrics from the configured redis address [enabled: \u0026lt;boolean\u0026gt; | default = false] # Sets an explicit value for the instance label when the integration is # self-scraped. Overrides inferred values. # # The default value for this integration is inferred from the hostname # portion of redis_addr. [instance: \u0026lt;string\u0026gt;] # Automatically collect metrics from this integration. If disabled, # the redis_exporter integration will be run but not scraped and thus not # remote-written. Metrics for the integration will be exposed at # /integrations/redis_exporter/metrics and can be scraped by an external # process. [scrape_integration: \u0026lt;boolean\u0026gt; | default = \u0026lt;integrations_config.scrape_integrations\u0026gt;] # How often should the metrics be collected? Defaults to # prometheus.global.scrape_interval. [scrape_interval: \u0026lt;duration\u0026gt; | default = \u0026lt;global_config.scrape_interval\u0026gt;] # The timeout before considering the scrape a failure. Defaults to # prometheus.global.scrape_timeout. [scrape_timeout: \u0026lt;duration\u0026gt; | default = \u0026lt;global_config.scrape_timeout\u0026gt;] # Allows for relabeling labels on the target. relabel_configs: [- \u0026lt;relabel_config\u0026gt; ... ] # Relabel metrics coming from the integration, allowing to drop series # from the integration that you don't care about. metric_relabel_configs: [ - \u0026lt;relabel_config\u0026gt; ... ] # How frequent to truncate the WAL for this integration. [wal_truncate_frequency: \u0026lt;duration\u0026gt; | default = \u0026quot;60m\u0026quot;] # Monitor the exporter itself and include those metrics in the results. [include_exporter_metrics: \u0026lt;bool\u0026gt; | default = false] # exporter-specific configuration options # Address of the redis instance. redis_addr: \u0026lt;string\u0026gt; # User name to use for authentication (Redis ACL for Redis 6.0 and newer). [redis_user: \u0026lt;string\u0026gt;] # Password of the redis instance. [redis_password: \u0026lt;string\u0026gt;] # Path of a file containing a passord. If this is defined, it takes precedece # over redis_password. [redis_password_file: \u0026lt;string\u0026gt;] # Namespace for the metrics. [namespace: \u0026lt;string\u0026gt; | default = \u0026quot;redis\u0026quot;] # What to use for the CONFIG command. [config_command: \u0026lt;string\u0026gt; | default = \u0026quot;CONFIG\u0026quot;] # Comma separated list of key-patterns to export value and length/size, searched for with SCAN. [check_keys: \u0026lt;string\u0026gt;] # Comma separated list of LUA regex for grouping keys. When unset, no key # groups will be made. [check_key_groups: \u0026lt;string\u0026gt;] # Check key or key groups batch size hint for the underlying SCAN. Keeping the same name for backwards compatibility, but this applies to both key and key groups batch size configuration. [check_key_groups_batch_size: \u0026lt;int\u0026gt; | default = 10000] # The maximum number of distinct key groups with the most memory utilization # to present as distinct metrics per database. The leftover key groups will be # aggregated in the 'overflow' bucket. [max_distinct_key_groups: \u0026lt;int\u0026gt; | default = 100] # Comma separated list of single keys to export value and length/size. [check_single_keys: \u0026lt;string\u0026gt;] # Comma separated list of stream-patterns to export info about streams, groups and consumers, searched for with SCAN. [check_streams: \u0026lt;string\u0026gt;] # Comma separated list of single streams to export info about streams, groups and consumers. [check_single_streams: \u0026lt;string\u0026gt;] # Comma separated list of individual keys to export counts for. [count_keys: \u0026lt;string\u0026gt;] # Path to Lua Redis script for collecting extra metrics. [script_path: \u0026lt;string\u0026gt;] # Timeout for connection to Redis instance (in Golang duration format). [connection_timeout: \u0026lt;time.Duration\u0026gt; | default = \u0026quot;15s\u0026quot;] # Name of the client key file (including full path) if the server requires TLS client authentication. [tls_client_key_file: \u0026lt;string\u0026gt;] # Name of the client certificate file (including full path) if the server requires TLS client authentication. [tls_client_cert_file: \u0026lt;string\u0026gt;] # Name of the CA certificate file (including full path) if the server requires TLS client authentication. [tls_ca_cert_file: \u0026lt;string\u0026gt;] # Whether to set client name to redis_exporter. [set_client_name: \u0026lt;bool\u0026gt;] # Whether to scrape Tile38 specific metrics. [is_tile38: \u0026lt;bool\u0026gt;] # Whether to scrape Client List specific metrics. [export_client_list: \u0026lt;bool\u0026gt;] # Whether to include the client's port when exporting the client list. Note # that including this will increase the cardinality of all redis metrics. [export_client_port: \u0026lt;bool\u0026gt;] # Whether to also export go runtime metrics. [redis_metrics_only: \u0026lt;bool\u0026gt;] # Whether to ping the redis instance after connecting. [ping_on_connect: \u0026lt;bool\u0026gt;] # Whether to include system metrics like e.g. redis_total_system_memory_bytes. [incl_system_metrics: \u0026lt;bool\u0026gt;] # Whether to to skip TLS verification. [skip_tls_verification: \u0026lt;bool\u0026gt;]  "}),e.add({id:45,href:"/docs/appendix/grafana-agent/integrations/memcached-exporter-config/",title:"Memcached Exporter",description:"grafana-agent内置了memcached_exporter，来采集memcached的运行指标。\n当前grafana-agent只支持配置一个memcached的地址来采集其metrics数据。如果您需要采集多个memcached的metrics指标，那么需要启动多个grafana-agent实例，并通过relabel_configs来区分来自不同memcached server的metrics。\n配置并启用memcached_exporter # memcached_exporter: enabled: true memcached_address: memcached-a:53 relabel_configs: - source_labels: [__address__] target_label: instance replacement: memcached-a  采集的关键指标列表 # memcached_commands_total : sum (memcached_commands_total{instance=~\u0026quot;$node\u0026quot;, command=\u0026quot;set\u0026quot;}) / sum (memcached_commands_total{instance=~\u0026quot;$node\u0026quot;, command=\u0026quot;get\u0026quot;}) memcached_commands_total : sum (memcached_commands_total{instance=~\u0026quot;$node\u0026quot;, status=\u0026quot;miss\u0026quot;}) / sum (memcached_commands_total{instance=~\u0026quot;$node\u0026quot;}) memcached_commands_total : sum (memcached_commands_total{instance=~\u0026quot;$node\u0026quot;}) by (command) memcached_current_bytes : sum(memcached_current_bytes{instance=~\u0026quot;$node\u0026quot;}) / sum(memcached_limit_bytes{instance=~\u0026quot;$node\u0026quot;}) memcached_current_connections : sum (memcached_current_connections{instance=~\u0026quot;$node\u0026quot;}) by (instance) memcached_current_items : sum (memcached_current_items{instance=~\u0026quot;$node\u0026quot;}) memcached_items_evicted_total : sum(memcached_items_evicted_total{instance=~\u0026quot;$node\u0026quot;}) memcached_items_reclaimed_total : sum(memcached_items_reclaimed_total{instance=~\u0026quot;$node\u0026quot;}) memcached_read_bytes_total : sum(irate(memcached_read_bytes_total{instance=~\u0026quot;$node\u0026quot;}[5m])) memcached_written_bytes_total : irate(memcached_written_bytes_total{instance=~\u0026quot;$node\u0026quot;}[10m])  完整地配置项说明 # # Enables the memcached_exporter integration, allowing the Agent to automatically # collect system metrics from the configured memcached server address [enabled: \u0026lt;boolean\u0026gt; | default = false] # Sets an explicit value for the instance label when the integration is # self-scraped.",content:"grafana-agent内置了memcached_exporter，来采集memcached的运行指标。\n当前grafana-agent只支持配置一个memcached的地址来采集其metrics数据。如果您需要采集多个memcached的metrics指标，那么需要启动多个grafana-agent实例，并通过relabel_configs来区分来自不同memcached server的metrics。\n配置并启用memcached_exporter # memcached_exporter: enabled: true memcached_address: memcached-a:53 relabel_configs: - source_labels: [__address__] target_label: instance replacement: memcached-a  采集的关键指标列表 # memcached_commands_total : sum (memcached_commands_total{instance=~\u0026quot;$node\u0026quot;, command=\u0026quot;set\u0026quot;}) / sum (memcached_commands_total{instance=~\u0026quot;$node\u0026quot;, command=\u0026quot;get\u0026quot;}) memcached_commands_total : sum (memcached_commands_total{instance=~\u0026quot;$node\u0026quot;, status=\u0026quot;miss\u0026quot;}) / sum (memcached_commands_total{instance=~\u0026quot;$node\u0026quot;}) memcached_commands_total : sum (memcached_commands_total{instance=~\u0026quot;$node\u0026quot;}) by (command) memcached_current_bytes : sum(memcached_current_bytes{instance=~\u0026quot;$node\u0026quot;}) / sum(memcached_limit_bytes{instance=~\u0026quot;$node\u0026quot;}) memcached_current_connections : sum (memcached_current_connections{instance=~\u0026quot;$node\u0026quot;}) by (instance) memcached_current_items : sum (memcached_current_items{instance=~\u0026quot;$node\u0026quot;}) memcached_items_evicted_total : sum(memcached_items_evicted_total{instance=~\u0026quot;$node\u0026quot;}) memcached_items_reclaimed_total : sum(memcached_items_reclaimed_total{instance=~\u0026quot;$node\u0026quot;}) memcached_read_bytes_total : sum(irate(memcached_read_bytes_total{instance=~\u0026quot;$node\u0026quot;}[5m])) memcached_written_bytes_total : irate(memcached_written_bytes_total{instance=~\u0026quot;$node\u0026quot;}[10m])  完整地配置项说明 # # Enables the memcached_exporter integration, allowing the Agent to automatically # collect system metrics from the configured memcached server address [enabled: \u0026lt;boolean\u0026gt; | default = false] # Sets an explicit value for the instance label when the integration is # self-scraped. Overrides inferred values. # # The default value for this integration is inferred from # memcached_address. [instance: \u0026lt;string\u0026gt;] # Automatically collect metrics from this integration. If disabled, # the memcached_exporter integration will be run but not scraped and thus not # remote-written. Metrics for the integration will be exposed at # /integrations/memcached_exporter/metrics and can be scraped by an external # process. [scrape_integration: \u0026lt;boolean\u0026gt; | default = \u0026lt;integrations_config.scrape_integrations\u0026gt;] # How often should the metrics be collected? Defaults to # prometheus.global.scrape_interval. [scrape_interval: \u0026lt;duration\u0026gt; | default = \u0026lt;global_config.scrape_interval\u0026gt;] # The timeout before considering the scrape a failure. Defaults to # prometheus.global.scrape_timeout. [scrape_timeout: \u0026lt;duration\u0026gt; | default = \u0026lt;global_config.scrape_timeout\u0026gt;] # Allows for relabeling labels on the target. relabel_configs: [- \u0026lt;relabel_config\u0026gt; ... ] # Relabel metrics coming from the integration, allowing to drop series # from the integration that you don't care about. metric_relabel_configs: [ - \u0026lt;relabel_config\u0026gt; ... ] # How frequent to truncate the WAL for this integration. [wal_truncate_frequency: \u0026lt;duration\u0026gt; | default = \u0026quot;60m\u0026quot;] # Monitor the exporter itself and include those metrics in the results. [include_exporter_metrics: \u0026lt;bool\u0026gt; | default = false] # # Exporter-specific configuration options # # Address of the memcached server in host:port form. [memcached_address: \u0026lt;string\u0026gt; | default = \u0026quot;localhost:53\u0026quot;] # Timeout for connecting to memcached. [timeout: \u0026lt;duration\u0026gt; | default = \u0026quot;1s\u0026quot;]  "}),e.add({id:46,href:"/docs/appendix/grafana-agent/integrations/kafka-exporter-config/",title:"Kafka Exporter",description:"grafana-agent内置了kafka_exporter，来采集kafka的metrics指标。\n我们强烈推荐您使用独立的账号运行grafana-agent，并做好访问kafka实例的最小化授权，避免过度授权带来的安全隐患，更多可以参考documentation。\n配置并启用kafka_exporter # kafka_exporter: enabled: true # Address array (host:port) of Kafka server kafka_uris: ['xxx','yyy']  采集的关键指标列表 # kafka_brokers: count of kafka_brokers (gauge) kafka_topic_partitions: Number of partitions for this Topic (gauge) kafka_topic_partition_current_offset: Current Offset of a Broker at Topic/Partition (gauge) kafka_consumergroup_current_offset: Current Offset of a ConsumerGroup at Topic/Partition (gauge) kafka_consumer_lag_millis: Current approximation of consumer lag for a ConsumerGroup at Topic/Partition (gauge) kafka_topic_partition_under_replicated_partition: 1 if Topic/Partition is under Replicated  完整地配置项说明 # # Enables the kafka_exporter integration, allowing the Agent to automatically # collect system metrics from the configured dnsmasq server address [enabled: \u0026lt;boolean\u0026gt; | default = false] # Sets an explicit value for the instance label when the integration is # self-scraped.",content:"grafana-agent内置了kafka_exporter，来采集kafka的metrics指标。\n我们强烈推荐您使用独立的账号运行grafana-agent，并做好访问kafka实例的最小化授权，避免过度授权带来的安全隐患，更多可以参考documentation。\n配置并启用kafka_exporter # kafka_exporter: enabled: true # Address array (host:port) of Kafka server kafka_uris: ['xxx','yyy']  采集的关键指标列表 # kafka_brokers: count of kafka_brokers (gauge) kafka_topic_partitions: Number of partitions for this Topic (gauge) kafka_topic_partition_current_offset: Current Offset of a Broker at Topic/Partition (gauge) kafka_consumergroup_current_offset: Current Offset of a ConsumerGroup at Topic/Partition (gauge) kafka_consumer_lag_millis: Current approximation of consumer lag for a ConsumerGroup at Topic/Partition (gauge) kafka_topic_partition_under_replicated_partition: 1 if Topic/Partition is under Replicated  完整地配置项说明 # # Enables the kafka_exporter integration, allowing the Agent to automatically # collect system metrics from the configured dnsmasq server address [enabled: \u0026lt;boolean\u0026gt; | default = false] # Sets an explicit value for the instance label when the integration is # self-scraped. Overrides inferred values. # # The default value for this integration is inferred from the hostname # portion of the first kafka_uri value. If there is more than one string # in kafka_uri, the integration will fail to load and an instance value # must be manually provided. [instance: \u0026lt;string\u0026gt;] # Automatically collect metrics from this integration. If disabled, # the dnsmasq_exporter integration will be run but not scraped and thus not # remote-written. Metrics for the integration will be exposed at # /integrations/dnsmasq_exporter/metrics and can be scraped by an external # process. [scrape_integration: \u0026lt;boolean\u0026gt; | default = \u0026lt;integrations_config.scrape_integrations\u0026gt;] # How often should the metrics be collected? Defaults to # prometheus.global.scrape_interval. [scrape_interval: \u0026lt;duration\u0026gt; | default = \u0026lt;global_config.scrape_interval\u0026gt;] # The timeout before considering the scrape a failure. Defaults to # prometheus.global.scrape_timeout. [scrape_timeout: \u0026lt;duration\u0026gt; | default = \u0026lt;global_config.scrape_timeout\u0026gt;] # Allows for relabeling labels on the target. relabel_configs: [- \u0026lt;relabel_config\u0026gt; ... ] # Relabel metrics coming from the integration, allowing to drop series # from the integration that you don't care about. metric_relabel_configs: [ - \u0026lt;relabel_config\u0026gt; ... ] # How frequent to truncate the WAL for this integration. [wal_truncate_frequency: \u0026lt;duration\u0026gt; | default = \u0026quot;60m\u0026quot;] # Monitor the exporter itself and include those metrics in the results. [include_exporter_metrics: \u0026lt;bool\u0026gt; | default = false] # Address array (host:port) of Kafka server [kafka_uris: \u0026lt;[]string\u0026gt;] # Connect using SASL/PLAIN [use_sasl: \u0026lt;bool\u0026gt;] # Only set this to false if using a non-Kafka SASL proxy [use_sasl_handshake: \u0026lt;bool\u0026gt; | default = true] # SASL user name [sasl_username: \u0026lt;string\u0026gt;] # SASL user password [sasl_password: \u0026lt;string\u0026gt;] # The SASL SCRAM SHA algorithm sha256 or sha512 as mechanism [sasl_mechanism: \u0026lt;string\u0026gt;] # Connect using TLS [use_tls: \u0026lt;bool\u0026gt;] # The optional certificate authority file for TLS client authentication [ca_file: \u0026lt;string\u0026gt;] # The optional certificate file for TLS client authentication [cert_file: \u0026lt;string\u0026gt;] # The optional key file for TLS client authentication [key_file: \u0026lt;string\u0026gt;] # If true, the server's certificate will not be checked for validity. This will make your HTTPS connections insecure [insecure_skip_verify: \u0026lt;bool\u0026gt;] # Kafka broker version [kafka_version: \u0026lt;string\u0026gt; | default = \u0026quot;2.0.0\u0026quot;] # if you need to use a group from zookeeper [use_zookeeper_lag: \u0026lt;bool\u0026gt;] # Address array (hosts) of zookeeper server. [zookeeper_uris: \u0026lt;[]string\u0026gt;] # Kafka cluster name [kafka_cluster_name: \u0026lt;string\u0026gt;] # Metadata refresh interval [metadata_refresh_interval: \u0026lt;duration\u0026gt; | default = \u0026quot;1m\u0026quot;] # If true, all scrapes will trigger kafka operations otherwise, they will share results. WARN: This should be disabled on large clusters [allow_concurrency: \u0026lt;bool\u0026gt; | default = true] # Maximum number of offsets to store in the interpolation table for a partition [max_offsets: \u0026lt;int\u0026gt; | default = 1000] # How frequently should the interpolation table be pruned, in seconds [prune_interval_seconds: \u0026lt;int\u0026gt; | default = 30] # Regex filter for topics to be monitored [topics_filter_regex: \u0026lt;string\u0026gt; | default = \u0026quot;.*\u0026quot;] # Regex filter for consumer groups to be monitored [groups_filter_regex: \u0026lt;string\u0026gt; | default = \u0026quot;.*\u0026quot;]  "}),e.add({id:47,href:"/docs/appendix/grafana-agent/integrations/elasticsearch-exporter-config/",title:"Elasticsearch Exporter",description:"grafana-agent内置了elasticsearch_exporter，可以采集Elasticsearch的运行指标。\n目前grafana-agent不支持配置多个elasticsearch的地址，只能配置一个ElasticSearch地址对其进行metrics的采集。\n我们强烈推荐您使用独立的账号运行grafana-agent，并做好访问elasticsearch实例的最小化授权，避免过度授权带来的安全隐患，更多可以参考official documentation。\n配置并启用elasticsearch_exporter # elasticsearch_exporter: enabled: true address: \u0026quot;http://localhost:9200\u0026quot;  采集的关键指标列表 # # Estimated size in bytes of breaker # 断路器预估内存大小 # Gauge elasticsearch_breakers_estimated_size_bytes # Limit size in bytes for breaker # 断路器设置内存限制 # Gauge elasticsearch_breakers_limit_size_bytes # tripped for breaker # 断路器累计阻断此时 # Counter elasticsearch_breakers_tripped # The number of primary shards in your cluster. This is an aggregate total across all indices # 集群主分片数量 # Gauge elasticsearch_cluster_health_active_primary_shards # Aggregate total of all shards across all indices, which includes replica shards.",content:"grafana-agent内置了elasticsearch_exporter，可以采集Elasticsearch的运行指标。\n目前grafana-agent不支持配置多个elasticsearch的地址，只能配置一个ElasticSearch地址对其进行metrics的采集。\n我们强烈推荐您使用独立的账号运行grafana-agent，并做好访问elasticsearch实例的最小化授权，避免过度授权带来的安全隐患，更多可以参考official documentation。\n配置并启用elasticsearch_exporter # elasticsearch_exporter: enabled: true address: \u0026quot;http://localhost:9200\u0026quot;  采集的关键指标列表 # # Estimated size in bytes of breaker # 断路器预估内存大小 # Gauge elasticsearch_breakers_estimated_size_bytes # Limit size in bytes for breaker # 断路器设置内存限制 # Gauge elasticsearch_breakers_limit_size_bytes # tripped for breaker # 断路器累计阻断此时 # Counter elasticsearch_breakers_tripped # The number of primary shards in your cluster. This is an aggregate total across all indices # 集群主分片数量 # Gauge elasticsearch_cluster_health_active_primary_shards # Aggregate total of all shards across all indices, which includes replica shards. # 集群分片总数 # Gauge elasticsearch_cluster_health_active_shards # Shards delayed to reduce reallocation overhead # 暂缓重分配的分片数 # Gauge elasticsearch_cluster_health_delayed_unassigned_shards # Count of shards that are being freshly created # 创建中的分片数 # Gauge elasticsearch_cluster_health_initializing_shards # Number of data nodes in the cluster # 数据节点数 # Gauge elasticsearch_cluster_health_number_of_data_nodes # Number of nodes in the cluster # 节点总数 # Gauge elasticsearch_cluster_health_number_of_nodes # Cluster level changes which have not yet been executed # 等待执行的集群变更总数 # Gauge elasticsearch_cluster_health_number_of_pending_tasks # The number of shards that are currently moving from one node to another node # 迁移中的分片数 # Gauge elasticsearch_cluster_health_relocating_shards # Whether all primary and replica shards are allocated # 集群健康度 # Gauge elasticsearch_cluster_health_status # The number of shards that exist in the cluster state, but cannot be found in the cluster itself # 集群未分配的分片数 # Gauge elasticsearch_cluster_health_unassigned_shards # Available space on block device in bytes # 可用磁盘容量（byte） # Gauge elasticsearch_filesystem_data_available_bytes # Size of block device in bytes # 磁盘容量（byte） # Gauge elasticsearch_filesystem_data_size_bytes # Count of documents on this node # 节点文档总数 # Gauge elasticsearch_indices_docs # Count of deleted documents on this node # 节点删除文档数 # Gauge elasticsearch_indices_docs_deleted # Count of documents with only primary shards on all nodes # 所有节点主分片文档总数 # Gauge elasticsearch_indices_docs_primary # Evictions from field data # field data cache 内存剔除次数 # Counter elasticsearch_indices_fielddata_evictions # Field data cache memory usage in bytes # field data cache 内存占用（byte） # Gauge elasticsearch_indices_fielddata_memory_size_bytes # Evictions from filter cache # filter cache 内存剔除次数 # Counter elasticsearch_indices_filter_cache_evictions # Filter cache memory usage in bytes # filter cache 内存占用（byte） # Gauge elasticsearch_indices_flush_time_seconds # Total flushes # flush操作次数累计 # Counter elasticsearch_indices_flush_total # Total time get exists in seconds # get成功操作次数累计 # Counter elasticsearch_indices_get_exists_time_seconds # Total get exists operations # get操作次数累计 # Counter elasticsearch_indices_get_exists_total # Total time of get missing in seconds # get失败操作耗时累计（秒） # Counter elasticsearch_indices_get_missing_time_seconds # Total get missing # get失败操作次数累计 # Counter elasticsearch_indices_get_missing_total # Total get time in seconds # get操作耗时累计（秒） # Counter elasticsearch_indices_get_time_seconds # Total get # get操作次数累计 # Counter elasticsearch_indices_get_tota # Total time indexing delete in seconds # 索引删除累计耗时（秒） # Counter elasticsearch_indices_indexing_delete_time_seconds_total # Total indexing deletes # 索引删除操作次数累计 # Counter elasticsearch_indices_indexing_delete_total # Cumulative index time in seconds # index操作累计耗时（秒） # Counter elasticsearch_indices_indexing_index_time_seconds_total # Total index calls # index操作数量累计 # Counter elasticsearch_indices_indexing_index_total # Cumulative docs merged # merge文档数量累计 # Counter elasticsearch_indices_merges_docs_total # Total merges # merge操作数量累计 # Counter elasticsearch_indices_merges_total # Total merge size in bytes # merge操作数据大小累计（byte） # Counter elasticsearch_indices_merges_total_size_bytes_total # Total time spent merging in seconds # merge操作累计耗时（秒） # Counter elasticsearch_indices_merges_total_time_seconds_total # Evictions from query cache # query cache 内存剔除次数 # Counter elasticsearch_indices_query_cache_evictions # Query cache memory usage in bytes # query cache 内存占用（byte） # Gauge elasticsearch_indices_query_cache_memory_size_bytes # Total time spent refreshing in seconds # refresh操作耗时累计（秒） # Counter elasticsearch_indices_refresh_time_seconds_total # Total refreshes # refresh操作次数累计 # Counter elasticsearch_indices_refresh_total # Total search fetch time in seconds # fetch操作耗时累计（秒） # Counter elasticsearch_indices_search_fetch_time_seconds # Total number of fetches # fetch操作次数累计 # Counter elasticsearch_indices_search_fetch_total # Total search query time in seconds # query操作耗时累计（秒） # Counter elasticsearch_indices_search_query_time_seconds # Total number of queries # query操作次数累计 # Counter elasticsearch_indices_search_query_total # Segments with only primary shards on all nodes # 所有节点主分片segment总数 # Gauge elasticsearch_indices_segment_count_primary # Segments with all shards on all nodes # 所有节点所有分片segment总数 # Gauge elasticsearch_indices_segment_count_total # Doc values with only primary shards on all nodes in bytes # 主分片doc value内存占用（byte） # Gauge elasticsearch_indices_segment_doc_values_memory_bytes_primary # Doc values with all shards on all nodes in bytes # 所有分片doc value内存占用（byte） # Gauge elasticsearch_indices_segment_doc_values_memory_bytes_total # Size of fields with only primary shards on all nodes in bytes # 分片field内存占用（byte） # Gauge elasticsearch_indices_segment_fields_memory_bytes_primary # Size of fields with all shards on all nodes in bytes # 所有分片field内存占用（byte） # Gauge elasticsearch_indices_segment_fields_memory_bytes_total # Size of fixed bit with only primary shards on all nodes in bytes # 主分片fixed bit set内存占用（byte） # Gauge elasticsearch_indices_segment_fixed_bit_set_memory_bytes_primary # Size of fixed bit with all shards on all nodes in bytes # 所有分片fixed bit set内存占用（byte） # Gauge elasticsearch_indices_segment_fixed_bit_set_memory_bytes_total # Index writer with only primary shards on all nodes in bytes # 主分片索引写入数据量（byte） # Gauge elasticsearch_indices_segment_index_writer_memory_bytes_primary # Index writer with all shards on all nodes in bytes # 所有分片索引写入数据量（byte） # Gauge elasticsearch_indices_segment_index_writer_memory_bytes_total # Size of segments with only primary shards on all nodes in bytes # 主分片segment数 # Gauge elasticsearch_indices_segment_memory_bytes_primary # Size of segments with all shards on all nodes in bytes # 所有分片segment总数 # Gauge elasticsearch_indices_segment_memory_bytes_total # Size of norms with only primary shards on all nodes in bytes # 主分片normalization factor内存占用（byte） # Gauge elasticsearch_indices_segment_norms_memory_bytes_primary # Size of norms with all shards on all nodes in bytes # 所有分片normalization factor内存占用（byte） # Gauge elasticsearch_indices_segment_norms_memory_bytes_total # Size of points with only primary shards on all nodes in bytes # 主分片point内存占用（byte） # Gauge elasticsearch_indices_segment_points_memory_bytes_primary # Size of points with all shards on all nodes in bytes # 所有分片point内存占用（byte） # Gauge elasticsearch_indices_segment_points_memory_bytes_total # Size of terms with only primary shards on all nodes in bytes # 主分片term内存占用（byte） # Gauge elasticsearch_indices_segment_terms_memory_primary # Number of terms with all shards on all nodes in bytes # 所有分片term内存占用（byte） # Gauge elasticsearch_indices_segment_terms_memory_total # Size of version map with only primary shards on all nodes in bytes # 所有分片version map内存占用（byte） # Gauge elasticsearch_indices_segment_version_map_memory_bytes_primary # Size of version map with all shards on all nodes in bytes # 所有分片version map内存占用（byte） # Gauge elasticsearch_indices_segment_version_map_memory_bytes_total # Count of index segments # segment个数 # Gauge elasticsearch_indices_segments_count # Current memory size of segments in bytes # segment内存占用（byte） # Gauge elasticsearch_indices_segments_memory_bytes # Current size of stored index data in bytes with only primary shards on all nodes # 主分片索引容量（byte） # Gauge elasticsearch_indices_store_size_bytes_primary # Current size of stored index data in bytes with all shards on all nodes # 所有分片索引容量（byte） # Gauge elasticsearch_indices_store_size_bytes_total # Throttle time for index store in seconds # 索引存储限制耗时（秒） # Counter elasticsearch_indices_store_throttle_time_seconds_total # Total translog operations # tranlog操作数累计 # Counter elasticsearch_indices_translog_operations # Total translog size in bytes # tranlog大小累计（byte） # Counter elasticsearch_indices_translog_size_in_bytes # Count of JVM GC runs # GC运行次数累计 # Counter elasticsearch_jvm_gc_collection_seconds_count # GC run time in seconds # GC运行耗时累计（秒） # C欧BT而 elasticsearch_jvm_gc_collection_seconds_sum # JVM memory currently committed by area # JVM申请内存大小（byte） # Gauge elasticsearch_jvm_memory_committed_bytes # JVM memory max # JVM内存限制大小（byte） # Gauge elasticsearch_jvm_memory_max_bytes # JVM memory peak used by pool # JVM内存峰值大小（byte） # Counter elasticsearch_jvm_memory_pool_peak_used_bytes # JVM memory currently used by area # JVM内存占用大小（byte） # Gauge elasticsearch_jvm_memory_used_bytes # Shortterm load average # 系统负载（1分钟） # Gauge elasticsearch_os_load1 # Midterm load average # 系统负载（5分钟） # Gauge elasticsearch_os_load15 # Longterm load average # 系统负载（15分钟） # Gauge elasticsearch_os_load5 # Percent CPU used by process # 进程CPU占用率 # Gauge elasticsearch_process_cpu_percent # Open file descriptors # 进程打开文件数 # Gauge elasticsearch_process_open_files_count # Thread Pool threads active # 活跃线程总数 # Gauge elasticsearch_thread_pool_active_count # Thread Pool operations completed # 线程池complete次数 # Counter elasticsearch_thread_pool_completed_count # Thread Pool operations rejected # 线程池reject次数 # Counter elasticsearch_thread_pool_rejected_count # Total number of bytes received # 网络收流量（byte） # Counter elasticsearch_transport_rx_size_bytes_total # Total number of bytes received # 网络发流量（byte） # Counter elasticsearch_transport_tx_size_bytes_total  完整地配置项说明 # # Enables the elasticsearch_exporter integration, allowing the Agent to automatically # collect system metrics from the configured ElasticSearch server address [enabled: \u0026lt;boolean\u0026gt; | default = false] # Sets an explicit value for the instance label when the integration is # self-scraped. Overrides inferred values. # # The default value for this integration is inferred from the hostname portion # of address. [instance: \u0026lt;string\u0026gt;] # Automatically collect metrics from this integration. If disabled, # the elasticsearch_exporter integration will be run but not scraped and thus not # remote-written. Metrics for the integration will be exposed at # /integrations/elasticsearch_exporter/metrics and can be scraped by an external # process. [scrape_integration: \u0026lt;boolean\u0026gt; | default = \u0026lt;integrations_config.scrape_integrations\u0026gt;] # How often should the metrics be collected? Defaults to # prometheus.global.scrape_interval. [scrape_interval: \u0026lt;duration\u0026gt; | default = \u0026lt;global_config.scrape_interval\u0026gt;] # The timeout before considering the scrape a failure. Defaults to # prometheus.global.scrape_timeout. [scrape_timeout: \u0026lt;duration\u0026gt; | default = \u0026lt;global_config.scrape_timeout\u0026gt;] # Allows for relabeling labels on the target. relabel_configs: [- \u0026lt;relabel_config\u0026gt; ... ] # Relabel metrics coming from the integration, allowing to drop series # from the integration that you don't care about. metric_relabel_configs: [ - \u0026lt;relabel_config\u0026gt; ... ] # How frequent to truncate the WAL for this integration. [wal_truncate_frequency: \u0026lt;duration\u0026gt; | default = \u0026quot;60m\u0026quot;] # Monitor the exporter itself and include those metrics in the results. [include_exporter_metrics: \u0026lt;bool\u0026gt; | default = false] # # Exporter-specific configuration options # # HTTP API address of an Elasticsearch node. [ address: \u0026lt;string\u0026gt; | default = \u0026quot;http://localhost:9200\u0026quot; ] # Timeout for trying to get stats from Elasticsearch. [ timeout: \u0026lt;duration\u0026gt; | default = \u0026quot;5s\u0026quot; ] # Export stats for all nodes in the cluster. If used, this flag will override the flag `node`. [ all: \u0026lt;boolean\u0026gt; ] # Node's name of which metrics should be exposed. [ node: \u0026lt;boolean\u0026gt; ] # Export stats for indices in the cluster. [ indices: \u0026lt;boolean\u0026gt; ] # Export stats for settings of all indices of the cluster. [ indices_settings: \u0026lt;boolean\u0026gt; ] # Export stats for cluster settings. [ cluster_settings: \u0026lt;boolean\u0026gt; ] # Export stats for shards in the cluster (implies indices). [ shards: \u0026lt;boolean\u0026gt; ] # Export stats for the cluster snapshots. [ snapshots: \u0026lt;boolean\u0026gt; ] # Cluster info update interval for the cluster label. [ clusterinfo_interval: \u0026lt;duration\u0026gt; | default = \u0026quot;5m\u0026quot; ] # Path to PEM file that contains trusted Certificate Authorities for the Elasticsearch connection. [ ca: \u0026lt;string\u0026gt; ] # Path to PEM file that contains the private key for client auth when connecting to Elasticsearch. [ client_private_key: \u0026lt;string\u0026gt; ] # Path to PEM file that contains the corresponding cert for the private key to connect to Elasticsearch. [ client_cert: \u0026lt;string\u0026gt; ] # Skip SSL verification when connecting to Elasticsearch. [ ssl_skip_verify: \u0026lt;boolean\u0026gt; ]  "}),e.add({id:48,href:"/docs/appendix/grafana-agent/integrations/consul-exporter-config/",title:"Consul Exporter",description:"The consul_exporter_config block configures the consul_exporter integration, which is an embedded version of consul_exporter. This allows for the collection of consul metrics and exposing them as Prometheus metrics.\nFull reference of options:\n# Enables the consul_exporter integration, allowing the Agent to automatically # collect system metrics from the configured consul server address [enabled: \u0026lt;boolean\u0026gt; | default = false] # Sets an explicit value for the instance label when the integration is # self-scraped.",content:"The consul_exporter_config block configures the consul_exporter integration, which is an embedded version of consul_exporter. This allows for the collection of consul metrics and exposing them as Prometheus metrics.\nFull reference of options:\n# Enables the consul_exporter integration, allowing the Agent to automatically # collect system metrics from the configured consul server address [enabled: \u0026lt;boolean\u0026gt; | default = false] # Sets an explicit value for the instance label when the integration is # self-scraped. Overrides inferred values. # # The default value for this integration is inferred from the hostname portion # of the server URL. [instance: \u0026lt;string\u0026gt;] # Automatically collect metrics from this integration. If disabled, # the consul_exporter integration will be run but not scraped and thus not # remote-written. Metrics for the integration will be exposed at # /integrations/consul_exporter/metrics and can be scraped by an external # process. [scrape_integration: \u0026lt;boolean\u0026gt; | default = \u0026lt;integrations_config.scrape_integrations\u0026gt;] # How often should the metrics be collected? Defaults to # prometheus.global.scrape_interval. [scrape_interval: \u0026lt;duration\u0026gt; | default = \u0026lt;global_config.scrape_interval\u0026gt;] # The timeout before considering the scrape a failure. Defaults to # prometheus.global.scrape_timeout. [scrape_timeout: \u0026lt;duration\u0026gt; | default = \u0026lt;global_config.scrape_timeout\u0026gt;] # Allows for relabeling labels on the target. relabel_configs: [- \u0026lt;relabel_config\u0026gt; ... ] # Relabel metrics coming from the integration, allowing to drop series # from the integration that you don't care about. metric_relabel_configs: [ - \u0026lt;relabel_config\u0026gt; ... ] # How frequent to truncate the WAL for this integration. [wal_truncate_frequency: \u0026lt;duration\u0026gt; | default = \u0026quot;60m\u0026quot;] # Monitor the exporter itself and include those metrics in the results. [include_exporter_metrics: \u0026lt;bool\u0026gt; | default = false] # # Exporter-specific configuration options # # Prefix from which to expose key/value pairs. [kv_prefix: \u0026lt;string\u0026gt; | default = \u0026quot;\u0026quot;] # Regex that determines which keys to expose. [kv_filter: \u0026lt;string\u0026gt; | default = \u0026quot;.*\u0026quot;] # Generate a health summary for each service instance. Needs n+1 queries to # collect all information. [generate_health_summary: \u0026lt;bool\u0026gt; | default = true] # HTTP API address of a Consul server or agent. Prefix with https:// to # connect using HTTPS. [server: \u0026lt;string\u0026gt; | default = \u0026quot;http://localhost:8500\u0026quot;] # Disable TLS host verification. [insecure_skip_verify: \u0026lt;bool\u0026gt; | default = false] # File path to a PEM-encoded certificate authority used to validate the # authenticity of a server certificate. [ca_file: \u0026lt;string\u0026gt; | default = \u0026quot;\u0026quot;] # File path to a PEM-encoded certificate used with the private key to verify # the exporter's authenticity. [cert_file: \u0026lt;string\u0026gt; | default = \u0026quot;\u0026quot;] # File path to a PEM-encoded private key used with the certificate to verify # the exporter's authenticity. [key_file: \u0026lt;string\u0026gt; | default = \u0026quot;\u0026quot;] # When provided, this overrides the hostname for the TLS certificate. It can # be used to ensure that the certificate name matches the hostname we declare. [server_name: \u0026lt;string\u0026gt; | default = \u0026quot;\u0026quot;] # Timeout on HTTP requests to the Consul API. [timeout: \u0026lt;duration\u0026gt; | default = \u0026quot;500ms\u0026quot;] # Limit the maximum number of concurrent requests to consul. 0 means no limit. [concurrent_request_limit: \u0026lt;int\u0026gt; | default = 0] # Allows any Consul server (non-leader) to service a read. [allow_stale: \u0026lt;bool\u0026gt; | default = true] # Forces the read to be fully consistent. [require_consistent: \u0026lt;bool\u0026gt; | default = false]  采集的指标列表 # consul_memberlist_tcp : irate(consul_memberlist_tcp{host=\u0026quot;$consul\u0026quot;}[1m]) consul_memberlist_udp : irate(consul_memberlist_udp{host=\u0026quot;$consul\u0026quot;}[1m]) consul_raft_apply[30s]) : delta(consul_raft_apply[30s]) consul_raft_commitTime : consul_raft_commitTime consul_raft_leader_dispatchLog : consul_raft_leader_dispatchLog consul_raft_leader_lastcontact : consul_raft_leader_lastcontact consul_raft_leader_lastcontact_count : consul_raft_leader_lastcontact_count consul_raft_replication_appendEntries_rpc : consul_raft_replication_appendEntries_rpc consul_raft_replication_heartbeat : consul_raft_replication_heartbeat consul_rpc_query : delta(consul_rpc_query{host=\u0026quot;$consul\u0026quot;}[30s]) consul_serf_coordinate_adjustment_ms : consul_serf_coordinate_adjustment_ms{host=\u0026quot;$consul\u0026quot;} labels) : COUNT (changes(consul_memberlist_gossep_sum[1m]) \u0026gt; 0) BY (labels) node_cpu : sum(irate(node_cpu{mode=\u0026quot;idle\u0026quot;, host=\u0026quot;$consul\u0026quot;}[1m])) * 100 / count_scalar(node_cpu{mode=\u0026quot;user\u0026quot;, host=\u0026quot;$consul\u0026quot;}) node_load1 : node_load1{host=\u0026quot;$consul\u0026quot;} node_load15 : node_load15{host=\u0026quot;$consul\u0026quot;} node_load5 : node_load5{host=\u0026quot;$consul\u0026quot;}  "}),e.add({id:49,href:"/docs/appendix/grafana-agent/integrations/dnsmasq-exporter-config/",title:"dnsmasq Exporter",description:"The dnsmasq_exporter_config block configures the dnsmasq_exporter integration, which is an embedded version of dnsmasq_exporter. This allows for the collection of metrics from dnsmasq servers.\nNote that currently, an Agent can only collect metrics from a single dnsmasq server. If you want to collect metrics from multiple servers, you can run multiple Agents and add labels using relabel_configs to differentiate between the servers:\ndnsmasq_exporter: enabled: true dnsmasq_address: dnsmasq-a:53 relabel_configs: - source_labels: [__address__] target_label: instance replacement: dnsmasq-a  Full reference of options:",content:"The dnsmasq_exporter_config block configures the dnsmasq_exporter integration, which is an embedded version of dnsmasq_exporter. This allows for the collection of metrics from dnsmasq servers.\nNote that currently, an Agent can only collect metrics from a single dnsmasq server. If you want to collect metrics from multiple servers, you can run multiple Agents and add labels using relabel_configs to differentiate between the servers:\ndnsmasq_exporter: enabled: true dnsmasq_address: dnsmasq-a:53 relabel_configs: - source_labels: [__address__] target_label: instance replacement: dnsmasq-a  Full reference of options:\n# Enables the dnsmasq_exporter integration, allowing the Agent to automatically # collect system metrics from the configured dnsmasq server address [enabled: \u0026lt;boolean\u0026gt; | default = false] # Sets an explicit value for the instance label when the integration is # self-scraped. Overrides inferred values. # # The default value for this integration is inferred from the dnsmasq_address # value. [instance: \u0026lt;string\u0026gt;] # Automatically collect metrics from this integration. If disabled, # the dnsmasq_exporter integration will be run but not scraped and thus not # remote-written. Metrics for the integration will be exposed at # /integrations/dnsmasq_exporter/metrics and can be scraped by an external # process. [scrape_integration: \u0026lt;boolean\u0026gt; | default = \u0026lt;integrations_config.scrape_integrations\u0026gt;] # How often should the metrics be collected? Defaults to # prometheus.global.scrape_interval. [scrape_interval: \u0026lt;duration\u0026gt; | default = \u0026lt;global_config.scrape_interval\u0026gt;] # The timeout before considering the scrape a failure. Defaults to # prometheus.global.scrape_timeout. [scrape_timeout: \u0026lt;duration\u0026gt; | default = \u0026lt;global_config.scrape_timeout\u0026gt;] # Allows for relabeling labels on the target. relabel_configs: [- \u0026lt;relabel_config\u0026gt; ... ] # Relabel metrics coming from the integration, allowing to drop series # from the integration that you don't care about. metric_relabel_configs: [ - \u0026lt;relabel_config\u0026gt; ... ] # How frequent to truncate the WAL for this integration. [wal_truncate_frequency: \u0026lt;duration\u0026gt; | default = \u0026quot;60m\u0026quot;] # Monitor the exporter itself and include those metrics in the results. [include_exporter_metrics: \u0026lt;bool\u0026gt; | default = false] # # Exporter-specific configuration options # # Address of the dnsmasq server in host:port form. [dnsmasq_address: \u0026lt;string\u0026gt; | default = \u0026quot;localhost:53\u0026quot;] # Path to the dnsmasq leases file. If this file doesn't exist, scraping # dnsmasq # will fail with an warning log message. [leases_path: \u0026lt;string\u0026gt; | default = \u0026quot;/var/lib/misc/dnsmasq.leases\u0026quot;]  "}),e.add({id:50,href:"/docs/api/",title:"API",description:"夜莺 Nightingale API 手册",content:""}),e.add({id:51,href:"/docs/usage/",title:"使用手册",description:"夜莺 Nightingale 使用手册",content:""}),e.add({id:52,href:"/docs/agent/",title:"采集器",description:"监控数据采集器，Categraf、Telegraf、Grafana-Agent、Datadog-Agent等",content:""}),e.add({id:53,href:"/docs/install/",title:"安装部署",description:"夜莺安装部署",content:""}),e.add({id:54,href:"/docs/prologue/",title:"简介",description:"夜莺介绍",content:""}),e.add({id:55,href:"/docs/",title:"Nightingale",description:"Nightingale is a cloud native monitoring system",content:""}),e.add({id:56,href:"/docs/prologue/consulting/",title:"",description:"系列 内容     监控体系概论 ✅ 监控在可观测性体系的位置✅ 监控方法论概述✅ 全方位的监控蓝图概述   监控系统部署 ✅ 采集端、时序库，对比选型✅ 监控系统自身的高可用✅ 监控系统如何自监控   监控最佳实践 ✅ 应用业务监控的最佳实践 ✅ Kubernetes监控的最佳实践✅ 各类中间件的典型监控方法✅ AIOps如何落地✅ 日志监控如何落地✅ 故障自愈如何落地   稳定性系统建设方案 ✅ 大型服务稳定性建设最佳实践✅ 服务稳定性建设相关咨询交流    关于以上企业内训服务，请联系: 18612185520（微信同号）\n关于快猫 # 快猫星云，一家云原生智能运维科技公司，秉承着让监控分析变简单的初心和使命，致力于打造先进的云原生监控分析平台，结合人工智能技术，提升云原生时代数字化服务的稳定性保障能力。\n快猫星云团队是开源项目夜莺监控的主要贡献者、项目管理委员会核心成员。夜莺监控是一款开源云原生监控分析系统，采用 All-In-One 的设计，集数据采集、可视化、监控告警、数据分析于一体，与云原生生态紧密集成，提供开箱即用的企业级监控分析和告警能力，已有众多企业选择将 Prometheus + AlertManager + Grafana 的组合方案升级为使用夜莺监控。\n夜莺监控，由滴滴开发和开源，并于 2022 年 5 月 11 日，捐赠予中国计算机学会开源发展委员会（CCF ODC），为 CCF ODC 成立后接受捐赠的第一个开源项目。\n关于团队 # 快猫星云创始团队均来自阿里、百度、小米、滴滴等顶级互联⽹公司，在运维、云计算、企业服务领域有十多年的实践经验，是云计算、运维、稳定性保障各个领域的专家。",content:"   系列 内容     监控体系概论 ✅ 监控在可观测性体系的位置✅ 监控方法论概述✅ 全方位的监控蓝图概述   监控系统部署 ✅ 采集端、时序库，对比选型✅ 监控系统自身的高可用✅ 监控系统如何自监控   监控最佳实践 ✅ 应用业务监控的最佳实践 ✅ Kubernetes监控的最佳实践✅ 各类中间件的典型监控方法✅ AIOps如何落地✅ 日志监控如何落地✅ 故障自愈如何落地   稳定性系统建设方案 ✅ 大型服务稳定性建设最佳实践✅ 服务稳定性建设相关咨询交流    关于以上企业内训服务，请联系: 18612185520（微信同号）\n关于快猫 # 快猫星云，一家云原生智能运维科技公司，秉承着让监控分析变简单的初心和使命，致力于打造先进的云原生监控分析平台，结合人工智能技术，提升云原生时代数字化服务的稳定性保障能力。\n快猫星云团队是开源项目夜莺监控的主要贡献者、项目管理委员会核心成员。夜莺监控是一款开源云原生监控分析系统，采用 All-In-One 的设计，集数据采集、可视化、监控告警、数据分析于一体，与云原生生态紧密集成，提供开箱即用的企业级监控分析和告警能力，已有众多企业选择将 Prometheus + AlertManager + Grafana 的组合方案升级为使用夜莺监控。\n夜莺监控，由滴滴开发和开源，并于 2022 年 5 月 11 日，捐赠予中国计算机学会开源发展委员会（CCF ODC），为 CCF ODC 成立后接受捐赠的第一个开源项目。\n关于团队 # 快猫星云创始团队均来自阿里、百度、小米、滴滴等顶级互联⽹公司，在运维、云计算、企业服务领域有十多年的实践经验，是云计算、运维、稳定性保障各个领域的专家。\n"}),e.add({id:57,href:"/docs/appendix/grafana-agent/integrations/github-exporter-config/",title:"Github Exporter",description:"The github_exporter_config block configures the github_exporter integration, which is an embedded version of github_exporter. This allows for the collection of metrics from the github api.\nWe strongly recommend that you configure a separate authentication token for the Agent, and give it only the strictly mandatory security privileges necessary for monitoring your repositories, as per the official documentation. We also recommend that you use api_token_file parameter, to avoid setting the authentication token directly on the Agent config file.",content:"The github_exporter_config block configures the github_exporter integration, which is an embedded version of github_exporter. This allows for the collection of metrics from the github api.\nWe strongly recommend that you configure a separate authentication token for the Agent, and give it only the strictly mandatory security privileges necessary for monitoring your repositories, as per the official documentation. We also recommend that you use api_token_file parameter, to avoid setting the authentication token directly on the Agent config file.\nFull reference of options:\n# Enables the github_exporter integration, allowing the Agent to automatically # collect metrics for the specified github objects. [enabled: \u0026lt;boolean\u0026gt; | default = false] # Sets an explicit value for the instance label when the integration is # self-scraped. Overrides inferred values. # # The default value for this integration is inferred from the hostname portion # of api_url. [instance: \u0026lt;string\u0026gt;] # Automatically collect metrics from this integration. If disabled, # the github_exporter integration will be run but not scraped and thus not # remote-written. Metrics for the integration will be exposed at # /integrations/github_exporter/metrics and can be scraped by an external # process. [scrape_integration: \u0026lt;boolean\u0026gt; | default = \u0026lt;integrations_config.scrape_integrations\u0026gt;] # How often should the metrics be collected? Defaults to # prometheus.global.scrape_interval. [scrape_interval: \u0026lt;duration\u0026gt; | default = \u0026lt;global_config.scrape_interval\u0026gt;] # The timeout before considering the scrape a failure. Defaults to # prometheus.global.scrape_timeout. [scrape_timeout: \u0026lt;duration\u0026gt; | default = \u0026lt;global_config.scrape_timeout\u0026gt;] # Allows for relabeling labels on the target. relabel_configs: [- \u0026lt;relabel_config\u0026gt; ... ] # Relabel metrics coming from the integration, allowing to drop series # from the integration that you don't care about. metric_relabel_configs: [ - \u0026lt;relabel_config\u0026gt; ... ] # How frequent to truncate the WAL for this integration. [wal_truncate_frequency: \u0026lt;duration\u0026gt; | default = \u0026quot;60m\u0026quot;] # # Exporter-specific configuration options # # The full URI of the github API. [api_url: \u0026lt;string\u0026gt; | default = \u0026quot;https://api.github.com\u0026quot;] # A list of github repositories for which to collect metrics. repositories: [ - \u0026lt;string\u0026gt; ] # A list of github organizations for which to collect metrics. organizations: [ - \u0026lt;string\u0026gt; ] # A list of github users for which to collect metrics. users: [ - \u0026lt;string\u0026gt; ] # A github authentication token that allows the API to be queried more often. # Optional, but recommended. [api_token: \u0026lt;string\u0026gt;] # A path to a file containing a github authentication token that allows the # API to be queried more often. If supplied, this supercedes `api_token` # Optional, but recommended. [api_token_file: \u0026lt;string\u0026gt;]  "}),e.add({id:58,href:"/docs/appendix/grafana-agent/integrations/statsd-exporter-config/",title:"Statsd Exporter",description:"The statsd_exporter_config block configures the statsd_exporter integration, which is an embedded version of statsd_exporter. This allows for the collection of statsd metrics and exposing them as Prometheus metrics.\nFull reference of options:\n# Enables the statsd_exporter integration, allowing the Agent to automatically # collect system metrics from the configured statsd server address [enabled: \u0026lt;boolean\u0026gt; | default = false] # Sets an explicit value for the instance label when the integration is # self-scraped.",content:"The statsd_exporter_config block configures the statsd_exporter integration, which is an embedded version of statsd_exporter. This allows for the collection of statsd metrics and exposing them as Prometheus metrics.\nFull reference of options:\n# Enables the statsd_exporter integration, allowing the Agent to automatically # collect system metrics from the configured statsd server address [enabled: \u0026lt;boolean\u0026gt; | default = false] # Sets an explicit value for the instance label when the integration is # self-scraped. Overrides inferred values. # # The default value for this integration is inferred from the agent hostname # and HTTP listen port, delimited by a colon. [instance: \u0026lt;string\u0026gt;] # Automatically collect metrics from this integration. If disabled, # the statsd_exporter integration will be run but not scraped and thus not # remote-written. Metrics for the integration will be exposed at # /integrations/statsd_exporter/metrics and can be scraped by an external # process. [scrape_integration: \u0026lt;boolean\u0026gt; | default = \u0026lt;integrations_config.scrape_integrations\u0026gt;] # How often should the metrics be collected? Defaults to # prometheus.global.scrape_interval. [scrape_interval: \u0026lt;duration\u0026gt; | default = \u0026lt;global_config.scrape_interval\u0026gt;] # The timeout before considering the scrape a failure. Defaults to # prometheus.global.scrape_timeout. [scrape_timeout: \u0026lt;duration\u0026gt; | default = \u0026lt;global_config.scrape_timeout\u0026gt;] # Allows for relabeling labels on the target. relabel_configs: [- \u0026lt;relabel_config\u0026gt; ... ] # Relabel metrics coming from the integration, allowing to drop series # from the integration that you don't care about. metric_relabel_configs: [ - \u0026lt;relabel_config\u0026gt; ... ] # How frequent to truncate the WAL for this integration. [wal_truncate_frequency: \u0026lt;duration\u0026gt; | default = \u0026quot;60m\u0026quot;] # Monitor the exporter itself and include those metrics in the results. [include_exporter_metrics: \u0026lt;bool\u0026gt; | default = false] # # Exporter-specific configuration options # # The UDP address on which to receive statsd metric lines. An empty string # will disable UDP collection. [listen_udp: \u0026lt;string\u0026gt; | default = \u0026quot;:9125\u0026quot;] # The TCP address on which to receive statsd metric lines. An empty string # will disable TCP collection. [listen_tcp: \u0026lt;string\u0026gt; | default = \u0026quot;:9125\u0026quot;] # The Unixgram socket path to receive statsd metric lines. An empty string # will disable unixgram collection. [listen_unixgram: \u0026lt;string\u0026gt; | default = \u0026quot;\u0026quot;] # The permission mode of the unixgram socket, when enabled. [unix_socket_mode: \u0026lt;string\u0026gt; | default = \u0026quot;755\u0026quot;] # An optional mapping config that can translate dot-separated StatsD metrics # into labeled Prometheus metrics. For full instructions on how to write this # object, see the official documentation from the statsd_exporter: # # https://github.com/prometheus/statsd_exporter#metric-mapping-and-configuration # # Note that a SIGHUP will not reload this config. [mapping_config: \u0026lt;statsd_exporter.mapping_config\u0026gt;] # Size (in bytes) of the operating system's transmit read buffer associated # with the UDP or unixgram connection. Please make sure the kernel parameters # net.core.rmem_max is set to a value greater than the value specified. [read_buffer: \u0026lt;int\u0026gt; | default = 0] # Maximum size of your metric mapping cache. Relies on least recently used # replacement policy if max size is reached. [cache_size: \u0026lt;int\u0026gt; | default = 1000] # Metric mapping cache type. Valid values are \u0026quot;lru\u0026quot; and \u0026quot;random\u0026quot;. [cache_type: \u0026lt;string\u0026gt; | default = \u0026quot;lru\u0026quot;] # Size of internal queue for processing events. [event_queue_size: \u0026lt;int\u0026gt; | default = 10000] # Number of events to hold in queue before flushing. [event_flush_threshold: \u0026lt;int\u0026gt; | default = 1000] # Number of events to hold in queue before flushing. [event_flush_interval: \u0026lt;duration\u0026gt; | default = \u0026quot;200ms\u0026quot;] # Parse DogStatsd style tags. [parse_dogstatsd_tags: \u0026lt;bool\u0026gt; | default = true] # Parse InfluxDB style tags. [parse_influxdb_tags: \u0026lt;bool\u0026gt; | default = true] # Parse Librato style tags. [parse_librato_tags: \u0026lt;bool\u0026gt; | default = true] # Parse SignalFX style tags. [parse_signalfx_tags: \u0026lt;bool\u0026gt; | default = true]  "}),e.add({id:59,href:"/docs/prologue/opensource-vs-enterprise/",title:"企业版",description:"夜莺（ Nightingale ）社区版（开源版）和商业版的区别",content:"企业版 # 对于开源，开放源代码只是第一步，仅仅是个开始。我们深知，只有建立了健康、良性、具有特定利益共同体的社区，聚集了一批志同道合的开发者，那么开源项目才具备了长期发展的基础，才会有蓬勃的生命力。\n开源项目的背后，核心在于社区，离不开开放的治理架构。CCF 开源发展委员会具有开放、中立、创新、产学研融合等特点，且有开源领域和学界泰斗级别的大师领衔，是中国开源的幸事，我们相信，夜莺监控项目加入到CCF开源大家庭，在计算机学会的支持和带动下，在国产开源云原生监控领域，填补空白，做精做强。让夜莺监控项目，成为中国开源项目的标杆，成为国内开源社区治理的标杆，也成为开源与产学研创新结合的标杆，创造出更大的社会价值。\n此外，商业公司也是开源项目和开源社区成功的背后最重要的一支力量，北京快猫星云科技有限公司，一家云原生智能运维科技公司，秉承着让监控分析变简单的初心和使命，致力于打造先进的云原生监控分析平台，结合人工智能技术，提升云原生时代数字化服务的稳定性保障能力。快猫星云团队是开源项目夜莺监控的主要贡献者，快猫星云的产品也是基于开源夜莺的引擎构建的，也欢迎有商业化服务需求的公司能够支持快猫团队，采购商业版本的产品或开源技术支持服务，长期共赢。\n社区版 vs 企业版 # 企业版会有我们开发人员提供7X24的技术支持服务，帮您兜底问题，提供各类监控场景的最佳实践指导以及企业内训。同时提供更多额外的商业模块，增强开源监控的能力，您可以按需采购，按年订阅制收费模式。\n您可以通过如下两个途径了解我们提供的商业产品服务，感兴趣的话可以在 这里 提交您的信息，我们会有销售人员与您联系，组织产品技术交流，买不买没关系，交个朋友，或许您可以从我们的产品和技术交流中碰撞出思维火花。\n 快猫官网 https://flashcat.cloud 产品介绍资料     功能 社区版 企业版     All-in-one的数据采集器 ✅ ✅   Prometheus多集群管理和告警 ✅ ✅   指标查询和可视化 ✅ ✅   仪表盘 ✅ ✅   报警回调、报警自动化处理 ✅ ✅   报警配置、管理、订阅 ✅ ✅   智能报警 ✖ ✅   ElasticSearch 多数据源管理、告警、可视化 ✖ ✅   On-Call管理：报警聚合、降噪、升级、排班 ✖ ✅   故障发现：北极星系统 ✖ ✅   故障定位：灭火图、日志中心、事件墙系统 ✖ ✅   数据集成：集成企业内部已有工具和数据（metrics、logging、tracing） ✖ ✅   用户权限管理 基础版本 完善的企业级权限管理功能   技术支持获取途径 社区群、Github 专项支持群、视频会议、现场沟通   技术支持响应级别 社区群内响应、Github issue回应 支持最高响应级别 7*24   专家解决方案 ✖ 7 x 12 专家技术支持   产品实施维护 ✖ 快猫星云团队负责实施及产品的运维、升级、维护   企业内训服务 ✖ ✅ 监控体系建设方案✅ 监控系统部署维护方案✅ 监控体系最佳实践✅ 稳定性保障体系建设方案    "}),search.addEventListener("input",t,!0);function t(){const s=5;var n=this.value,o=e.search(n,{limit:s,enrich:!0});const t=new Map;for(const e of o.flatMap(e=>e.result)){if(t.has(e.doc.href))continue;t.set(e.doc.href,e.doc)}if(suggestions.innerHTML="",suggestions.classList.remove("d-none"),t.size===0&&n){const e=document.createElement("div");e.innerHTML=`No results for "<strong>${n}</strong>"`,e.classList.add("suggestion__no-results"),suggestions.appendChild(e);return}for(const[r,a]of t){const n=document.createElement("div");suggestions.appendChild(n);const e=document.createElement("a");e.href=r,n.appendChild(e);const o=document.createElement("span");o.textContent=a.title,o.classList.add("suggestion__title"),e.appendChild(o);const i=document.createElement("span");if(i.textContent=a.description,i.classList.add("suggestion__description"),e.appendChild(i),suggestions.appendChild(n),suggestions.childElementCount==s)break}}})()