<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>使用手册 on</title><link>https://n9e.github.io/docs/usage/</link><description>Recent content in 使用手册 on</description><generator>Hugo -- gohugo.io</generator><language>en-US</language><lastBuildDate>Fri, 03 Jun 2022 08:48:45 +0000</lastBuildDate><atom:link href="https://n9e.github.io/docs/usage/index.xml" rel="self" type="application/rss+xml"/><item><title>入门教程</title><link>https://n9e.github.io/docs/usage/video/</link><pubDate>Tue, 06 Oct 2020 08:48:57 +0000</pubDate><guid>https://n9e.github.io/docs/usage/video/</guid><description>视频讲解-夜莺页面功能介绍 视频讲解-告警自愈脚本的使用 视频讲解-监控对象的管理功能 视频讲解-如何接入多个时序存储 视频讲解-夜莺的配置文件 除了这些视频教程，使用手册这一章，还会提供更多小节来介绍一些大家常问的问题，比如如何监控交换机，如何监控应用等。从总体问题比例来看，夜莺服务端问题相对较少，大家摸索一下，很快可以掌握，疑问比较多的，是对各种目标的监控，比如如何监控 MySQL，如何监控 Redis 等，针对这部分问题，大家应该去查看采集器的文档，比如 Telegraf 每个采集器下面都有 README介绍， 通过这些 README，理论上就可以知道如何使用各个采集器。Categraf 的采集器目录 在这里， 未来我们也会把所有采集器补充完整的 README，以及告警规则和监控大盘JSON，大家导入直接就可以使用，当然，路漫漫其修远兮，一步一步来吧。</description></item><item><title>SNMP</title><link>https://n9e.github.io/docs/usage/snmp/</link><pubDate>Tue, 06 Oct 2020 08:48:57 +0000</pubDate><guid>https://n9e.github.io/docs/usage/snmp/</guid><description>监控网络设备，主要是通过 SNMP 协议，Categraf、Telegraf、Datadog-Agent、snmp_exporter 都提供了这个能力。
Categraf # Categraf 提供了一个网络设备的采集插件：switch_legacy，在 conf/input.switch_legacy 下可以看到配置文件，最核心就是配置交换机的 IP 以及认证信息，switch_legacy 当前只支持 v2 协议，所以认证信息就是 community 字段。其他配置都一目了然，这里就不赘述了。
这个插件是把之前 Open-Falcon 社区的 swcollector 直接拿过来了，感谢 冯骐 大佬持续在维护这个开源项目。
Telegraf # Telegraf 内置支持 SNMP 的采集，本节给一个入门例子，让大家快速上手，更多具体知识可以参考这里。在 telegraf.conf 中搜索 inputs.snmp，即可找到对应的配置，例子如下：
[[inputs.snmp]] agents = [&amp;quot;udp://172.25.79.194:161&amp;quot;] timeout = &amp;quot;5s&amp;quot; version = 3 agent_host_tag = &amp;quot;ident&amp;quot; retries = 1 sec_name = &amp;quot;managev3user&amp;quot; auth_protocol = &amp;quot;SHA&amp;quot; auth_password = &amp;quot;example.Demo.c0m&amp;quot; [[inputs.snmp.field]] oid = &amp;quot;RFC1213-MIB::sysUpTime.0&amp;quot; name = &amp;quot;uptime&amp;quot; [[inputs.snmp.field]] oid = &amp;quot;RFC1213-MIB::sysName.0&amp;quot; name = &amp;quot;source&amp;quot; is_tag = true [[inputs.</description></item><item><title>应用监控</title><link>https://n9e.github.io/docs/usage/apm/</link><pubDate>Tue, 06 Oct 2020 08:48:57 +0000</pubDate><guid>https://n9e.github.io/docs/usage/apm/</guid><description>写在前面 # 应用监控实际要比 OS、中间件的监控更为关键，因为某个 OS 层面的指标异常，比如 CPU 飙高了，未必会影响终端用户的体验，但是应用层面的监控指标出问题，通常就会影响客户的感受、甚至影响客户的付费。
针对应用监控，Google提出了 4 个黄金指标，分别是：流量、延迟、错误、饱和度，其中前面 3 个指标都可以通过内嵌 SDK 的方式埋点采集，本节重点介绍这种方式。当然了，内嵌 SDK 有较强的代码侵入性，如果业务研发难以配合，也可以采用解析日志的方案，这个超出了夜莺（夜莺是指标监控系统）的范畴，大家如果感兴趣，可以了解一下快猫的商业化产品
埋点工具 # 最常见的通用埋点工具有两个，一个是 statsd，一个是 prometheus SDK，当然，各个语言也会有自己的更方便的方式，比如 Java 生态使用 micrometer 较多，如果是 SpringBoot 的程序，则使用 actuator 会更便捷，actuator 底层就是使用 micrometer。
夜莺自身监控 # 我们就以夜莺自身的代码举例，讲解如何内嵌埋点工具，这里选择 prometheus SDK 作为埋点方案。
夜莺核心模块有两个，Webapi 主要是提供 HTTP 接口给 JavaScript 调用，Server 主要是负责接收监控数据，处理告警规则，这两个模块都引入了 Prometheus 的 Go 的SDK，用此方式做 App Performance 监控，本节以夜莺的代码为例，讲解如何使用 Prometheus 的 SDK。
Webapi # Webapi 模块主要统计两个内容，一个是请求的数量统计，一个是请求的延迟统计，统计时，要用不同的 Label 做维度区分，后面就可以通过不同的维度做多种多样的统计分析，对于 HTTP 请求，规划 4 个核心 Label，分别是：service、code、path、method。service 标识服务名称，要求全局唯一，便于和其他服务名称区分开，比如 Webapi 模块，就定义为 n9e-webapi，code 是 HTTP 返回的状态码，200 就表示成功数量，其他 code 就是失败的，后面我们可以据此统计成功率，method 是 HTTP 方法，GET、POST、PUT、DELETE 等，比如新增用户和获取用户列表可能都是 /api/n9e/users，从路径上无法区分，只能再加上 method 才能区分开。</description></item><item><title>Mtail日志监控</title><link>https://n9e.github.io/docs/usage/mtail/</link><pubDate>Tue, 06 Oct 2020 08:48:57 +0000</pubDate><guid>https://n9e.github.io/docs/usage/mtail/</guid><description>前言 # 说到日志监控，大家第一反应的可能是ELK的方案，或者Loki的方案，这两个方案都是把日志采集了发到中心，在中心存储、查看、分析，不过这个方案相对比较重量级一些，如果我们的需求只是从日志中提取一些metrics数据，比如统计一些日志中出现的Error次数之类的，则有一个更简单的方案。
这里给大家介绍一个Google出品的小工具，mtail，mtail就是流式读取日志，通过正则表达式匹配的方式从日志中提取metrics指标，这种方式可以利用目标机器的算力，不过如果量太大，可能会影响目标机器上的业务程序，另外一个好处是无侵入性，不需要业务埋点，如果业务程序是第三方供应商提供的，我们改不了其代码，mtail此时就非常合适了。当然了，如果业务程序是我们公司的人自己写的，那还是建议用埋点的方式采集指标，mtail只是作为一个补充吧。
mtail简介 # mtail的使用方案，参考如下两个文档（下载的话参考Releases页面）：
Deploying Programming Guide 我们拿mtail的启动命令来举例其用法：
mtail --progs /etc/mtail --logs /var/log/syslog --logs /var/log/ntp/peerstats 通过 --progs 参数指定一个目录，这个目录里放置一堆的*.mtail文件，每个mtail文件就是描述的正则提取规则，通过 --logs 参数来指定要监控的日志目录，可以写通配符，--logs 可以写多次，上例中只是指定了 --progs 和 --logs ，没有其他参数，mtail启动之后会自动监听一个端口3903，在3903的/metrics接口暴露符合Prometheus协议的监控数据，Prometheus 或者 Categraf 或者 Telegraf 等就可以从 /metrics 接口提取监控数据。
这样看起来，原理就很清晰了，mtail 启动之后，根据 --logs 找到相关日志文件，seek 到文件末尾，开始流式读取，每读到一行，就根据 --progs 指定的那些规则文件做匹配，看是否符合某些正则，从中提取时序数据，然后通过3903的/metrics暴露采集到的监控指标。当然，除了Prometheus这种/metrics方式暴露，mtail 还支持把监控数据直接推给 graphite 或者 statsd，具体可以参考：这里
mtail样例 # 这里我用mtail监控一下n9e-server的日志，从中提取一下各个告警规则触发的 notify 的数量，这个日志举例：
2021-12-27 10:00:30.537582 INFO engine/logger.go:19 event(cbb8d4be5efd07983c296aaa4dec5737 triggered) notify: rule_id=9 [__name__=net_response_result_code author=qin ident=10-255-0-34 port=4567 protocol=tcp server=localhost]2@1640570430 很明显，日志中有这么个关键字：notify: rule_id=9，可以用正则来匹配，统计出现的行数，ruleid 也可以从中提取到，这样，我们可以把 ruleid 作为标签上报，于是乎，我们就可以写出这样的 mtail 规则了：</description></item><item><title>ES日志告警</title><link>https://n9e.github.io/docs/usage/esalert/</link><pubDate>Mon, 03 Oct 2022 10:55:57 +0000</pubDate><guid>https://n9e.github.io/docs/usage/esalert/</guid><description>在收集到日志之后，我们通常会有下面几类基于日志做告警的需求：
统计日志中的 ERROR 关键字出现次数，超过阈值则发出告警； 从网关日志中提取服务接口的 QPS，出现较大波动则发出告警； 从网关日志中提取服务接口的延迟，延迟太高则发出告警； 我们可以基于夜莺的的整体流程，快速构建一个日志告警平台来满足上述的需求，本文从产品设计，架构设计，代码实现三个方面，来介绍如何基于夜莺来构建日志告警平台。为了满足大家的好奇心，我们来先看一张效果图，下图是告警历史详情页的截图。
产品设计 # 通过前文的介绍，我们的需求已经比较明确了，将应用的日志收集起来，在平台上配置告警规则，根据配置的规则触发告警通知，收到通知之后，我们在页面上可以看到和告警数据相关的日志原文，便于快速定位问题。
夜莺监控已经支持了告警规则配置页面和告警详情查看页面，所以我们可以直接复用这两个页面。当收到告警通知，点击到告警详情页时，夜莺目前的告警详情页只有查看时序数据的能力，没有查看日志原文的能力，所以还需要增加在详情页查看日志原文的能力。所以为了支持日志告警能力，在产品层面我们需要对夜莺的两个页面（告警规则页面、告警历史详情页面）进行改造。
告警规则配置页面：
历史告警页面：
架构设计 # 产品设计确定之后，我们来进行架构设计，首先看一下夜莺已有的能力
n9e-webapi 提供各种配置管理、即时数据查询、告警历史详情查看的能力 n9e-server 提供同步规则、查询数据、产生异常点、生成告警事件、告警屏蔽、告警订阅、告警通知的能力。 如果要增加日志告警能力，我们可以发现在产生异常点之后，n9e-server 后续的一系列能力是可以复用的，所以我们可以得到下面的架构图
从上图我们可以发现，日志告警模块只要实现下面4个功能即可
同步告警规则 从日志中提取 metric 数据和原文 根据规则判断数据是否异常 异常点发送给 n9e-server 搞清楚要做什么事情之后，下面我们要开始动手写代码了
代码实现 # 本小节主要是介绍日志告警模块代码实现的思路，我们可以开发一个独立的模块，主要是实现下面四个功能。
同步告警规则 # 我们可以通过定期查询 n9e-webapi 提供的 api 来同步告警规则，同步逻辑可以参考 n9e-server 模块 https://github.com/ccfos/nightingale/blob/main/src/server/memsto/alert_rule_cache.go 的逻辑，将从数据库查询，改成从 api 获取即可
日志中查询 metric 数据和原文 # Elasticsearch 提供了 bucket aggregations 和 metric aggregations 的 api，通过这两个 api ，我们可以根据查询条件查到对应的 metric 数据。通过 es 的 search api，我们可以根据查询条件查到日志原文。</description></item><item><title>JVM监控</title><link>https://n9e.github.io/docs/usage/jvm/</link><pubDate>Tue, 25 Oct 2022 10:55:57 +0000</pubDate><guid>https://n9e.github.io/docs/usage/jvm/</guid><description>本讲介绍JVM监控相关知识。
进程级监控 # Java类的程序，如果只是监控端口存活性，可以直接使用 Categraf 的 net_response 插件，如果只是监控进程存活性，以及进程的CPU、内存等使用率，这个和C的程序、Go的程序没有本质区别，使用 Categraf 的 procstat 插件。
procstat 插件的采集配置文件中，有这么一段配置：
# gather jvm metrics only when jstat is ready # gather_more_metrics = [ # &amp;quot;threads&amp;quot;, # &amp;quot;fd&amp;quot;, # &amp;quot;io&amp;quot;, # &amp;quot;uptime&amp;quot;, # &amp;quot;cpu&amp;quot;, # &amp;quot;mem&amp;quot;, # &amp;quot;limit&amp;quot;, # &amp;quot;jvm&amp;quot; # ] 如果打开，才能采集进程的 threads、fd、io、cpu、mem等的情况，如果不打开，只能采集到进程数量。其中 gather_more_metrics 中有一项是 jvm，如果配置了 jvm 这一项，会通过 jstat 采集一些 jvm 相关的指标，前提是机器上得有 jstat 命令可以用。
埋点方式 # 这个方式的监控，之前社区里有小伙伴分享过，链接在这里，这里就不重复讲解了</description></item><item><title>告警通知</title><link>https://n9e.github.io/docs/usage/notify/</link><pubDate>Tue, 06 Oct 2020 08:48:57 +0000</pubDate><guid>https://n9e.github.io/docs/usage/notify/</guid><description>夜莺告警通知，内置支持邮件、钉钉机器人、企微机器人、飞书机器人多种方式作为发送通道，也支持调用自定义脚本和Webhook，给用户自定义发送通道的能力。相关配置在 webapi.conf 和 server.conf 中都有涉及。这里分别讲解。
webapi.conf # [[NotifyChannels]] Label = &amp;quot;邮箱&amp;quot; # do not change Key Key = &amp;quot;email&amp;quot; [[NotifyChannels]] Label = &amp;quot;钉钉机器人&amp;quot; # do not change Key Key = &amp;quot;dingtalk&amp;quot; [[NotifyChannels]] Label = &amp;quot;企微机器人&amp;quot; # do not change Key Key = &amp;quot;wecom&amp;quot; [[NotifyChannels]] Label = &amp;quot;飞书机器人&amp;quot; # do not change Key Key = &amp;quot;feishu&amp;quot; [[ContactKeys]] Label = &amp;quot;Wecom Robot Token&amp;quot; # do not change Key Key = &amp;quot;wecom_robot_token&amp;quot; [[ContactKeys]] Label = &amp;quot;Dingtalk Robot Token&amp;quot; # do not change Key Key = &amp;quot;dingtalk_robot_token&amp;quot; [[ContactKeys]] Label = &amp;quot;Feishu Robot Token&amp;quot; # do not change Key Key = &amp;quot;feishu_robot_token&amp;quot; NotifyChannels是个数组，可以写多个，告警规则配置页面，展示的通知媒介，就是读取的这个配置文件的内容。</description></item><item><title>告警格式</title><link>https://n9e.github.io/docs/usage/format/</link><pubDate>Tue, 06 Oct 2020 08:48:57 +0000</pubDate><guid>https://n9e.github.io/docs/usage/format/</guid><description>告警事件的消息通知格式，是由模板控制的，模板文件在 etc/template 下：
dingtalk.tpl 钉钉的消息模板 feishu.tpl 飞书的消息模板 wecom.tpl 企业微信的消息模板 subject.tpl 邮件标题模板 mailbody.tpl 邮件内容模板 这些模板文件都遵从 go template 语法，模板中可以引用变量，有哪些变量可以引用呢？可以参考 AlertCurEvent 结构，这个结构的各个字段都可以被引用。
需求：如何自定义展示标签 # 告警事件中一般会有多个标签，模板文件中这个写法 {{.TagsJSON}} 可以按照数组的方式展示所有的标签。对于Kubernetes体系的监控数据，有的时候标签会非常非常多，看起来很费劲，有些朋友就会想，我是否可以自定义，只展示部分标签呢？
答案当然是可以的。TagsJSON 是所有标签的数组形式，TagsMap是所有标签的map形式，我们可以使用TagsMap来方便的获取特定的标签值，比如我这里修改企微的模板文件，不展示所有的标签：
**级别状态**: {{if .IsRecovered}}&amp;lt;font color=&amp;quot;info&amp;quot;&amp;gt;S{{.Severity}} Recovered&amp;lt;/font&amp;gt;{{else}}&amp;lt;font color=&amp;quot;warning&amp;quot;&amp;gt;S{{.Severity}} Triggered&amp;lt;/font&amp;gt;{{end}} **规则标题**: {{.RuleName}}{{if .RuleNote}} **规则备注**: {{.RuleNote}}{{end}} **监控指标**: {{$metric := index .TagsMap &amp;quot;__name__&amp;quot;}}{{if eq &amp;quot;disk_used_percent&amp;quot; $metric}}机器：{{index .TagsMap &amp;quot;ident&amp;quot;}} 分区：{{index .TagsMap &amp;quot;path&amp;quot;}}{{else}}{{.TagsJSON}}{{end}} {{if .IsRecovered}}**恢复时间**：{{timeformat .LastEvalTime}}{{else}}**触发时间**: {{timeformat .TriggerTime}} **触发时值**: {{.TriggerValue}}{{end}} **发送时间**: {{timestamp}} 注意上面监控指标那一行，先从TagsMap中拿到 __name__ 对应的标签值，就是 $metric，然后判断 $metric 是否是磁盘利用率，如果是就只展示ident标签的内容和path标签的内容，如果不是，就还是按照老样子，把TagsJSON全部展示出来。</description></item><item><title>智能异常检测</title><link>https://n9e.github.io/docs/usage/aialert/</link><pubDate>Thu, 14 Jul 2022 10:55:57 +0000</pubDate><guid>https://n9e.github.io/docs/usage/aialert/</guid><description>时序数据异常检测简介 # 对于所有的在线业务，都会随着时间产生一些数据，这些数据我们称为时序数据，在服务正常的时候，这些时序数据的变化会符合一定的模式，我们可以根据这些时序数据的变化，来判断我们服务是否出现了异常。业内目前主要有三个方式来判断时序数据是否异常：
第一种是有值班人员实时盯着重要的时序数据，根据经验来判断时序数据是否出现了异常 第二种是使用监控产品，给关注的时序数据配置一个静态的阈值，如果超过阈值就表示时序数据出现异常 第三种是近几年出现的新的方式，使用机器学习的能力，动态学习时序数据的规律，实时计算动态的阈值，识别是否异常。 目前业界主流的方式是使用配置静态阈值来判断，但随着业务发展，这个方式也开始出现一些问题，下面介绍下传统静态阈值告警遇到的问题。
静态阈值可能遇到的问题 # 01.静态阈值覆盖场景有限，业务类监控数据不适用 # 业务类监控数据，使用静态阈值很多情况下不能很好的标识是否异常，比如下图的曲线，常见的业务数据都有这些特点，峰值和谷值差距很大，如果上限阈值配置是600，下降阈值配置10，那图中红圈标记的异常就会出现漏报。
02.阈值会由于特殊日或业务发展产生变化 # 业务监控指标经常会由于 “特殊日”（节假日、营销活动日）或者业务发展影响而产生变化，传统的静态阈值或同环比策略在这种场景下，会产生多次误报，给负责稳定性的同学造成不必要的打扰，像下图的情况，紫色曲线是当天的监控数据同比1天和7天都低很多，但属于正常情况，这个在静态阈值的同环比策略下则会发出误报。
03.传统静态阈值的设置，依赖专家经验，人力维护成本高 # 下图是静态阈值告警配置常见的流程，经过几轮调整之后，才可正常使用，而随着业务增长，仍然需要不定期调整阈值，人力维护成本高。
智能异常检测的优势 # 智能异常检测基于机器学习算法模型实时生成动态基线，可以有效避免传统阈值方式造成的误报问题，也摆脱了对专家经验的依赖，提升了告警准确率，也提升了值班同学的幸福感：）
下图是智能异常算法实时计算出来的动态基线，会随着业务增长动态变化
下图总结了静态阈值和智能算法的区别：
哪些场景适合智能异常检测？ # 智能异常检测相比静态阈值的规则，有很多优势，对于有周期性的时序数据尤其合适，以下列举了一些常见的场景：
网页浏览量 活跃用户数 应用下载量 购物下单量 证券交易量 打车呼叫量 &amp;hellip;&amp;hellip; 前面介绍了智能异常检测的优势和适用场景，那如何落地呢？下面介绍下夜莺的落地方案。
夜莺的智能告警落地方案 # 如果之前使用了夜莺，再部署一个智能异常检测模块即可，可以和开源的夜莺监控无缝集成，整体架构如下图
智能异常检测模块完成安装之后，在夜莺告警规则配置页面，会多出一个智能告警的选项，如下图所示：
选择智能告警之后，只需填写要监控的指标，不需要填写阈值，点击保存即可，之后在告警规则列表页，智能告警的规则右侧会有一个“训练结果”的按钮
点击“训练结果”，可以进入训练结果详情页，点击曲线详情，可以看到曲线学习出来的动态基线。如果曲线偏离到基线之外，夜莺的告警引擎会发出告警通知。
自建还是购买？ # 从成本角度来看 # 如果你们团队已经有了算法团队+研发团队，可以让两个团队根据业界已有方案来落地实施。如果没有算法或者研发团队，招一个能把智能异常检测落地的工程师的成本至少是20W，夜莺的智能告警企业版，一年只有1W+，在这个情况下购买智能告警服务，显然是更划算的。
从工作幸福感来看 # 如果你在运维的一线，且经常被静态阈值的误报打扰，建议推动团队尽快开启智能异常检测功能，如果团队没有这方面积累，可以购买夜莺的智能告警服务，减少日常生活中误报对自己的打扰。
如果对夜莺的智能异常检测服务感兴趣，欢迎点击 链接 购买试用，购买之后，将您的订单号和联系方式发送邮件到 n9e@flashcat.cloud, 我们后面会联系您，目前正在打折优惠，团队版首月试用费用只需 29 元， 感兴趣的可以买起来：）</description></item></channel></rss>