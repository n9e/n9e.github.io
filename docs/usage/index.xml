<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>使用手册 on</title><link>https://n9e.github.io/docs/usage/</link><description>Recent content in 使用手册 on</description><generator>Hugo -- gohugo.io</generator><language>en-US</language><lastBuildDate>Fri, 03 Jun 2022 08:48:45 +0000</lastBuildDate><atom:link href="https://n9e.github.io/docs/usage/index.xml" rel="self" type="application/rss+xml"/><item><title>入门教程</title><link>https://n9e.github.io/docs/usage/video/</link><pubDate>Tue, 06 Oct 2020 08:48:57 +0000</pubDate><guid>https://n9e.github.io/docs/usage/video/</guid><description>视频讲解-夜莺页面功能介绍 视频讲解-告警自愈脚本的使用 视频讲解-监控对象的管理功能 视频讲解-如何接入多个时序存储 视频讲解-夜莺的配置文件 除了这些视频教程，使用手册这一章，还会提供更多小节来介绍一些大家常问的问题，比如如何监控交换机，如何监控应用等。从总体问题比例来看，夜莺服务端问题相对较少，大家摸索一下，很快可以掌握，疑问比较多的，是对各种目标的监控，比如如何监控 MySQL，如何监控 Redis 等，针对这部分问题，大家应该去查看采集器的文档，比如 Telegraf 每个采集器下面都有 README介绍， 通过这些 README，理论上就可以知道如何使用各个采集器。Categraf 的采集器目录 在这里， 未来我们也会把所有采集器补充完整的 README，以及告警规则和监控大盘JSON，大家导入直接就可以使用，当然，路漫漫其修远兮，一步一步来吧。</description></item><item><title>SNMP</title><link>https://n9e.github.io/docs/usage/snmp/</link><pubDate>Tue, 06 Oct 2020 08:48:57 +0000</pubDate><guid>https://n9e.github.io/docs/usage/snmp/</guid><description>监控网络设备，主要是通过 SNMP 协议，Categraf、Telegraf、Datadog-Agent、snmp_exporter 都提供了这个能力。
Categraf # Categraf 提供了一个网络设备的采集插件：switch_legacy，在 conf/input.switch_legacy 下可以看到配置文件，最核心就是配置交换机的 IP 以及认证信息，switch_legacy 当前只支持 v2 协议，所以认证信息就是 community 字段。其他配置都一目了然，这里就不赘述了。
这个插件是把之前 Open-Falcon 社区的 swcollector 直接拿过来了，感谢 冯骐 大佬持续在维护这个开源项目。
Telegraf # Telegraf 内置支持 SNMP 的采集，本节给一个入门例子，让大家快速上手，更多具体知识可以参考这里。在 telegraf.conf 中搜索 inputs.snmp，即可找到对应的配置，例子如下：
[[inputs.snmp]] agents = [&amp;quot;udp://172.25.79.194:161&amp;quot;] timeout = &amp;quot;5s&amp;quot; version = 3 agent_host_tag = &amp;quot;ident&amp;quot; retries = 1 sec_name = &amp;quot;managev3user&amp;quot; auth_protocol = &amp;quot;SHA&amp;quot; auth_password = &amp;quot;example.Demo.c0m&amp;quot; [[inputs.snmp.field]] oid = &amp;quot;RFC1213-MIB::sysUpTime.0&amp;quot; name = &amp;quot;uptime&amp;quot; [[inputs.snmp.field]] oid = &amp;quot;RFC1213-MIB::sysName.0&amp;quot; name = &amp;quot;source&amp;quot; is_tag = true [[inputs.</description></item><item><title>应用监控</title><link>https://n9e.github.io/docs/usage/apm/</link><pubDate>Tue, 06 Oct 2020 08:48:57 +0000</pubDate><guid>https://n9e.github.io/docs/usage/apm/</guid><description>写在前面 # 应用监控实际要比 OS、中间件的监控更为关键，因为某个 OS 层面的指标异常，比如 CPU 飙高了，未必会影响终端用户的体验，但是应用层面的监控指标出问题，通常就会影响客户的感受、甚至影响客户的付费。
针对应用监控，Google提出了 4 个黄金指标，分别是：流量、延迟、错误、饱和度，其中前面 3 个指标都可以通过内嵌 SDK 的方式埋点采集，本节重点介绍这种方式。当然了，内嵌 SDK 有较强的代码侵入性，如果业务研发难以配合，也可以采用解析日志的方案，这个超出了夜莺（夜莺是指标监控系统）的范畴，大家如果感兴趣，可以了解一下快猫的商业化产品
埋点工具 # 最常见的通用埋点工具有两个，一个是 statsd，一个是 prometheus SDK，当然，各个语言也会有自己的更方便的方式，比如 Java 生态使用 micrometer 较多，如果是 SpringBoot 的程序，则使用 actuator 会更便捷，actuator 底层就是使用 micrometer。
夜莺自身监控 # 我们就以夜莺自身的代码举例，讲解如何内嵌埋点工具，这里选择 prometheus SDK 作为埋点方案。
夜莺核心模块有两个，Webapi 主要是提供 HTTP 接口给 JavaScript 调用，Server 主要是负责接收监控数据，处理告警规则，这两个模块都引入了 Prometheus 的 Go 的SDK，用此方式做 App Performance 监控，本节以夜莺的代码为例，讲解如何使用 Prometheus 的 SDK。
Webapi # Webapi 模块主要统计两个内容，一个是请求的数量统计，一个是请求的延迟统计，统计时，要用不同的 Label 做维度区分，后面就可以通过不同的维度做多种多样的统计分析，对于 HTTP 请求，规划 4 个核心 Label，分别是：service、code、path、method。service 标识服务名称，要求全局唯一，便于和其他服务名称区分开，比如 Webapi 模块，就定义为 n9e-webapi，code 是 HTTP 返回的状态码，200 就表示成功数量，其他 code 就是失败的，后面我们可以据此统计成功率，method 是 HTTP 方法，GET、POST、PUT、DELETE 等，比如新增用户和获取用户列表可能都是 /api/n9e/users，从路径上无法区分，只能再加上 method 才能区分开。</description></item><item><title>日志监控</title><link>https://n9e.github.io/docs/usage/mtail/</link><pubDate>Tue, 06 Oct 2020 08:48:57 +0000</pubDate><guid>https://n9e.github.io/docs/usage/mtail/</guid><description>前言 # 说到日志监控，大家第一反应的可能是ELK的方案，或者Loki的方案，这两个方案都是把日志采集了发到中心，在中心存储、查看、分析，不过这个方案相对比较重量级一些，如果我们的需求只是从日志中提取一些metrics数据，比如统计一些日志中出现的Error次数之类的，则有一个更简单的方案。
这里给大家介绍一个Google出品的小工具，mtail，mtail就是流式读取日志，通过正则表达式匹配的方式从日志中提取metrics指标，这种方式可以利用目标机器的算力，不过如果量太大，可能会影响目标机器上的业务程序，另外一个好处是无侵入性，不需要业务埋点，如果业务程序是第三方供应商提供的，我们改不了其代码，mtail此时就非常合适了。当然了，如果业务程序是我们公司的人自己写的，那还是建议用埋点的方式采集指标，mtail只是作为一个补充吧。
mtail简介 # mtail的使用方案，参考如下两个文档（下载的话参考Releases页面）：
Deploying Programming Guide 我们拿mtail的启动命令来举例其用法：
mtail --progs /etc/mtail --logs /var/log/syslog --logs /var/log/ntp/peerstats 通过 --progs 参数指定一个目录，这个目录里放置一堆的*.mtail文件，每个mtail文件就是描述的正则提取规则，通过 --logs 参数来指定要监控的日志目录，可以写通配符，--logs 可以写多次，上例中只是指定了 --progs 和 --logs ，没有其他参数，mtail启动之后会自动监听一个端口3903，在3903的/metrics接口暴露符合Prometheus协议的监控数据，Prometheus 或者 Categraf 或者 Telegraf 等就可以从 /metrics 接口提取监控数据。
这样看起来，原理就很清晰了，mtail 启动之后，根据 --logs 找到相关日志文件，seek 到文件末尾，开始流式读取，每读到一行，就根据 --progs 指定的那些规则文件做匹配，看是否符合某些正则，从中提取时序数据，然后通过3903的/metrics暴露采集到的监控指标。当然，除了Prometheus这种/metrics方式暴露，mtail 还支持把监控数据直接推给 graphite 或者 statsd，具体可以参考：这里
mtail样例 # 这里我用mtail监控一下n9e-server的日志，从中提取一下各个告警规则触发的 notify 的数量，这个日志举例：
2021-12-27 10:00:30.537582 INFO engine/logger.go:19 event(cbb8d4be5efd07983c296aaa4dec5737 triggered) notify: rule_id=9 [__name__=net_response_result_code author=qin ident=10-255-0-34 port=4567 protocol=tcp server=localhost]2@1640570430 很明显，日志中有这么个关键字：notify: rule_id=9，可以用正则来匹配，统计出现的行数，ruleid 也可以从中提取到，这样，我们可以把 ruleid 作为标签上报，于是乎，我们就可以写出这样的 mtail 规则了：</description></item></channel></rss>