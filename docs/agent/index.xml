<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>采集器 on</title><link>https://n9e.github.io/docs/agent/</link><description>Recent content in 采集器 on</description><generator>Hugo -- gohugo.io</generator><language>en-US</language><lastBuildDate>Fri, 06 May 2022 08:49:15 +0000</lastBuildDate><atom:link href="https://n9e.github.io/docs/agent/index.xml" rel="self" type="application/rss+xml"/><item><title>Categraf</title><link>https://n9e.github.io/docs/agent/categraf/</link><pubDate>Thu, 12 May 2022 13:26:54 +0100</pubDate><guid>https://n9e.github.io/docs/agent/categraf/</guid><description>基本介绍 # Categraf 是一款 all-in-one 的采集器，由 快猫团队 开源，代码托管在两个地方：
gitlink: https://www.gitlink.org.cn/flashcat/categraf github: https://github.com/flashcatcloud/categraf Categraf 不但可以采集 OS、MySQL、Redis、Oracle 等常见的监控对象，也准备提供日志采集能力和 trace 接收能力，这是夜莺主推的采集器，相关信息请查阅项目 README
Categraf 采集到数据之后，通过 remote write 协议推给远端存储，Nightingale 恰恰提供了 remote write 协议的数据接收接口，所以二者可以整合在一起，重点是配置 Categraf 的 conf/config.toml 中的 writer 部分，其中 url 部分配置为 n9e-server 的 remote write 接口：
[writer_opt] # default: 2000 batch = 2000 # channel(as queue) size chan_size = 10000 [[writers]] url = &amp;quot;http://N9E-SERVER:19000/prometheus/v1/write&amp;quot; # Basic auth username basic_auth_user = &amp;quot;&amp;quot; # Basic auth password basic_auth_pass = &amp;quot;&amp;quot; # timeout settings, unit: ms timeout = 5000 dial_timeout = 2500 max_idle_conns_per_host = 100 采集插件 # Categraf 每个采集器，都有一个配置目录，在 conf 下面，以 input.</description></item><item><title>Telegraf</title><link>https://n9e.github.io/docs/agent/telegraf/</link><pubDate>Thu, 12 May 2022 13:26:54 +0100</pubDate><guid>https://n9e.github.io/docs/agent/telegraf/</guid><description>Telegraf 是 InfluxData 公司开源的一款采集器，内置非常多的采集插件，不过 Telegraf 是面向 InfluxDB 生态的，采集的监控数据推给 InfluxDB 非常合适，推给 Prometheus、Victoriametrics、Thanos 这些时序库，可能会带来问题。主要是两点：
有些数据是 string 类型的，Prometheus、VM、M3、Thanos 等都不支持 string 类型的数据 有些采集器设计的标签是非稳态的设计，比如经常会看到 result=success 和 result=failed 的标签，需要手工配置采集器 drop 掉，但是对于新手确实有些难度 另外一个问题是，Telegraf 采集的数据存到 Prometheus 中，这种做法在业界实践的比较少，导致 Grafana 大盘很少，需要我们付出较大精力手工制作大盘。不过，如果，你是资深监控玩家，Telegraf 上面这些问题都不是问题。下面是笔者之前调研 Telegraf 的几篇笔记，供大家参考：
Telegraf监控客户端调研笔记（1）-介绍、安装、初步测试 Telegraf监控客户端调研笔记（2）-CPU、MEM、DISK、IO相关指标采集 Telegraf监控客户端调研笔记（3）-kernel、system、processes相关指标采集 Telegraf监控客户端调研笔记（4）-exec、net、netstat相关指标采集 Telegraf监控客户端调研笔记（5）-本地端口监控&amp;amp;远程TCP探测 Telegraf监控客户端调研笔记（6）-PING监控、进程监控 Telegraf 是如何与 Nightingale 整合的呢？Telegraf 有不同的 output plugin，可以把采集的数据推给 OpenTSDB、推给 Datadog，Nightingale 实现了 OpenTSDB 和 Datadog 这两种消息接收接口，所以，可以通过任一 output plugin 和 Nightingale 对接。下面提供一个简单的 Telegraf 配置供大家参考，使用 OpenTSDB 的 output plugin 和 Nightingale 对接，即 [[outputs.</description></item><item><title>Datadog-Agent</title><link>https://n9e.github.io/docs/agent/datadog-agent/</link><pubDate>Thu, 12 May 2022 13:26:54 +0100</pubDate><guid>https://n9e.github.io/docs/agent/datadog-agent/</guid><description>Datadog 是专门提供监控和分析服务的 SaaS 服务商，市值几百亿，成立了10多年了，他们做的客户端采集器，理论上应该是比较完备的，夜莺实现了几个 Datadog 特定的接口，可以接收Datadog-Agent 推送上来的数据，即：我们可以拿 Datadog-Agent 作为客户端采集器采集监控数据，然后上报给夜莺。
1、注册datadog的账号 # https://www.datadoghq.com/
2、选择套餐 # https://app.datadoghq.com/billing/plan 可以选择免费的套餐
3、拿到agent安装命令 # https://app.datadoghq.com/account/settings#agent 选择对应的OS，比如CentOS7，可能是类似这么个命令：
DD_AGENT_MAJOR_VERSION=7 DD_API_KEY=xxx DD_SITE=&amp;quot;datadoghq.com&amp;quot; bash -c &amp;quot;$(curl -L https://s3.amazonaws.com/dd-agent/scripts/install_script.sh)&amp;quot; DD_API_KEY 是一串字符串，不同的账号有自己的 API_KEY，拿着这个命令去 shell 下（使用root账号应该会省事一些）跑一下安装
4、修改配置文件 # 修改 Datadog-Agent 的配置文件，把推送监控数据的地址，改成 n9e-server 的地址，配置文件地址在：/etc/datadog-agent/datadog.yaml 修改 dd_url 这个配置项，比如我的环境：
dd_url: http://10.206.0.16:19000/datadog 5、重启datadog-agent # systemctl restart datadog-agent</description></item><item><title>Grafana-Agent</title><link>https://n9e.github.io/docs/agent/grafana-agent/</link><pubDate>Thu, 12 May 2022 13:26:54 +0100</pubDate><guid>https://n9e.github.io/docs/agent/grafana-agent/</guid><description>Grafana-agent 是 Grafana 开源的一款 Agent，专门用于和自己的 Cloud 做数据采集集成，通过 remote write 协议推数据给后端，和 Categraf 的数据推送方式一样，所以，也是可以作为 Nightingale 的采集器的。Grafana-Agent 的具体使用请查阅 Grafana 官方文档，下面给出 v0.23.0 版本的 Grafana-Agent 的简要安装方式，如果各位看官使用了其他版本的 Grafana-Agent，下面的教程可能就不适用了，毕竟，Grafana-Agent 也在快速迭代，请大家注意。
1. 下载二进制 # 以 64 位 Linux 举例：
curl -SOL &amp;quot;https://github.com/grafana/agent/releases/download/v0.23.0/agent-linux-amd64.zip&amp;quot; gunzip ./agent-linux-amd64.zip chmod a+x &amp;quot;agent-linux-amd64&amp;quot; 2. 生成配置 # cat &amp;lt;&amp;lt;EOF &amp;gt; ./agent-cfg.yaml server: log_level: info http_listen_port: 12345 metrics: global: scrape_interval: 15s scrape_timeout: 10s remote_write: - url: https://N9E-SERVER:19000/prometheus/v1/write basic_auth: username: &amp;quot;&amp;quot; password: &amp;quot;&amp;quot; integrations: agent: enabled: true node_exporter: enabled: true include_exporter_metrics: true EOF 上面的 url 部分，就是 n9e-server 的 remote write 数据接收接口，仔细看就会发现，和 Categraf 章节用的 url 是一样的。</description></item><item><title>Falcon-Plugin</title><link>https://n9e.github.io/docs/agent/falcon-plugin/</link><pubDate>Thu, 12 May 2022 13:26:54 +0100</pubDate><guid>https://n9e.github.io/docs/agent/falcon-plugin/</guid><description>Nightingale 实现了 Open-Falcon 的 HTTP 数据接收接口，所以，Open-Falcon 社区很多采集插件也是可以直接使用的。但是 Falcon-Agent 不行，因为 Falcon-Agent 推送监控数据给服务端，走的是 RPC 接口。
如果你发现某个 Falcon-Plugin 是用 CRON 的方式驱动的，推送数据走的是 Falcon-Agent 的 HTTP 接口，那这个插件就可以推数据给夜莺。举个例子，比如 mymon 其配置文件采用 ini 格式，下面是样例：
[default] basedir = . # 工作目录 log_dir = ./fixtures # 日志目录，默认日志文件为myMon.log,旧版本有log_file项，如果同时设置了，会优先采用log_file ignore_file = ./falconignore # 配置忽略的metric项 snapshot_dir = ./snapshot # 保存快照(process, innodb status)的目录 snapshot_day = 10 # 保存快照的时间(日) log_level = 5 # 日志级别[RFC5424] # 0 LevelEmergency # 1 LevelAlert # 2 LevelCritical # 3 LevelError # 4 LevelWarning # 5 LevelNotice # 6 LevelInformational # 7 LevelDebug falcon_client=http://127.</description></item></channel></rss>